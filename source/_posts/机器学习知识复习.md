---
title: 机器学习知识复习
mathjax: true
date: 2019-02-25 09:54:28
tags: [机器学习,深度学习]
category: [机器学习,深度学习]
---

## 机器学习

### 机器学习基础

#### 偏差与方差

- 偏差.

  偏差度量了学习**算法预测的期望值**与**真实结果**的偏离程度, 即 **刻画了学习算法本身的拟合能力** .

- 方差.

  方差表示**模型预测的期望值**与**预测值**之间的平方和，度量了同样大小的训练集的变动所导致的学习性能的变化, 即 **刻画了数据扰动所造成的影响** .

- 噪声.

  噪声表达了在当前任务上任何学习算法所能达到的期望泛化误差的下界, 即 **刻画了学习问题本身的难度** . 巧妇难为无米之炊, 给一堆很差的食材, 要想做出一顿美味, 肯定是很有难度的.

#### 导致偏差和方差的原因

- 偏差

  通常是由于我们对学习算法做了错误的假设，或者模型的复杂度不够；

  - 比如真实模型是一个二次函数，而我们假设模型为一次函数，这就会导致偏差的增大（欠拟合）；
  - **由偏差引起的误差**通常在**训练误差**上就能体现，或者说训练误差主要是由偏差造成的

- 方差

  通常是由于模型的复杂度相对于训练集过高导致的；

  - 比如真实模型是一个简单的二次函数，而我们假设模型是一个高次函数，这就会导致方差的增大（过拟合）；
  - **由方差引起的误差**通常体现在测试误差相对训练误差的**增量**上。

### 深度学习中的偏差与方差

- 神经网络的拟合能力非常强，因此它的**训练误差**（偏差）通常较小；

- 但是过强的拟合能力会导致较大的方差，使模型的测试误差（**泛化误差**）增大；

- 因此深度学习的核心工作之一就是研究如何降低模型的泛化误差，这类方法统称为

  **正则化方法**

  1. **batch normalization**

     **1.1. BN的作用**

     * BN 是一种正则化方法（减少泛化误差），主要作用有：
       - **加速网络的训练**（缓解梯度消失，支持更大的学习率）
       - **防止过拟合**
       - 降低了**参数初始化**的要求。

     **1.2. 为什么要用BN?**

     **训练的本质是学习数据分布**。如果训练数据与测试数据的分布不同会**降低**模型的**泛化能力**。因此，应该在开始训练前对所有输入数据做归一化处理。

     而在神经网络中，因为**每个隐层**的参数不同，会使下一层的输入发生变化，从而导致每一批数据的分布也发生改变；**致使**网络在每次迭代中都需要拟合不同的数据分布，增大了网络的训练难度与**过拟合**的风险。

     **1.3. BN的基本原理**

     - BN 方法会针对**每一批数据**，在**网络的每一层输入**之前增加**归一化**处理，使输入的均值为 `0`，标准差为 `1`。**目的**是将数据限制在统一的分布下。

     - 具体来说，针对每层的第 `k` 个神经元，计算**这一批数据**在第 `k` 个神经元的均值与标准差，然后将归一化后的值作为该神经元的激活值。
       $$\hat{x}_{k} \leftarrow \frac{x_{k}-\mathrm{E}\left[x_{k}\right]}{\sqrt{\operatorname{Var}\left[x_{k}\right]}}$$

     - 但同时 BN 也降低了模型的拟合能力，破坏了之前学到的**特征分布**；

     - 为了**恢复数据的原始分布**，BN 引入了一个**重构变换**来还原最优的输入数据分布

       $$y_{k} \leftarrow \gamma \hat{X}_{k}+\beta​$$

     **1.4. BN方法小结**

     BN的过程可以归纳为一个函数：

     $$\begin{aligned} \mathrm{BN}\left(\boldsymbol{x}_{i}\right) &=\gamma \hat{\boldsymbol{x}}_{i}+\beta \\ &=\gamma \frac{\boldsymbol{x}_{i}-\mathbf{E}\left[\boldsymbol{x}_{i}\right]}{\sqrt{\boldsymbol{\operatorname { V a r }}\left[\boldsymbol{x}_{i}\right]+\epsilon}}+\beta \end{aligned}​$$

     **1.5. BN在训练和测试时分别怎么做**

     - **训练时**每次会传入一批数据，做法如前述；

     - 当**测试**或**预测时**，每次可能只会传入**单个数据**，此时模型会使用**全局统计量**代替批统计量；

       - 训练每个 batch 时，都会得到一组`（均值，方差）`；

       - 所谓全局统计量，就是对这些均值和方差求其对应的数学期望；

       - 具体计算公式为： 

         $$\begin{array}{c}{\mathrm{E}[x] \leftarrow \mathrm{E}\left[\mu_{i}\right]} \\ {\operatorname{Var}[x] \leftarrow \frac{m}{m-1} \mathrm{E}\left[\sigma_{i}^{2}\right]}\end{array}$$ 

         > 其中 $μ_i$ 和 $σ_i$ 分别表示第 i 轮 batch 保存的均值和标准差；`m` 为 batch_size，系数 `m/(m-1)` 用于计算**无偏方差估计**

         >  原文称该方法为**移动平均**（moving averages）

       - 此时的BN调整为

         $$\begin{aligned} \mathrm{BN}\left(\boldsymbol{x}_{i}\right) &=\gamma \frac{\boldsymbol{x}_{i}-\mathbf{E}\left[\boldsymbol{x}_{i}\right]}{\sqrt{\operatorname{Var}\left[\boldsymbol{x}_{i}\right]+\epsilon}}+\beta \\ &=\frac{\gamma}{\sqrt{\operatorname{Var}\left[\boldsymbol{x}_{i}\right]+\epsilon}} \boldsymbol{x}_{i}+\left(\beta-\frac{\gamma \mathbf{E}\left[\boldsymbol{x}_{i}\right]}{\sqrt{\operatorname{Var}\left[\boldsymbol{x}_{i}\right]+\epsilon}}\right)\end{aligned}$$

     具体来说：BN就是

     * 在训练时用每一批数据的均值和标准差做平均得到$\hat{X}_k$，然后用

     $y_{k} \leftarrow \gamma \hat{X}_{k}+\beta$做变换得到最终需要的x，进行训练。

     * 而测试时用每批数据得到的均值方差求平均来做归一化

  2. **L1/L2 范数正则化**

     **2.1. L1/L2 范数的作用、异同**
     **相同点**

     * 限制模型的学习能力——通过限制参数的规模，使模型偏好于**权值较小**的目标函数，防止过拟合。

     **不同点**

     * **L1 正则化**可以产生更**稀疏的权值矩阵**，可以用于特征选择，同时一定程度上防止过拟合；**L2 正则化**主要用于防止模型过拟合
     * **L1 正则化**适用于特征之间有关联的情况；**L2 正则化**适用于特征之间没有关联的情况。

     **2.2. 为什么 L1 和 L2 正则化可以防止过拟合？**

     - L1 & L2 正则化会使模型偏好于更小的权值。
     - 更小的权值意味着**更低的模型复杂度**；添加 L1 & L2 正则化相当于为模型添加了某种**先验**，限制了参数的分布，从而降低了模型的复杂度。
     - 模型的复杂度降低，意味着模型对于噪声与异常点的抗干扰性的能力增强，从而提高模型的泛化能力。——直观来说，就是对训练数据的拟合刚刚好，不会过分拟合训练数据（比如异常点，噪声）——**奥卡姆剃刀原理**

     **2.3. 为什么 L1 正则化可以产生稀疏权值，而 L2 不会？**
     L1正则化和L2正则化可以看做是损失函数的惩罚项。所谓『惩罚』是指对损失函数中的某些参数做一些限制。对于线性回归模型，使用L1正则化的模型建叫做Lasso回归，使用L2正则化的模型叫做Ridge回归（岭回归）。

     L1回归的公式如下：
     $$
     J=J_{0}+\alpha \sum_{w}|w|
     $$
     其中$J_{0}$是原始的损失函数，加号后面的一项是L1正则化项，$\alpha$是正则化系数

     其中$J_0$是原始的损失函数，加号后面的一项是L1正则化项，αα是正则化系数。注意到L1正则化是权值的绝对值之和，$J$是带有绝对值符号的函数，因此$J$是不完全可微的。机器学习的任务就是要通过一些方法（比如梯度下降）求出损失函数的最小值。当我们在原始损失函数$J_0$后添加L1正则化项时，相当于对$J_0$做了一个约束。令$L=\alpha \sum_{w}|w|$，则$J=J_{0}+L$，此时我们的任务变成在L1约束下求出$J_0$取最小值的解。考虑二维的情况，即只有两个权值$w^1$和$w^2$，此时$L=\left|w^{1}\right|+\left|w^{2}\right|$对于梯度下降法，求解$J_0$的过程可以画出等值线，同时L1正则化的函数L也可以在w1w2w1w2的二维平面上画出来。如下图：

     ![](https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/20190226104434.png)

     图中等值线是$J_{0}$的等值线，黑色方形是L函数的图形。在图中，当$J_{0}$等值线与$L$图形首次相交的地方就是最优解。上图中$J_{0}$与L在L的一个顶点处相交，这个顶点就是最优解。注意到这个顶点的值是$\left(w^{1}, w^{2}\right)=(0, w)$。可以直观想象，因为L函数有很多『突出的角』（二维情况下四个，多维情况下更多），$J_{0}$与这些角接触的机率会远大于与L其它部位接触的机率，而在这些角上，会有很多权值等于0，这就是为什么L1正则化可以产生稀疏模型，进而可以用于特征选择。

     而L2正则化的公式如下：

     $$J=J_{0}+\alpha \sum_{m} w^{2}$$

     平面图如下，因为此时L2的图形是一个圆，因此两者相交的点没有0的情况，这就是L2不产生稀疏矩阵的原因。

     ![](https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/20190226104909.png)

P.S. 为什么相切的点就是所求的点。我们要求$J_0$在L约束下的最小值，L是约束，那么我们就只能在下面的菱形和圆形里面取值，相切那个点。（彩色等值线是越靠近外面越大）

### 偏差与方差的权衡

* 给定一个机器学习任务：
  * 训练不足时，模型拟合能力不足，此时偏差是主要影响模型泛化误差的原因。
  * 随着训练进行，模型拟合能力增强，此时方差逐渐主导模型的泛化误差。
  * 当训练充足后，模型拟合能力过强，此时发生过拟合
* 偏差和方差的关系和模型复杂度，欠拟合，过拟合的概念紧密关联。
  * 当模型复杂度增大时，偏差随之减小，方差随之增大
  * 泛化误差存在最小值，此时模型复杂度处于最优状态，增大模型复杂度会增大方差，减小模型复杂度会增大偏差。

### 生成模型与判别模型

- 监督学习的任务是学习一个模型，对给定的输入预测相应的输出

- 这个模型的一般形式为一个**决策函数**或一个**条件概率分布**（后验概率）：
  $$
  Y=f(X) \quad\text { or } \quad P(Y | X)
  $$
  - **决策函数**：输入 X 返回 Y；其中 Y 与一个**阈值**比较，然后根据比较结果判定 X 的类别
  - **条件概率分布**：输入 X 返回 **X 属于每个类别的概率**；将其中概率最大的作为 X 所属的类别

- 监督学习模型可分为**生成模型**与**判别模型**

  - **判别模型**直接学习**决策函数**或者**条件概率分布**

    - 直观来说，**判别模型**学习的是类别之间的最优分隔面，反映的是不同类数据之间的差异

  - **生成模型**学习的是**联合概率分布**$P(X, Y)$，然后根据条件概率公式计算$P(Y|X)$
    $$
    P(Y | X)=\frac{P(X, Y)}{P(X)}
    $$

**两者之间的联系**

- 由生成模型可以得到判别模型，但由判别模型得不到生成模型。

- 当存在“隐变量”时，只能使用生成模型

  > 隐变量：当我们找不到引起某一现象的原因时，就把这个在起作用，但无法确定的因素，叫“隐变量”

**优缺点**

- 判别模型
  - 优点
    - 直接面对预测，往往学习的准确率更高
    - 由于直接学习 `P(Y|X)` 或 `f(X)`，可以对数据进行各种程度的抽象，定义特征并使用特征，以简化学习过程
  - 缺点
    - 不能反映训练数据本身的特性
    - ...
- 生成模型
  - 优点
    - 可以还原出联合概率分布 `P(X,Y)`，判别方法不能
    - 学习收敛速度更快——即当样本容量增加时，学到的模型可以更快地收敛到真实模型
    - 当存在“隐变量”时，只能使用生成模型
  - 缺点
    - 学习和计算过程比较复杂

**常见模型**

- 判别模型
  - K 近邻、感知机（神经网络）、决策树、逻辑斯蒂回归、**最大熵模型**、SVM、提升方法、**条件随机场**
- 生成模型
  - 朴素贝叶斯、隐马尔可夫模型、混合高斯模型、贝叶斯网络、马尔可夫随机场

### 先验概率与后验概率

> [先验概率，后验概率，似然概率，条件概率，贝叶斯，最大似然](https://blog.csdn.net/suranxu007/article/details/50326873) - CSDN博客

**条件概率**（似然概率）

- 一个事件发生后另一个事件发生的概率。
- 一般的形式为 `P(X|Y)`，表示 y 发生的条件下 x 发生的概率。
- 有时为了区分一般意义上的**条件概率**，也称**似然概率**

**先验概率**

- 事件发生前的预判概率
- 可以是基于历史数据的统计，可以由背景常识得出，也可以是人的主观观点给出。
- 一般都是**单独事件**发生的概率，如 `P(A)`、`P(B)`。

**后验概率**

- 基于先验概率求得的**反向条件概率**，形式上与条件概率相同（若 `P(X|Y)` 为正向，则 `P(Y|X)` 为反向）

**贝叶斯公式**
$$
P(Y | X)=\frac{P(X | Y) * P(Y)}{P(X)}
$$

## 机器学习实践

### 超参数选择

#### Grid Search

- 网格搜索
- 在高维空间中对一定区域进行遍历

#### Random Search

- 在高维空间中随机选择若干超参数

#### 相关库（未使用）

- Hyperopt
  - 用于超参数优化的 Python 库，其内部使用 Parzen 估计器的树来预测哪组超参数可能会得到好的结果。
  - GitHub - <https://github.com/hyperopt/hyperopt>
- Hyperas
  - 将 Hyperopt 与 Keras 模型集成在一起的库
  - GitHub - <https://github.com/maxpumperla/hyperas>

### 余弦相似度（Cos距离）与欧氏距离的区别和联系

* 欧式距离和余弦相似度都能度量 2 个向量之间的相似度
* 放到向量空间中看，欧式距离衡量两点之间的**直线距离**，而余弦相似度计算的是两个向量之间的**夹角**
* **没有归一化时**，欧式距离的范围是 [0, +∞]，而余弦相似度的范围是 [-1, 1]；余弦距离是计算相似程度，而欧氏距离计算的是相同程度（对应值的相同程度）
* **归一化的情况下**，可以将空间想象成一个超球面（三维），欧氏距离就是球面上两点的直线距离，而向量余弦值等价于两点的球面距离，本质是一样。

### 监督学习和无监督学习

* 监督学习给定标签，无监督学习不给定标签

* 监督学习的任务是分类和回归，无监督学习的任务是聚类

### 熵，交叉熵和相对熵

* 信息熵代表的是随机变量或整个**系统的不确定性**，熵越大，随机变量或系统的不确定性就越大。
  $$
  -\sum_{i=1}^{n} P\left(X_{i}\right) \log P\left(X_{i}\right)
  $$

* **交叉熵**，其用来衡量在给定的真实分布下，使用**非真实分布**所指定的策略消除系统的不确定性所需要付出的努力的大小
  $$
  \sum_{k=1}^{N} p_{k} \log _{2} \frac{1}{q_{k}}
  $$
  其中$p_k$是真实分布，$q_k$为非真实分布

  因此，交叉熵越低，这个消除系统不确定性的策略就越好，最低的交叉熵也就是使用了真实分布所计算出来的信息熵，因为此时$p_{k}=q_{k}$ ，交叉熵 = 信息熵。这也是为什么在机器学习中的分类算法中，我们总是最小化交叉熵，因为交叉熵越低，就证明由算法所产生的策略最接近最优策略，也间接证明我们算法所算出的非真实分布越接近真实分布。

* **相对熵**，其用来衡量两个取值为正的函数或概率分布之间的差异，即：
  相对熵 = 某个策略的交叉熵 - 信息熵

具体可以参考[熵，交叉熵，相对熵](http://drawon.site/2018/09/19/%E7%86%B5-%E4%BA%A4%E5%8F%89%E7%86%B5%E4%B8%8E%E7%9B%B8%E5%AF%B9%E7%86%B5/)

### 混淆矩阵、模型度量指标：准确率、精确率、召回率、F1 值等

**混淆矩阵**

- True Positive(TP)：将正类预测为正类的数量.
- True Negative(TN)：将负类预测为负类的数量.
- False Positive(FP)：将负类预测为正类数 → 误报 (Type I error).
- False Negative(FN)：将正类预测为负类数 → 漏报 (Type II error).

![](https://github-blog-1255346696.cos.ap-beijing.myqcloud.com/20190227145622.png)

**准确率**：
$$
A C C=\frac{T P+T N}{T P+T N+F P+F N}
$$
**精确率**：
$$
P=\frac{T P}{T P+F P}
$$
**召回率**：
$$
R=\frac{T P}{T P+F N}
$$
准确率与精确率的区别：

> 在正负样本不平衡的情况下，**准确率**这个评价指标有很大的缺陷。比如在互联网广告里面，点击的数量是很少的，一般只有千分之几，如果用acc，即使全部预测成负类（不点击）acc 也有 99% 以上，没有意义。

**F1值**——精确率和召回率的调和均值：
$$
\begin{aligned} \frac{2}{F_{1}} &=\frac{1}{P}+\frac{1}{R} \\ F_{1} &=\frac{2 T P}{2 T P+F P+F N} \end{aligned}
$$

> 只有当精确率和召回率都很高时，F1值才会高

### 如何处理数据中的缺失值

可以分为以下 2 种情况：

1. 缺失值较多

   - 直接舍弃该列特征，否则可能会带来较大的噪声，从而对结果造成不良影响。

2. 缺失值较少

   - 当缺失值较少（<10%）时，可以考虑对缺失值进行填充，以下是几种常用的填充策略：

   1. 用一个**异常值**填充（比如 0），将缺失值作为一个特征处理

      `data.fillna(0)`

   2. 用**均值**|**条件均值**填充

      > 如果数据是不平衡的，那么应该使用条件均值填充
      >
      > 所谓**条件均值**，指的是与缺失值所属标签相同的所有数据的均值

      `data.fillna(data.mean())`

   3. 用相邻数据填充

      ```
      # 用前一个数据填充
      data.fillna(method='pad')
      # 用后一个数据填充
      data.fillna(method='bfill') 
      ```

   4. 插值

      `data.interpolate()`

   5. 拟合

      > 简单来说，就是将缺失值也作为一个预测问题来处理：将数据分为正常数据和缺失数据，对有值的数据采用随机森林等方法拟合，然后对有缺失值的数据进行预测，用预测的值来填充。

### 关联规则挖掘的 3 个度量指标：支持度、置信度、提升度

**支持度**（Support）

- X → Y 的支持度表示项集 {X,Y} 在总项集中出现的概率
  $$
  \text { Support }(X \rightarrow Y)=\frac{P(X \cup Y)}{P(I)}=\frac{\operatorname{num}(X \cup Y)}{\operatorname{num}(I)}
  $$

**置信度**（Confidence）

- X → Y 的置信度表示在先决条件 X 发生的情况下，由规则 X → Y 推出 Y 的概率。

$$
\text { Con fidence }(X \rightarrow Y)=P(Y | X)=\frac{P(X \cup Y)}{P(X)}=\frac{\operatorname{num}(X \cup Y)}{\operatorname{num}(X)}
$$

**提升度**（Lift）

- X → Y 的提升度表示含有X的条件下，同时含有Y的概率，与Y总体发生的概率之比。

$$
\begin{aligned} \operatorname{Lift}(X \rightarrow Y) &=\frac{P(Y | X)}{P(Y)}=\frac{\text { Con fidence }(X \rightarrow Y)}{\operatorname{num}(Y) / \operatorname{num}(I)} \\ &=\frac{P(X \cup Y)}{P(X) P(Y)}=\frac{\operatorname{num}(X \cup Y) \operatorname{num}(I)}{\operatorname{num}(X) \operatorname{num}(Y)} \end{aligned}
$$

### 规则的有效性：

- 满足最小支持度和最小置信度的规则，叫做“强关联规则”

  > 最小支持度和最小置信度是人工设置的阈值

- `Lift(X→Y) > 1` 的 X→Y 是有效的强关联规则

- `Lift(X→Y) <=1` 的 X→Y 是无效的强关联规则

- 特别地，`Lift(X→Y) = 1` 时，X 与 Y 相互独立。

### **判断规则的有效性**

问题：已知有1000名顾客买年货，分为甲乙两组，每组各500人，其中甲组有500人买了茶叶，同时又有450人买了咖啡；乙组有450人买了咖啡，如表所示，请问“茶叶→咖啡”是一条有效的关联规则吗？

| 组次          | 买茶叶的人数 | 买咖啡的人数 |
| ------------- | ------------ | ------------ |
| 甲组（500人） | 500          | 450          |
| 乙组（500人） | 0            | 450          |

答：

- “茶叶→咖啡”的支持度：Support(X→Y) = 450 / 1000 = 45%
- “茶叶→咖啡”的置信度：Confidence(X→Y) = 450 / 500 = 90%
- “茶叶→咖啡”的提升度：Lift(X→Y) = 90% / 90% = 1

由于提升度 `Lift(X→Y) = 1`，表示 X 与 Y 相互独立。也就是说，是否购买咖啡，与是否购买茶叶无关联。规则“茶叶→咖啡”不成立，或者说几乎没有关联，虽然它的置信度高达90%，但它不是一条有效的关联规则。

## 机器学习算法

- 基本遵从《统计学习方法》一书中的符号表示。

- 除特别说明，默认`w`为行向量，`x`为列向量，以避免在`wx`中使用转置符号；但有些公式为了更清晰区分向量与标量，依然会使用`^T`的上标，注意区分。

  输入实例`x`的特征向量记为：
  $$
  x=\left(x^{(1)}, x^{(2)}, \cdots, x^{(n)}\right)^{T}
  $$

注意：`x_i` 和 `x^(i)` 含义不同，前者表示训练集中第 i 个实例，后者表示特征向量中的第 i 个分量；因此，通常记训练集为：
$$
T=\left\{\left(x_{1}, y_{1}\right),\left(x_{2}, y_{2}\right), \cdots,\left(x_{N}, y_{N}\right)\right\}
$$

>  特征向量用小`n`表示维数，训练集用大`N`表示个数

### 信息论

* 信息论的基本思想：一件不太可能的事发生，要比一件非常可能的事发生，提供更多的信息。

* 该想法可描述为以下性质：
  1. 非常可能发生的事件信息量要比较少，并且极端情况下，一定能够发生的事件应该没有信息量。
  2. 比较不可能发生的事件具有更大的信息量。
  3. 独立事件应具有增量的信息。例如，投掷的硬币两次正面朝上传递的信息量，应该是投掷一次硬币正面朝上的信息量的两倍。

### 信息熵

信息熵可以参照第一章中的内容

### 逻辑回归

#### 逻辑回归模型定义

**二项**逻辑回归模型即如下的**条件概率分布**
$$
\begin{array}{l}{P(Y=1 | x)=\frac{\exp (w x)}{1+\exp (w x)}=\frac{1}{1+\exp (-w x)}} \\ {P(Y=0 | x)=1-P(Y=1 | x)}\end{array}
$$

#### 逻辑回归的推导

逻辑回归推导的关键点 (3)

1. 逻辑回归的定义
2. 损失函数（极大似然）
3. 参数优化（梯度下降）

1. **逻辑斯蒂回归**的定义：
   $$
   \begin{aligned} P(Y&=1 | x )=\frac{1}{1+\exp (-w x)}=\sigma(x) \\ P(Y&=0 | x )=1-\sigma(x) \end{aligned}
   $$

2. **负对数函数**作为损失函数：
   $$
   \begin{aligned} L(w) &=-\log \left(\prod_{i=1}^{N}\left[\sigma\left(x_{i}\right)\right]^{y_{i}}\left[1-\sigma\left(x_{i}\right)\right]^{1-y_{i}}\right) \\ &=-\sum_{i=1}^{N}\left[y_{i} \log \sigma\left(x_{i}\right)+\left(1-y_{i}\right) \log \left(1-\sigma\left(x_{i}\right)\right)\right] \\ &=-\sum_{i=1}^{N}\left[y_{i} \log \frac{\sigma\left(x_{i}\right)}{1-\sigma\left(x_{i}\right)}+\log \left(1-\sigma\left(x_{i}\right)\right)\right] \end{aligned}
   $$

进一步代入 `σ(x)` 有：
$$
L(w)=-\sum_{i=1}^{N}\left[y_{i}\left(w x_{i}\right)-\log \left(1+\exp \left(w x_{i}\right)\right)\right]
$$

3. 求梯度
   $$
   \begin{aligned} \frac{\partial L(w)}{\partial w} &=-\sum_{i=1}^{N}\left[y_{i} x_{i}-\frac{\exp \left(w x_{i}\right)}{1+\exp \left(w x_{i}\right)} x_{i}\right] \\ &=\sum_{i=1}^{N}\left[\sigma\left(x_{i}\right)-y_{i}\right] x_{i} \end{aligned}
   $$

#### 多分类逻辑回归

* 设$Y \in\{1,2, \ldots \mathrm{K}\}$，则多项式逻辑回归模型为
  $$
  \begin{aligned} P(Y=k | x) &=\frac{\exp \left(w_{k} x\right)}{1+\sum_{k=1}^{K-1} \exp \left(w_{k} x\right)} \quad k=1,2, \ldots, K-1 \\ P(Y=K | x) &=\frac{1}{1+\sum_{k=1}^{K-1} \exp \left(w_{k} x\right)} \end{aligned}
  $$

最终推出来softmax回归
$$
h_{\theta}\left(x^{(i)}\right)=\left[ \begin{array}{c}{p\left(y^{(i)}=1 | x^{(i)} ; \theta\right)} \\ {p\left(y^{(i)}=2 | x^{(i)} ; \theta\right)} \\ {\vdots} \\ {p\left(y^{(i)}=k | x^{(i)} ; \theta\right)}\end{array}\right]=\frac{1}{\sum_{j=1}^{k} e^{\theta_{j}^{T} x^{(i)}}} \left[ \begin{array}{c}{e^{\theta_{1}^{T} x^{(i)}}} \\ {e^{\theta_{2}^{T} x^{(i)}}} \\ {\vdots} \\ {e^{\theta_{k}^{T} x^{(i)}}}\end{array}\right]
$$
定义了新的假设函数（hypothesis function）之后，我们要得到其对应的代价函数（cost function）。
$$
J(\theta)=-\frac{1}{m}\left[\sum_{i=1}^{m} \sum_{j=1}^{k} 1\left\{y^{(i)}=j\right\} \log \frac{e^{\theta_{j}^{T} x^{(i)}}}{\sum_{l=1}^{k} e^{\theta_{l}^{T} x^{(i)}}}\right]
$$
其中 ![1\left\{ \cdot \right\}](https://www.zhihu.com/equation?tex=1%5Cleft%5C%7B+%5Ccdot+%5Cright%5C%7D) 的取值规则为大括号内的表达式值为真时，取 1，为假时取 0。

对该代价函数求最优解同样可以使用如梯度下降之类的迭代算法，其梯度公式如下：
$$
\nabla_{\theta_{j}} J(\theta)=(-\frac{1}{m}\left[\sum_{i=1}^{m} \sum_{j=1}^{k} 1\left\{y^{(i)}=j\right\} \log \frac{e^{\theta_{j}^{T} x^{(i)}}}{\sum_{l=1}^{k} e^{\theta_{l}^{T} x^{(i)}}}\right])'\\
=(-\frac{1}{m}\left[\sum_{i=1}^{m} \sum_{j=1}^{k} 1\left\{y^{(i)}=j\right\} (\log e^{\theta_{j}^{T} x^{(i)}}-\log {\sum_{l=1}^{k} e^{\theta_{l}^{T} x^{(i)}}})\right])'\\
=(-\frac{1}{m}\left[\sum_{i=1}^{m} \sum_{j=1}^{k} 1\left\{y^{(i)}=j\right\} (\theta_{j}^{T} x^{(i)}-\log {\sum_{l=1}^{k} e^{\theta_{l}^{T} x^{(i)}}})\right])'\\
\\
=-\frac{1}{m}\left[\sum_{i=1}^{m} \sum_{j=1}^{k} 1\left\{y^{(i)}=j\right\} (x^{(i)}-(\log {\sum_{l=1}^{k} e^{\theta_{l}^{T} x^{(i)}}})')\right]
\\
==-\frac{1}{m}\left[\sum_{i=1}^{m} \sum_{j=1}^{k} 1\left\{y^{(i)}=j\right\} (x^{(i)}-\frac{x^{(i)}*e^{\theta_{l}^{T} x^{(i)}}}{\log {\sum_{l=1}^{k} e^{\theta_{l}^{T} x^{(i)}}}})\right]
\\
=-\frac{1}{m} \sum_{i=1}^{m}\left[x^{(i)}\left(1\left\{y^{(i)}=j\right\}-p\left(y^{(i)}=j | x^{(i)} ; \theta\right)\right)\right]
$$
有了偏导数，就可以对代价函数进行优化，最终求解。

### 支持向量机

- 支持向量机（Support Vector Machines, SVM）是一种二分类模型。它的**基本模型**是定义在特征空间上的**间隔最大**的线性分类器，间隔最大使它有别于感知机；支持向量机还包括**核技巧**，这使其成为实质上的非线性分类器。
- **SVM 的学习策略就是间隔最大化**，可形式化为一个求解**凸二次规划**的问题，也等价于正则化的**合页损失函数**的最小化问题。
- SVM 的最优化算法是求解凸二次规划的最优化算法。

#### 什么是支持向量

- 训练数据集中与分离超平面距离最近的样本点的实例称为支持向量（离超平面最近的点就是支持向量，包括正类和负类各自离超平面最近的点）
- 更通俗的解释：
  - 数据集种的某些点，位置比较特殊。比如 `x+y-2=0` 这条直线，假设出现在直线上方的样本记为 A 类，下方的记为 B 类。
  - 在寻找找这条直线的时候，一般只需看两类数据，它们各自最靠近划分直线的那些点，而其他的点起不了决定作用。
  - 这些点就是所谓的“支持点”，在数学中，这些点称为**向量**，所以更正式的名称为“**支持向量**”。

#### 支持向量机的分类

- 线性可分支持向量机
  - 当训练数据**线性可分**时，通过**硬间隔最大化**，学习一个线性分类器，即线性可分支持向量机，又称**硬间隔支持向量机**。
- 线性支持向量机
  - 当训练数据**接近线性可分**时，通过**软间隔最大化**，学习一个线性分类器，即线性支持向量机，又称**软间隔支持向量机**。
- 非线性支持向量机
  - 当训练数据**线性不可分**时，通过使用**核技巧**及软间隔最大化，学习非线性支持向量机。

#### 核函数与核技巧

- **核函数**表示将输入从输入空间映射到特征空间后得到的特征向量之间的内积

#### 支持向量机推导

* svm由简至繁包括：线性可分支持向量机，线性支持向量机，非线性支持向量机

#### 线性可分支持向量机的推导

- 当训练数据**线性可分**时，通过**硬间隔最大化**，学习一个线性分类器，即线性可分支持向量机，又称**硬间隔支持向量机**。

* 线性 SVM 的推导分为两部分
  1. 如何根据**间隔最大化**的目标导出 SVM 的**标准问题**；
  2. 拉格朗日乘子法对偶问题的求解过程.

##### **符号定义**：

* 训练集`T`

$$
T=\left\{\left(x_{1}, y_{1}\right),\left(x_{2}, y_{2}\right), \cdots,\left(x_{N}, y_{N}\right)\right\}
$$

* 分离超平面`(w,b)`：

$$
w^{*} \cdot x+b^{*}=0
$$

* 如果使用映射函数，那么分离超平面为：

$$
w^{*} \cdot \Phi(x)+b^{*}=0
$$

> 映射函数 `Φ(x)` 定义了从输入空间到特征空间的变换，特征空间通常是更高维的，甚至无穷维；方便起见，这里假设 `Φ(x)` 做的是恒等变换。

* 分类决策函数 `f(x)`

$$
f(x)=\operatorname{sign}\left(w^{*} \cdot x+b^{*}\right)
$$

##### **SVM 标准问题的推导**(2)

1. **从“函数间隔”到“几何间隔”**

给定训练集`T`和超平面`(w,b)`，定义**函数间隔**$\hat{\gamma}$：
$$
\begin{aligned} \hat{\gamma} &=\min _{i=1, \cdots, N} y_{i}\left(w x_{i}+b\right) \\ &=\min _{i=1, \cdots, N} \hat{\gamma}_{i} \end{aligned}
$$
对 `w` 作规范化，使函数间隔成为**几何间隔**$\gamma$
$$
\begin{aligned} \gamma &=\min _{i=1, \cdots, N} y_{i}\left(\frac{w}{\|w\|} x_{i}+\frac{b}{\|w\|}\right) \\ &=\min _{i=1, \cdots, N} \frac{\gamma_{i}}{\|w\|} \end{aligned}
$$

2. **最大化几何间隔**

$$
\begin{array}{ll}{\max _{w, b}} & {\gamma} \\ {\text { s.t. }} & {y_{i}\left(\frac{w}{\|w\|} x_{i}+\frac{b}{\|w\|}\right) \geq \gamma, \quad i=1,2, \cdots, N}\end{array}
$$

由函数间隔与几何间隔的关系，等价于
$$
\begin{array}{ll}{\max _{w, b}} & {\gamma} \\ {\text { s.t. }} & {y_{i}\left(\frac{w}{\|w\|} x_{i}+\frac{b}{\|w\|}\right) \geq \gamma, \quad i=1,2, \cdots, N}\end{array}
$$

