---
title: Coursera-deeplearning-ai-（二）
date: 2018-04-11 10:03:47
tags: [deeplearning,机器学习,深度学习]
category: [机器学习]
---

这篇博文主要讲的是关于deeplearning.ai的第二门课程的内容，《Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization》

<!--more-->

## Week one

### 设置训练，验证，测试集

设置神经网络时，有很多的值需要你自己设置，比如隐藏层的数量，隐藏点的个数，学习率，激活函数的类型等等……

数据通常被分为三部分：训练集，hold-out交叉验证集（或者成为开发集dev），测试集。分布如下图所示：

![](http://ooi9t4tvk.bkt.clouddn.com/18-4-11/88387245.jpg)

多年前，数据较少：70%的训练数据和30%的测试数据，或者60%训练数据，验证集和测试集各占20%

但现在数据越来越多，100w的总数据，验证集和测试集可能都只需要1w个就行了，剩下的98w数据都可以用于训练，比例为98/1/1

数据更多的时候，可能开发集和测试集所占的比例更小

#### 数据不平衡

训练集，开发集，测试集的数据分布不同，比如图片识别中，两边的数据来源不同（一边是高清图片，一边是模糊图片），这时候只需要保证**开发集和测试集在同一个分布**即可。

### 偏差方差

深度学习中有一个问题叫做“偏差-方差困境”，要在偏差和方差之间权衡

![](http://ooi9t4tvk.bkt.clouddn.com/18-4-11/22424626.jpg)

#### 如何判断是高方差还是高偏差

往往通过训练集误差和开发集误差的对比来进行判断：

* 训练集误差小，开发集误差大，证明过拟合了，高方差
* 训练集误差大，开发集误差约等于训练集误差，证明欠拟合，高偏差
* 训练集误差大，开发集误差远大于训练集，证明高偏差且高方差，这是因为在某些数据上过拟合，而在大部分数据上欠拟合
* 训练集误差小，开发集误差也很小，这就是最理想的状态

下面这个分类猫的例子比较直观解释了上面四种情况，注意，此时所谓的大小是因为我们设置的贝叶斯先验错误为0%，所以认为1%小，15%大。如果贝叶斯先验概率不是0%而是15%，那么15%的错误率也是很小的了。并且此时要求训练集和开发集的数据分布是相同的（如果一个是高质量数据，一个是低质量数据，那么两个本来错误率就不一样）。

![](http://ooi9t4tvk.bkt.clouddn.com/18-4-11/29396365.jpg)

### 机器学习的基本准则

训练好模型之后：

* 首先询问，是否存在**高偏差**（在训练集上面的表现），如果存在，那么你可以尝试使用**更大的网络**（更多层和更多隐藏点），或者尝试训练**更多的迭代次数**。尝试多种方法，直到将偏差减小到一个可以接受的范围。
* 再看看是否有较高的**方差**（在开发集上面的表现），如果存在，那么比较好的办法就是**增加训练数据**，或者是**正则化**

### 正则化

如果发现**过拟合**，那么就是方差过大，首先应该尝试的方法就是正则化

以逻辑回归为例，为了最小化代价函数$J(W,b)=\frac{1}{m}\sum_{i=1}^{m}L(\hat{y}^{(i)},y^{(i)})$，我们在后面加上一个W的范数，常用的范数为二范数，代价函数变为：

$J(W,b)=\frac{1}{m}\sum_{i=1}^{m}L(\hat{y}^{(i)},y^{(i)})+\frac{\lambda}{2m}||w||^{2}_{2}$

其中的$\lambda$是正则化参数，$||w||^{2}_{2}$称为w的二范数，$||w||^{2}_{2}=\sum_{j=1}^{n_{x}}w_j^2=w^Tw$

为什么只对w正则化而忽略b呢，这是因为在过拟合的情况下，w的维度非常大，而b只有一个参数，影响相对于w来说可以忽略

偶尔也用一范数，但很少用，具体的逻辑回归的正则化方法如下

![](http://ooi9t4tvk.bkt.clouddn.com/18-4-11/27719103.jpg)

#### 神经网络的正则化

神经网路的正则化的方法和逻辑回归基本一样，只是w的二范数成了w矩阵的元素平方和，这个值被称为Frobenius norm（弗罗贝尼乌斯范数）

在反向传播的时候，反向传播的$dw^{[l]}$就成了原本的反向传播的值（下图中间绿色方框行，由代价函数J求导得到），加上$\frac{\lambda}{m}w^{[l]}$，w的更新公式就成了这样:

$w^{[l]}=(1-\frac{\alpha\lambda}{m})w^{[l]}-\alpha(原本的反向传播值)$

所以正则化之后，每次更新相当于只是在原本的w前面乘以一个略小于1的值$1-\frac{\alpha\lambda}{m}$，再减去原本的反向传播的值，因此神经网络的正则化又被称之为权重衰减

![](http://ooi9t4tvk.bkt.clouddn.com/18-4-11/82915442.jpg)

### 为什么正则化可以消除过拟合

如图，如果过拟合，我们在加入正则化之后，如果把$\lambda$设置的非常大，那么为了是代价函数最小，w必须非常小，那么w的很多值就为0了，多层神经网络看上去就像是一个简单神经网路一样

![](http://ooi9t4tvk.bkt.clouddn.com/18-4-11/98592108.jpg)

另一个直观解释是当你使用tanh之类的激活函数的时候，当$\lambda$非常大的时候，那么w非常小，因此z也非常小，经过激活函数变化之后的a也非常小，因此a值只能在0附近变化，这一段tanh函数基本相当于一个线性函数，也就是多层神经网络变化之后基本相当于在做线性变换，就变成一个接近线性变化的值

![](http://ooi9t4tvk.bkt.clouddn.com/18-4-11/41548130.jpg)

### dropout 正则化

dropout正则化，也就是丢弃法正则化，也成为随机失活正则化。

对每个点进行抛硬币，50%的概率丢弃该点，得到一个丢弃一部分的神经网络，这个方法虽然听上去不可靠，但是实际表现却不错

随机失活正则化的实现方法：

假设有一个L=3的神经网络，先设置一个保留率keep-prob，随机产生一个3*n的矩阵，与keep-prob比较之后产生d3，让原本的w乘以这个d3，再除以一个keep-prob以消除引入随机失活的影响（因为你引入随机失活，相当于对某层的a乘以一个keep-prob，那么我要结果一样，就要除以一个keep-prob）

举个例子为什么要除以keep-prob，比如我们现在第三层有50个点，如果keep-prob为0.8的话，那么这层大概平均来说有10个点要失效，$z^{[4]}=w^{[4]}a^{[3]}+b^{[4]}$，那么此时的$a^{[3]}$的期望就变成了原来的80%，为了使得$z^{[4]}$的期望不变，我们就需要将$a^{[3]}$除以一个keep-prob来确保$z^{[4]}$期望不变。

![](http://ooi9t4tvk.bkt.clouddn.com/18-4-11/1978794.jpg)

### 随机失活正则化的理解

直观解释：因为你不知道哪一个神经元可能被丢弃，所以你不能过分依赖某个神经元，因此权重就不得不分散

在真正使用的时候，如果你担心某层容易过拟合，那么就把这一层的留存率设置的低一些；如果确认不会过拟合，那就把留存率设置接近1，比如在输入层这里留存率就应该是1

### 其它正则化方法

在图片处理的时候，如果你没有更多的数据，比如处理猫之类的：你可以将图片进行水平翻转，或者放大旋转之类的，处理数字的时候：可以扭曲加旋转

![](http://ooi9t4tvk.bkt.clouddn.com/18-4-12/9225476.jpg)

另一种方法叫做**早终止方法**（early stopping）

画出训练集的代价函数和开发集的代价函数，选择两者都还比较小的值

### 归一化（normalization）

归一化可以加速训练过程

归一化的过程：**减去均值（$x-\mu$），将方差归一化$(x-\mu)/\sigma$**

归一化过程中一定要注意，对训练集和测试集都需要归一化

### 梯度消失和梯度爆炸

比如你的激活函数是g(z)=z，然后$\hat{y}=w^{[l]}*w^{[l-1]}*...*w^{[2]}*w^{[1]}$，只要所有w都是对角矩阵，他的某一项大于1，则出现梯度爆炸，求出的梯度非常大，或者是梯度消失，求出的梯度基本为0

### 权重初始化和深度网络

特殊地初始化可以部分解决梯度爆炸和梯度消失的问题

在使用Relu激活函数的时候：

$W^{[L]}=np.random.randn(shape)*np.sqrt(1/n)$

### 梯度检验

根据导数的定义，对代价函数进行求导：

![](http://ooi9t4tvk.bkt.clouddn.com/18-4-12/31073973.jpg)

检查：两个导数之间的欧式距离/两个导数的2范数之和，如果基本等于$\epsilon$的话，那就说明正确了，如果大于$\epsilon$很多的话，就说明错了

### 梯度下降的实现

* 只在调试的时候用提督检验，在训练的时候不要用
* 如果算法梯度检验失败，检查每一个dw，db来找到程序的bug
* 记得正则化
* 在没有dropout的时候先进行梯度检验，发现算法没有问题再使用dropout
* 随机初始化可以先运行一下梯度检验

### 合适的初始化方法

He初始化方法（[He et al., 2015](https://arxiv.org/abs/1502.01852)），在激活函数是Relu的时候非常有效，具体做法是$W^{[l]}=\rm{np.random.randn}(layer\_dimension[l],layer\_dimension[l-1])*\rm{np.sqrt}(2./layer\_dimension[l-1])$

## 第二周

### 优化算法

向量化可以高效计算m个example，但是当example非常多的时候，计算起来也是非常的慢的，比如你现在有500w个example，拿计算起来就是非常慢的

为了加快计算的速度，提出了mini-batch gradient descent，也就是批量梯度下降，将数据分成一个个的小batch，然后进行前向传播，反向传播，参数更新等步骤，这样计算速度会快上很多

比如现在有500w条数据，将每1000条数据凑成一个batch，用`{}`来表示第多少个batch，现在分成了$X^{\{1\}}$到$X^{\{5000\}}$共5000个batch，每个batch的维度是$(n_x,1000)$

![](http://ooi9t4tvk.bkt.clouddn.com/18-4-28/23613139.jpg)

Y以同样的方法被分成5000份，每个$Y^{\{t\}}$的维度是(1，1000)

到目前为止，我们一共用过三种括号，分别是小括号，中括号，和大括号

* 小括号：$x^{(i)}$，表示第i个训练实例
* 中括号：$Z^{[L]}$表示第L层
* 大括号：$X^{\{t\}}$,$Y^{\{t\}}$表示第t个batch

分成batch之后的步骤和之前的神经网络的构建步骤一样，只是多了一重循环batch的for

![](http://ooi9t4tvk.bkt.clouddn.com/18-4-28/12421014.jpg)

### 理解mini-batch梯度下降

批量梯度下降的损失函数往往一直下降，但是mini-batch梯度下降存在噪声，但是整体趋势是下降的

![](http://ooi9t4tvk.bkt.clouddn.com/18-4-30/72186468.jpg)

两种极端情况：

1. 如果mini-batch的size=m，那么这就是梯度下降，梯度下降的好处是每一步迭代都是往最优值的方向去靠近，但是数据量很大的时候，批量梯度下降就会非常的慢，这种情况又被称为批梯度下降
2. 如果mini-batch的size=1，那么这种情况就是每次输入一个example，这样每次迭代的方向可能是乱的，最终的结果可能在最优值附近徘徊，这种情况又被称为随机梯度下降
3. 只有mini-batch值合适的时候，才能既用到向量化的加速运算，又能得到一个最优值

一般认为：

在m<=2000时，认为数据量足够下，可以使用批量梯度下降

在m>2000时，通常使用的mini-batch的size为64, 128, 256, 512，用2的倍数是因为内存读取的方式是通过2的倍数来读取的，这样能够加快运算

### 指数加权平均

如图，是一大堆温度数据，我们为了对温度数据做个平均，用v0=0,$v_1=0.9v_0+0.1\theta_1$，一直到$v_t=0.9v_{t-1}+0.1\theta_t$进行指数加权平均

![](http://ooi9t4tvk.bkt.clouddn.com/18-5-1/63473191.jpg)

这种指数加权平均的效果的$v_{t}$就大致等同于对$\frac{1}{1-\beta}$天的数据进行平均，其中$\beta$是$v_t=\beta v_{t-1}+(1-\beta)\theta_t$这个公式中的系数

比如，当$\beta=0.9$时，这就相当于对前10天的数据进行平均；当的$\beta=0.98$时，这就相当于对前50天的数据进行平均；当的$\beta=0.5$时，这就相当于对前2天的数据进行平均

更大的$\beta$意味着更平滑的曲线，但是对数据的延迟性也更大

### 指数加权平均的理解

通用的迭代公式：$v_t=\beta v_{t-1}+(1-\beta)\theta_t $

我们来举个例子，假如$\beta=0.9$

那么

$v_{100}=0.9 v_{99}+0.1\theta_{100}$

$v_{99}=0.9 v_{98}+0.1\theta_{99}$

$v_{98}=0.9 v_{97}+0.1\theta_{98}$

将$v_{100}=0.9 v_{99}+0.1\theta_{100}$展开可以得到

$v_{100}=0.9 v_{99}+0.1\theta_{100}=0.1\theta_{100}+0.9(0.1\theta_{99}+0.9 v_{98})=0.1\theta_{100}+0.9*0.1\theta_{99}+0.9^2(0.9 v_{97}+0.1\theta_{98})...$ 

这个过程与我们平时的平均数有类似的地方，因为我们平时求解的平均数是在每个$\theta$前面的系数相等，都是1/n，在指数加权平均的时候，将靠的近的系数放大，靠的远的系数变小，以指数形式衰减

这样下去，要使得v的加和的那一项足够小， 也就是$0.1*0.9^{t}$足够小的情况下，$0.9^{10}=1/e$，就认为是10天的平均

**指数加权平均的好处：** 

我们可以看到指数加权平均的求解过程实际上是一个递推的过程，那么这样就会有一个非常大的好处，每当我要求从0到某一时刻（n）的平均值的时候，我并不需要像普通求解平均值的作为，保留所有的时刻值，类和然后除以n。

而是只需要保留0-(n-1)时刻的平均值和n时刻的温度值即可。也就是每次只需要保留常数值，然后进行运算即可，这对于深度学习中的海量数据来说，是一个很好的减少内存和空间的做法。

### 偏差修正

因为$v_0=0$，而$v_1=0.98v_0+0.02\theta_1$，因为$v_0=0$，所以$v_1=0.02\theta_1$；$v_2=0.98v_1+0.02\theta_2$，$v_2=0.0196\theta_1+0.02\theta_2$

由于上面两个等式展现的原因，这些v的值在初始阶段都很小，为了使这些初始阶段的值可以作为平均，我们用$v_t=\frac{v_t}{1-\beta^t}$来进行偏差修正，如下图

![](http://ooi9t4tvk.bkt.clouddn.com/18-5-2/83045151.jpg)

### 动量(Momentum)梯度下降

动量梯度下降比普通的梯度下降更快，其主要思想是：计算梯度的指数加权平均，使用这个梯度来更新权重

实现的方式如下，$\beta$参数最常用的值就是0.9：

![](http://ooi9t4tvk.bkt.clouddn.com/18-5-2/7255551.jpg)

进行动量梯度下降之后，纵轴上的偏差被减小了，得到如下图红线的效果

![](http://ooi9t4tvk.bkt.clouddn.com/18-5-2/48630632.jpg)

### RMSprop(Root Mean Square prop)算法

实现的方法和momentum类似，但是公式变成了

$S_{dw}=\beta_2S_{dw}+(1-\beta_2)dw^{2}$

$S_{db}=\beta_2S_{db}+(1-\beta_2)db^{2}$

而迭代公式变成了

$w:=w-\alpha\frac{dw}{\sqrt{S_{dw}}+\epsilon}$

$b:=b-\alpha\frac{dw}{\sqrt{S_{db}}+\epsilon}$

加一个$\epsilon$是为了不出现除以0的情况

![](http://ooi9t4tvk.bkt.clouddn.com/18-5-2/46166279.jpg)

### Adam(Adaptive moment estimation) 优化算法

Adam(Adaptive moment estimation)的意思是：适应性矩优化，这里的矩指的是一阶矩，二阶矩那个矩。

Adam就是将momentum和RMSprop结合起来

实现方法如下图，注意这里的参数都需要修正偏差：

![](http://ooi9t4tvk.bkt.clouddn.com/18-5-2/70350494.jpg)

里面的超参，一般来说momentum的超参$\beta_1=0.9$，RMSprop的超参$\beta_2=0.999$，$\epsilon=10^{-8}$，学习率$\alpha$ 是需要去调整的参数，Adam的公式如下，将w换成b则得到b的更新公式

$$
\begin{cases}
v_{dW^{[l]}} = \beta_1 v_{dW^{[l]}} + (1 - \beta_1) \frac{\partial \mathcal{J} }{ \partial W^{[l]} } \\

v^{corrected}_{dW^{[l]}} = \frac{v_{dW^{[l]}}}{1 - (\beta_1)^t} \\
s_{dW^{[l]}} = \beta_2 s_{dW^{[l]}} + (1 - \beta_2) (\frac{\partial \mathcal{J} }{\partial W^{[l]} })^2 \\
s^{corrected}_{dW^{[l]}} = \frac{s_{dW^{[l]}}}{1 - (\beta_2)^t} \\
W^{[l]} = W^{[l]} - \alpha \frac{v^{corrected}_{dW^{[l]}}}{\sqrt{s^{corrected}_{dW^{[l]}}} + \varepsilon}
\end{cases}
$$


### 学习率衰减

我们用下面的公式来衰减学习率$\alpha$：

$\alpha=\frac{1}{1+decay\_rate\times epoch\_num}\alpha_0$

decay_rate是这里的下降率，epoch_num是迭代的次数

### 局部最优解

在二维图像中，很容易产生局部最优解，但是在高维的时候，你要找到一个这个点在所有维度上梯度都为0，这是非常困难的，我们称这种有部分维度梯度为0的点为鞍点，因为图形的形状就好像马鞍一样







