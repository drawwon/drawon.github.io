<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[staticmethod和classmethod]]></title>
    <url>%2F2018%2F09%2F13%2Fstaticmethod%E5%92%8Cclassmethod%2F</url>
    <content type="text"><![CDATA[一般来说，要使用某个类的方法，需要先实例化一个对象再调用方法。 而使用@staticmethod或@classmethod，就可以不需要实例化，直接类名.方法名()来调用。 这有利于组织代码，把某些应该属于某个类的函数给放到那个类里去，同时有利于命名空间的整洁。 既然@staticmethod和@classmethod都可以直接类名.方法名()来调用，那他们有什么区别呢 从它们的使用上来看, @staticmethod不需要表示自身对象的self和自身类的cls参数，就跟使用函数一样。 @classmethod也不需要self参数，但第一个参数需要是表示自身类的cls参数。 如果在@staticmethod中要调用到这个类的一些属性方法，只能直接类名.属性名或类名.方法名。 而@classmethod因为持有cls参数，可以来调用类的属性，类的方法，实例化对象等，避免硬编码。 下面上代码。 12345678910111213141516class A(object): bar = 1 def foo(self): print 'foo' @staticmethod def static_foo(): print 'static_foo' print A.bar @classmethod def class_foo(cls): print 'class_foo' print cls.bar cls().foo()A.static_foo()A.class_foo() 输出 12345static_foo1class_foo1foo 再看一个例子，是classmethod用于处理init的重构问题的： 看下面的定义的一个时间类： 12345678910111213141516171819class Data_test(object): day=0 month=0 year=0 def __init__(self,year=0,month=0,day=0): self.day=day self.month=month self.year=year def out_date(self): print "year :" print self.year print "month :" print self.month print "day :" print self.dayt=Data_test(2016,8,1)t.out_date() 输出： 123456year :2016month :8day :1 符合期望。 如果用户输入的是 “2016-8-1” 这样的字符格式，那么就需要调用Date_test 类前做一下处理： 123string_date='2016-8-1'year,month,day=map(int,string_date.split('-'))s=Data_test(year,month,day) 先把‘2016-8-1’ 分解成 year，month，day 三个变量，然后转成int，再调用Date_test(year,month,day)函数。 也很符合期望。 那我可不可以把这个字符串处理的函数放到 Date_test 类当中呢？ 那么@classmethod 就开始出场了 123456789101112131415161718192021222324class Data_test2(object): day=0 month=0 year=0 def __init__(self,year=0,month=0,day=0): self.day=day self.month=month self.year=year @classmethod def get_date(cls,string_date): #这里第一个参数是cls， 表示调用当前的类名 year,month,day=map(int,string_date.split('-')) date1=cls(year,month,day) #返回的是一个初始化后的类 return date1 def out_date(self): print "year :" print self.year print "month :" print self.month print "day :" print self.day 在Date_test类里面创建一个成员函数， 前面用了@classmethod装饰。 它的作用就是有点像静态类，比静态类不一样的就是它可以传进来一个当前类作为第一个参数。 那么如何调用呢？ 12r=Data_test2.get_date("2016-8-6")r.out_date() 输出： 123456year :2016month :8day :1]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker常用命令]]></title>
    <url>%2F2018%2F09%2F09%2Fdocker%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[从docker hub下载一个image 1docker pull name:version 运行一个docker，开启其bash 1docker run -it ubuntu:18.04 bash 其中-i表示交互式，-t表示建立一个虚拟的terminal 继续运行一个已经退出的docker 12docker start `docker ps -q -l` # restart it in the backgrounddocker attach `docker ps -q -l` # reattach the terminal &amp; stdin exec 命令-i -t 参数docker exec 后边可以跟多个参数，这里主要说明 -i -t 参数。 只用 -i 参数时，由于没有分配伪终端，界面没有我们熟悉的 Linux 命令提示符，但命令执行结果仍然可以返回。 当 -i -t 参数一起使用时，则可以看到我们熟悉的 Linux 命令提示符。 12345678910111213141516$ docker run -dit ubuntu69d137adef7a8a689cbcb059e94da5489d3cddd240ff675c640c8d96e84fe1f6$ docker container lsCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES69d137adef7a ubuntu:latest &quot;/bin/bash&quot; 18 seconds ago Up 17 seconds zealous_swirles$ docker exec -i 69d1 bashlsbinbootdev...$ docker exec -it 69d1 bashroot@69d137adef7a:/# 如果从这个 stdin 中 exit，不会导致容器的停止。这就是为什么推荐大家使用 docker exec 的原因。 更多参数说明请使用 docker exec --help 查看。 结束正在运行的docker1docker container kill `docker container ls -q` exec正在运行的docker1docker exec -it `docker container ls -q` bash 运行某个docker并添加端口映射1docker run -itd -p 13389:3389 -p 10022:22 drawon/ubuntu-mate-xrdp DOCKER 给运行中的容器添加映射端口 方法1 1、获得容器IP 将container_name 换成实际环境中的容器名 1docker inspect `container_name` | grep IPAddress 2、 iptable转发端口 将容器的8000端口映射到docker主机的8001端口 复制代码代码如下: iptables -t nat -A DOCKER -p tcp —dport 8001 -j DNAT —to-destination 172.17.0.19:8000 方法2 1.提交一个运行中的容器为镜像 1docker commit containerid foo/live 2.运行镜像并添加端口 1docker run -d -p 8000:80 foo/live /bin/bash]]></content>
  </entry>
  <entry>
    <title><![CDATA[leetcode-22解答]]></title>
    <url>%2F2018%2F08%2F27%2Fleetcode-22%E8%A7%A3%E7%AD%94%2F</url>
    <content type="text"><![CDATA[给定一个值n，要求能生成n对括号的组合数，题目具体如下： Given n pairs of parentheses, write a function to generate all combinations of well-formed parentheses. For example, given n = 3, a solution set is: 1234567[ &quot;((()))&quot;, &quot;(()())&quot;, &quot;(())()&quot;, &quot;()(())&quot;, &quot;()()()&quot;] 方法一：暴力求解把所有有可能的情况全部列出来，判断是否符合要求，符合的留下： 12345678910111213141516171819202122232425class Solution: def generateParenthesis(self, n): """ :type n: int :rtype: List[str] """ def is_valid(str_list): count=0 for i in str_list: if i=='(':count+=1 else:count-=1 if count&lt;0:return False return count==0 res = ["("] for i in range(2*n-1): cur_res = [] for j in res: cur_res.append(j+'(') cur_res.append(j+')') res = cur_res fin = [] for i in res: if is_valid(i): fin.append(i) return fin 方法二：递归12345678910111213141516171819202122232425class Solution(object): def generateParenthesis(self, n): def generate(A = []): if len(A) == 2*n: if valid(A): ans.append("".join(A)) else: A.append('(') generate(A) A.pop() A.append(')') generate(A) A.pop() def valid(A): bal = 0 for c in A: if c == '(': bal += 1 else: bal -= 1 if bal &lt; 0: return False return bal == 0 ans = [] generate() return ans 方法三：回溯只加那些可能是正确的情况，不像前面两种方法枚举所有情况 1234567891011121314class Solution(object): def generateParenthesis(self, N): ans = [] def backtrack(S = '', left = 0, right = 0): if len(S) == 2 * N: ans.append(S) return if left &lt; N: backtrack(S+'(', left+1, right) if right &lt; left: backtrack(S+')', left, right+1) backtrack() return ans]]></content>
      <categories>
        <category>算法</category>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu彻底删除软件包]]></title>
    <url>%2F2018%2F08%2F22%2FUbuntu%E5%BD%BB%E5%BA%95%E5%88%A0%E9%99%A4%E8%BD%AF%E4%BB%B6%E5%8C%85%2F</url>
    <content type="text"><![CDATA[在删除apt安装的软件过程中，如果直接用apt remove，那么只是删除了软件本身，但是没有删除相关的配置，要删除相关的配置，就要用apt purge 下面是详细的apt相关的卸载方法 apt-get的卸载相关的命令有remove/purge/autoremove/clean/autoclean等。具体来说： apt-get purge / apt-get —purge remove删除已安装包（不保留配置文件)。如软件包a，依赖软件包b，则执行该命令会删除a，而且不保留配置文件 apt-get autoremove删除为了满足依赖而安装的，但现在不再需要的软件包（包括已安装包），保留配置文件。 apt-get remove删除已安装的软件包（保留配置文件），不会删除依赖软件包，且保留配置文件。 apt-get autocleanAPT的底层包是dpkg, 而dpkg 安装Package时, 会将 *.deb 放在 /var/cache/apt/archives/中，apt-get autoclean 只会删除 /var/cache/apt/archives/ 已经过期的deb。 apt-get clean使用 apt-get clean 会将 /var/cache/apt/archives/ 的 所有 deb 删掉，可以理解为 rm /var/cache/apt/archives/*.deb。 那么如何彻底卸载软件呢？具体来说可以运行如下命令： 123456# 删除软件及其配置文件apt-get --purge remove &lt;package&gt;# 删除没用的依赖包apt-get autoremove &lt;package&gt;# 此时dpkg的列表中有“rc”状态的软件包，可以执行如下命令做最后清理：dpkg -l |grep ^rc|awk &apos;&#123;print $2&#125;&apos; |sudo xargs dpkg -P123456 当然如果要删除暂存的软件安装包，也可以再使用clean命令]]></content>
      <categories>
        <category>Linux</category>
        <category>Ubuntu</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ResNet50 Transfer Learning]]></title>
    <url>%2F2018%2F08%2F11%2FResNet50-Transfer-Learning%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[keras TensorFlow 搭建验证码识别系统]]></title>
    <url>%2F2018%2F08%2F11%2Fkeras-TensorFlow-%E6%90%AD%E5%BB%BA%E9%AA%8C%E8%AF%81%E7%A0%81%E8%AF%86%E5%88%AB%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[keras整体来说是一个非常简单易用的框架，搭建一个网络非常地快捷和方便，这篇博客主要是记录之前用keras搭建的一个cnn识别验证码的步骤。 数据生成首先用ImageCaptcha这个库来生成验证码，这里有两种生成的方式，一种是直接生成很多张，放在电脑中，然后每次读一部分进来进行训练，还有一种方式就是用生成器的方式来生成数据，然后用keras model的fit_generator方法进行训练。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263from captcha.image import ImageCaptchaimport matplotlib.pyplot as pltimport numpy as npimport random,osimport tensorflow as tf%matplotlib inline%config InlineBackend.figure_format = 'retina'import kerasfrom keras import backend as Kfrom keras_tqdm import TQDMNotebookCallbackimport stringcharacters = string.digits + string.ascii_uppercase# print(characters)width, height, n_len, n_class = 160, 80, 4, len(characters)generator = ImageCaptcha(width=width, height=height)# for i in range(1000):# random_str = ''.join([random.choice(characters) for j in range(4)])# img = generator.generate_image(random_str)# img.save('./pic/'+str(i) +'_'+ random_str + '.jpg')imgs = []labels =[]temp = [[] for i in range(4)]# 处理生成的数据，通过opencv的二值化和高斯模糊函数来去噪声def deal_img(img):# img = load_img(path,grayscale=True) kernel = np.ones((3,1), np.uint8) img = img_to_array(img).astype(np.uint8) img = cv.cvtColor(img, cv.COLOR_BGR2GRAY) # img= cv.bilateralFilter(img,9,75,75)# img = cv.Canny(img, 100, 200) blur = cv.GaussianBlur(img, (5, 5), 0) _, img = cv.threshold(blur, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU) img = cv.dilate(img, kernel, iterations=1) img = cv.erode(img, kernel, iterations=1) return img.reshape(height,width,1)# 数据生成器，每次生成batch_size张图片# 输出的y的格式是[144,1]def gen(batch_size=32): while True: imgs=[] labels = [] for i in range(batch_size): random_str = ''.join([random.choice(characters) for j in range(4)]) img = generator.generate_image(random_str) img = deal_img(img) imgs.append(img) y=np.zeros((len(characters)*4)) for i,char in enumerate(random_str): y[characters.find(char)+i*len(characters)] = 1 labels.append(y) train_x = np.array(imgs) train_y = np.array(labels) yield train_x, train_y 网络构建构建一个类似于vgg16的网络 12345678910111213141516171819from keras.preprocessing.image import img_to_array,load_imgimport numpy as npfrom keras.layers import *from keras.models import Modelimport cv2 as cv# 构建类似于vgg16的网络结构input_tensor = Input(shape=(height, width, 1))x = input_tensorfor i in range(4): x = Conv2D(32*2**i, (3, 3), activation='relu')(x) x = Conv2D(32*2**i, (3, 3), activation='relu')(x) x = MaxPooling2D((2, 2))(x)x = Flatten()(x)x = Dropout(0.25)(x)x = [Dense(n_class, activation='softmax', name='c%d'%(i+1))(x) for i in range(4)]x = concatenate(x)model = Model(inputs=input_tensor, outputs=x) 我们来看看模型的结构，画出模型结构图，在使用plot_model之前要先pip install pydot-ng &amp; apt install graphviz 123from keras.utils import plot_modelplot_model(model, to_file='model.png')model.summary() 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849model.summary()___________________________________________________________________________________Layer (type) Output Shape Param # Connected to ================================================================================================input_1 (InputLayer) (None, 80, 160, 1) 0 ________________________________________________________________________________________________conv2d_1 (Conv2D) (None, 78, 158, 32) 320 input_1[0][0] ________________________________________________________________________________________________conv2d_2 (Conv2D) (None, 76, 156, 32) 9248 conv2d_1[0][0] ________________________________________________________________________________________________max_pooling2d_1 (MaxPooling2D) (None, 38, 78, 32) 0 conv2d_2[0][0] ________________________________________________________________________________________________conv2d_3 (Conv2D) (None, 36, 76, 64) 18496 max_pooling2d_1[0][0] ________________________________________________________________________________________________conv2d_4 (Conv2D) (None, 34, 74, 64) 36928 conv2d_3[0][0] ________________________________________________________________________________________________max_pooling2d_2 (MaxPooling2D) (None, 17, 37, 64) 0 conv2d_4[0][0] ________________________________________________________________________________________________conv2d_5 (Conv2D) (None, 15, 35, 128) 73856 max_pooling2d_2[0][0] ________________________________________________________________________________________________conv2d_6 (Conv2D) (None, 13, 33, 128) 147584 conv2d_5[0][0] _______________________________________________________________________________________________max_pooling2d_3 (MaxPooling2D) (None, 6, 16, 128) 0 conv2d_6[0][0] ________________________________________________________________________________________________conv2d_7 (Conv2D) (None, 4, 14, 256) 295168 max_pooling2d_3[0][0] ________________________________________________________________________________________________conv2d_8 (Conv2D) (None, 2, 12, 256) 590080 conv2d_7[0][0] ________________________________________________________________________________________________max_pooling2d_4 (MaxPooling2D) (None, 1, 6, 256) 0 conv2d_8[0][0] ________________________________________________________________________________________________flatten_1 (Flatten) (None, 1536) 0 max_pooling2d_4[0][0] ________________________________________________________________________________________________dropout_1 (Dropout) (None, 1536) 0 flatten_1[0][0] ________________________________________________________________________________________________c1 (Dense) (None, 36) 55332 dropout_1[0][0] ________________________________________________________________________________________________c2 (Dense) (None, 36) 55332 dropout_1[0][0] ________________________________________________________________________________________________c3 (Dense) (None, 36) 55332 dropout_1[0][0] ________________________________________________________________________________________________c4 (Dense) (None, 36) 55332 dropout_1[0][0] ________________________________________________________________________________________________concatenate_1 (Concatenate) (None, 144) 0 c1[0][0] c2[0][0] c3[0][0] c4[0][0] ================================================================================================Total params: 1,393,008Trainable params: 1,393,008Non-trainable params: 0_______________________________________________________________________________________________ 定义loss和acc这里的loss不能用系统自带的几个loss和acc，因为我们这里是分4个字符的验证码，不是一个分对了就是对，而是四个都对了才是对 123456789101112131415161718192021222324252627282930313233tf_session = K.get_session()def my_acc(y_true, y_pred): predict = tf.reshape(y_pred, [-1, n_len, len(characters)]) max_idx_p = tf.argmax(predict, -1) max_idx_l = tf.argmax(tf.reshape(y_true, [-1,n_len, len(characters)]), -1) print(K.int_shape(max_idx_p)) print(K.int_shape(max_idx_l)) correct_pred = tf.reduce_all(tf.equal(max_idx_p, max_idx_l),axis=1) return tf.reduce_mean(tf.cast(correct_pred, tf.float32))def my_loss(y_true, y_pred): loss = tf.zeros((1,)) for i in range(n_len): a = tf.reshape(y_pred[:,i*36:(i+1)*36],shape=(-1,36)) b = tf.reshape(y_true[:,i*36:(i+1)*36],shape=(-1,36)) loss = tf.add(loss,tf.keras.losses.categorical_crossentropy(b,a)) return loss model.compile(loss = my_loss, optimizer='adam', metrics=[my_acc,'acc'])checkpointer = keras.callbacks.ModelCheckpoint(filepath='output/weight.h5',#"output/weights.&#123;epoch:02d&#125;--&#123;val_loss:.2f&#125;-&#123;val_my_acc:.4f&#125;.hdf5", verbose=2, save_weights_only=True)model.fit_generator(gen(32),steps_per_epoch=15000,epochs=1,verbose=1,validation_data=gen(100),validation_steps=1,callbacks=[checkpointer])(None, 4)(None, 4)Epoch 1/115000/15000 [==============================] - 13561s 904ms/step - loss: 0.4114 - my_acc: 0.9086 - acc: 0.3406 - val_loss: 0.6470 - val_my_acc: 0.8500 - val_acc: 0.3700Epoch 00001: saving model to output/weight.h5 至此，模型训练结束，你可以生成更多的数据来训练一次达到更高的模型精度 测试模型精度123456789101112131415def decode_str(result): strings =[] for s in range(result.shape[0]): string = [characters[result[s,i*len(characters):(i+1)*len(characters)].argmax()] for i in range(n_len)] strings.append(string) return [''.join(string) for string in strings]x,y = next(gen(1000))true_label = decode_str(y)score = model.evaluate(x,y,verbose=2)result = model.predict(x,verbose=2)#最后得出的精度值为93.3%score[0.3298118329048157, 0.933, 0.298] 问题解决一开始随便搭建了一个conv加dense层组合的网络，效果很差，所以还是要用一些成熟的网络。还有一个问题就是loss不下降，这个问题的原因是一开始用的adam optimizer，step设置得太小了，后来用了adadelta，step的初始值就是1，这样下降很快，效果提升就比较明显。]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[批量kill Linux进程]]></title>
    <url>%2F2018%2F07%2F08%2F%E6%89%B9%E9%87%8Fkill-Linux%E8%BF%9B%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[有时候因为一些情况，需要把 linux 下符合某一项条件的所有进程 kill 掉，又不能用 killall 直接杀掉某一进程名称包含的所有运行中进程（我们可能只需要杀掉其中的某一类或运行指定参数命令的进程），这个时候我们需要运用 ps, grep, cut 和 kill 一起操作。 ok，下面给出具体的参考： 1ps -ef|grep LOCAL=NO|grep -v grep|cut -c 9-15|xargs kill -9 运行这条命令将会杀掉所有含有关键字”LOCAL=NO”的进程，是不是很方便？ 下面将这条命令作一下简单说明： 管道符”|”用来隔开两个命令，管道符左边命令的输出会作为管道符右边命令的输入。 “ps -ef” 是linux里查看所有进程的命令。这时检索出的进程将作为下一条命令”grep LOCAL=NO”的输入。 “grep LOCAL=NO” 的输出结果是，所有含有关键字”LOCAL=NO”的进程。 “grep -v grep” 是在列出的进程中去除含有关键字”grep”的进程。 “cut -c 9-15” 是截取输入行的第9个字符到第15个字符，而这正好是进程号PID。 “xargs kill -9” 中的 xargs 命令是用来把前面命令的输出结果（PID）作为”kill -9”命令的参数，并执行该命令。”kill -9”会强行杀掉指定进程。 其它类似的情况，只需要修改”grep LOCAL=NO”中的关键字部分就可以了。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[thinking in java读书笔记]]></title>
    <url>%2F2018%2F06%2F24%2Fthinking-in-java%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[基础语法大多数语法与c++相似，只记录部分不熟悉的或者是不一样的语法。 static关键字 static的作用是，用static修饰的部分，不需要实例化类，可以直接通过类名+”.”来使用 static还可以用来修饰变量，如果被static修饰之后，在内存中只有一个拷贝，只分配一次内存，没有用static修饰的在内存中有多个拷贝，每次new都会分配一个新地址 运算符 ^：异或操作符 &amp;和&amp;&amp;符号的区别：&amp;符号两边的运算都要执行，&amp;&amp;只有在左边条件为真的时候才执行，例如if(str!=null &amp;&amp; !&quot;&quot;.equals(str))： 用&amp;&amp;的时候，此时如果str!=null，右边的!&quot;&quot;.equals(str)会被执行，如果此时str=null，那么右边的!&quot;&quot;.equals(str)不会被执行； 如果用&amp;：不管str!=null的结果如何，后面的!&quot;&quot;.equals(str)都会被执行 &gt;&gt;&gt;：无符号右移操作 foreach如果要遍历一个数组，可以使用在java SE5中引入的foreach方法：for(int i : range(10)) 12345678Random rand = new Random();float f[] = new float[10];for(int i = 0;i &lt; 10; i++)&#123; f[i] = rand.nextFloat();&#125;for (float x: f)&#123; System.out.println(x);&#125; 构造器和垃圾回收器构造器构造器就相当于js当中的构造函数，python中的__init__函数，在java当中构造器的名称就是和类名相同的一个函数 12345class Rock2&#123; Rock2(int i)&#123; System.out.println('Rock' + i); &#125;&#125; 方法重载方法重载就是同一个函数，在其参数不同的时候执行不同的函数的过程，比如： 12345678910class Tree&#123; int height; Tree()&#123; System.out.println("a seed") &#125; Tree(int initialHeight)&#123; height = initialHeight; System.out.println("a tree high is" + height); &#125;&#125; 在构造函数中调用构造函数一个class可以有多个构造函数，还可以在某个构造函数中调用另一个构造函数，调用的方法是用this(构造参数)来实现的，注意：在一个构造其中最多只能调用一次别的构造函数，因为某个class只能被构造一次。且只能在构造函数中调用构造函数，还要在构造函数的最前面调用。 1234567891011121314151617181920212223242526272829class Flower &#123; int petalCount = 0; String s = "initial string"; private Flower(int petal) &#123; petalCount = petal; println("petal only constructor,petalCount=" + petalCount); &#125; Flower(String ss) &#123; println("constructor with string only" + ss); &#125; private Flower(String s, int petal) &#123; this(petal); //this(s) ，只能调用一次，如果调用第二次会报错 this.s = s; petalCount = petal; println("string and int constructor"); &#125; Flower() &#123; this("hi", 47); println("petalCount=" + petalCount + ",s=" + s); &#125; public static void main(String[] args) &#123; Flower flower = new Flower(); &#125;&#125; 垃圾回收所有用new构建的对象，java都会自动回收，只有那些不是用new得到的对象所占用的内存，java无法处理，需要你编写finalize()函数来进行垃圾回收 对象可能不被垃圾回收 垃圾回收不等于“析构” 垃圾回收只与内存有关 因为垃圾回收本身也要消耗一定资源，所以在jvm内存耗尽之前，它是不会浪费时间去执行垃圾回收的。 在垃圾回收的时候，会自动调用finalize()函数，通常是一些销毁时对对象的验证 1234567891011121314151617181920212223public class Main &#123; public static void main(String[] args) &#123; Book novel = new Book(true); novel.checkIn(); new Book(true); System.gc(); &#125;&#125;class Book&#123; boolean checkedOut = false; Book(boolean checkOut)&#123; checkedOut = checkOut; &#125; void checkIn()&#123; checkedOut = false; &#125; protected void finalize()&#123; if (checkedOut)&#123; println("error:checked out"); &#125; &#125;&#125; 垃圾回收的自适应技术所谓的自适应，就是在两种垃圾回收方式中切换：标记-清扫模式和停止-复制模式 先来介绍一下这两种模式的工作机理： 标记-清扫模式：遍历所有的引用，找出存活的对象。每找到一个存活对象，就会给对象一个标记，这个过程不会回收任何对象。只有标记完所有对象的时候，才开始清理，没有标记的对象将被释放。剩下的空间是不连续的，如果希望得到连续空间，就需要重新整理剩下的对象。 停止-复制模式：暂停程序运行，将所有存活的对象从当前堆复制到另一个堆，没有被复制到都是垃圾。得到的新堆是连续的。这种方法需要两倍的程序运行内存（一个本身，一个复制堆），在程序稳定时只有少量垃圾，大量复制会产生内存浪费。 自适应模式：如果对象很稳定，就切换到“标记-清扫”模式；要是标记清扫模式的堆空间中出现很多碎片，就会切换回“停止-复制”模式 类成员初始化顺序首先被初始化的是静态变量，然后是普通变量，比如定义的int，或者是定义的new 类元素，然后是构造器，最后是函数对象 12345678910111213141516171819202122232425262728293031323334353637383940package javastatic;class Window&#123; Window(int marker)&#123; System.out.println("Windows("+marker+")"); &#125;&#125;class House&#123; Window w1=new Window(1); House()&#123; System.out.println("House()"); w3=new Window(33); &#125; Window w2=new Window(2); void f()&#123; System.out.println("f()"); &#125; Window w3=new Window(3);&#125; public class OrderOfInitialization &#123; /** * @param args */ public static void main(String[] args) &#123; // TODO Auto-generated method stub House house=new House(); house.f(); &#125;&#125;/* output:Window(1)Window(2)Window(3)House()Window(33)f()*///:~ 静态数据无论创建多少个对象，静态数据都只占用一份存储区域，static不能用于局部变量，且静态变量的初始化优先级最高，在最前面 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475package test; class Bowl&#123; Bowl(int marker)&#123; System.out.println("Bowl("+marker+")"); &#125; void f1(int marker)&#123; System.out.println("f1("+marker+")"); &#125;&#125; class Table&#123; static Bowl bowl1=new Bowl(1); Table()&#123; System.out.println("Table()"); bowl2.f1(1); &#125; void f2(int marker)&#123; System.out.println("f2("+marker+")"); &#125; static Bowl bowl2=new Bowl(2);&#125; class Cupboard&#123; Bowl bowl3=new Bowl(3); static Bowl bowl4=new Bowl(4); Cupboard()&#123; System.out.println("Cupboard()"); bowl4.f1(2); &#125; void f3(int marker)&#123; System.out.println("f3("+marker+")"); &#125; static Bowl bowl5=new Bowl(5);&#125; public class Static &#123; public static void main(String args[]) &#123; System.out.println("Creating new Cupboard() in main"); new Cupboard(); System.out.println("Creating new Cupboard() in main"); new Cupboard(); table.f2(1); cupboard.f3(1); &#125; static Table table=new Table(); static Cupboard cupboard=new Cupboard();&#125;/* output：Bowl(1)Bowl(2)Table()f1(1)Bowl(4)Bowl(5)Bowl(3)Cupboard()f1(2)Creating new Cupboard() in mainBowl(3)Cupboard()f1(2)Creating new Cupboard() in mainBowl(3)Cupboard()f1(2)f2(1)f3(1)*/ 静态方法：静态方法不能访问this变量，但静态方法可以访问静态变量 数组初始化数组在java中的定义形式推荐的是： 1int[] array; 方括号在前，定义的是一个int类型的数组，比在后面更容易理解 数组的初始化有三种方法， 第一种是先定义长度，然后遍历数组，一个个赋值 第二种是用大括号直接赋值 第三种是用new+类型名[]+{值} 1234567891011121314151617181920212223public static void main(String[] args) &#123; Random rand = new Random(47); //第一种 int[] a = new int[rand.nextInt(20) + 1]; System.out.println("array a length:" + a.length); for (int i = 0; i &lt; a.length; i++) &#123; a[i] = rand.nextInt(500); &#125; System.out.println(Arrays.toString(a)); //第二种 Integer[] b = &#123; new Integer(1), new Integer(2), 3, &#125;; //第三种 Integer[] c = new Integer[]&#123; new Integer(1), new Integer(2), 3, &#125;;&#125; 数组排序可以自己写冒泡排序： 123456789for (int i = 0; i &lt; ns.length; i++) &#123; for (int j = i+1; j &lt; ns.length; j++) &#123; if (ns[i] &gt; ns[j])&#123; int t = ns[i]; ns[i] = ns[j]; ns[j] = t; &#125; &#125;&#125; 也可以直接调用Arrays.sort方法 123int[] ns=[1,33,4,2,5]Arrays.sort(ns)System.out.println(Arrays.toString(ns)); 打印数组的方法： 12345678910//方法一 Arrays.toString或者Arrays.deeptoString(打印多维数组)System.out.println( Arrays.toString(ns));//方法二 foreach遍历for(int i: ns)&#123; System.out.println(i);&#125;//方法三 for遍历for(i=0;i&lt;ns.length;i++)&#123; System.out.println(ns[i]);&#125; tips: idea快捷键： psvm：快速创建main函数 sout：快速输入System.out.println() fori：快速创建for模板 可变参数列表在java se5之前用的方法是输入内容放在args里面 1234567891011121314public class VarArgs &#123; static void printArray(Object[] args) &#123; for (Object obj : args) System.out.print(obj + " "); System.out.println(); &#125; public static void main(String[] args) &#123; printArray(new Object[] &#123; new Integer(55), new Float(5.34), new Double(3.56) &#125;); printArray(new Object[] &#123; "one", "two", "three" &#125;); printArray(new Object[] &#123; new A(), new A(), new A() &#125;); &#125;&#125; 在se5之后，就可以直接使用可变参数了，这与之前看的javascript的多参数用法一样，与python的*args一样，用法是... args 1234567891011121314151617public class NewVarArgs &#123; static void printArray(Object... args) &#123; for (Object obj : args) System.out.print(obj + " "); System.out.println(); &#125; public static void main(String[] args) &#123; printArray(new Integer(33), new Float(5.23), new Double(3.55)); printArray(33,5.23f,3.55d); printArray("one","two","three"); printArray(new A(),new A(),new A()); printArray((Object[])new Integer[]&#123;1,2,3,4,5,6&#125;); printArray(); &#125;&#125; 枚举enum枚举可以用于switch语句，自带ordinal()方法用于得到index，和values方法用于创建数组 12345678910111213public static void main(String[] args) &#123; for (Money m : Money.values())&#123; System.out.println("money " + m); &#125; Money money; switch(money)&#123; case one: System.out.println("case one");break; case two://剩余逻辑 case default: //xxxx &#125;enum Money&#123; one,five,ten,twenty,fifty,hundred&#125; 访问权限控制包一个包里面有多各类，然而有且仅有一个public类与包的名字相同，其他类主要为public类提供支持 包定义与引用声明包的方法是用package关键字 12package my.mypackagepublic class Myclass&#123;&#125; 引用的方法可以写全包名+类名，或者是使用import 包名 访问权限控制public：都可以访问 private：只有拥有成员的当前类可以访问 protected：当前和继承的对象可以访问 封装将类中的属性标记为private，外部代码不可以直接访问类元素，而是通过一些封装好的函数来访问，比如 12345678910111213141516171819public class Person &#123; private String name; private int age; public void setAge(int age) &#123; this.age = age; &#125; public void setName(String name) &#123; this.name = name.trim(); &#125; public int getAge() &#123; return age; &#125; public String getName() &#123; return name; &#125;&#125; 重载和重写重载：与父类的函数名相同，返回值类型相同，但是参数类型不同 重写（覆写）：与父类的函数名和参数都相同，只是函数内容不同 se5中引入了一个@override关键字，在你想要重写的时候，可以把这个关键字放在返回值之前，如果不是重写，那么将会报错 123456class Lisa extends Homer&#123; @override void doh(Milhouse m)&#123; System.out.println('doh(Milhouse)') &#125;&#125; 继承关键字extends，子类继承了父类所有元素和方法，可以重写这些方法 java只允许单继承，也就是每个类只能有一个父类 用super()表示父类的构造方法，用super.函数名()调用父类中被覆写的方法 123456789101112131415public class Student extends Person&#123; private int score; public void setScore(int score)&#123; this.score = score; &#125; public int getScore() &#123; return score; &#125; public String hello()&#123; return super().hello() + "!"; &#125;&#125; 向上向下转型在java中，一个类型可以安全地向上转型，因为一个子类肯定包含父类的所有元素和方法，但是父类不一定能够安全地向下转型。 转型之前先用instanceof判断 123if (p instanceof Student)&#123; p = (Student) p;&#125; 多态java的方法调用总是作用于对象的实际类型 如果一个变量的声明类型和实际类型值不同，那么他调用方法的时候，调用的是实际类型的方法 在java中，多态的含义是： 针对某个类型的方法调用，其真正执行的方法取决于运行时期的实际类型的方法 对某个类型调用某个方法，执行的方法可能是某个子类的覆写方法 利用多态，允许添加更多类型的子类实现功能扩展 1234567891011121314151617181920212223242526272829public class Hello &#123; public static void main(String[] args) &#123; Person p = new Person(); Person s = new Student(); p.run(); //unamed run s.run(); //student run &#125;&#125;class Person&#123; protected String name; private int age; Person(String name, int age)&#123; this.name = name; this.age = age; &#125; Person()&#123; this("unamed",0); &#125; public void run()&#123; System.out.println(this.name + "run"); &#125;&#125;class Student extends Person&#123; public void run()&#123; System.out.println("student "+ "run"); &#125;&#125; java中所有类都继承于object，因此拥有object的所有方法，object中定义了如下的重要方法 toString：把instance输出为String equals：判断两个instance是否逻辑相等 hashCode：计算一个instance的hash值 final 用final关键字修饰的方法不能被override 用final关键字修饰的类不能被继承 用final关键字修饰的字段在初始化之后不能被修改 抽象类如果一个类包含一个抽象方法，那么这个类就是抽象类 抽象方法：就是一个只有函数名，但是没有函数主体 用abstract关键字修饰，抽象方法无法被实例化，但其子类可以被实例化 123public abstract class Person&#123; public abstract void run(); &#125; 抽象方法的作用就是用来被继承 从抽象类继承的子类必须实现抽象方法，不然该子类仍是一个抽象类 12345678910111213public class Rectangle extends Shape &#123; private double width; private double height; Rectangle(double width, double height)&#123; this.width = width; this.height = height; &#125; @Override public double area() &#123; return width*height; &#125;&#125; 接口如果一个抽象类没有字段，并且所有方法都是抽象方法，那么我们就可以把这个抽象类改写为接口 接口用interface进行声明，接口默认的是public和abstract，所以在定义接口的时候不用写public和abstract 1234public interface Shape &#123; double area(); default double perimeter()&#123;return 0;&#125;;&#125; default关键字可以实现interface的默认方法，这样就不必在每个implements中实现这个方法 一个接口可以用extends继承另一个接口 包java定义的名字空间叫做包，用于解决名字冲突的问题 12package xiaoming;public class Person&#123;&#125; 12package xiaohong;public class Person&#123;&#125;; 小明的Person类：xiaoming.Person 小红的Person类：xiaohong.Person 包作用域同一个包中的类，可以访问包作用域的字段和方法 包作用域就是不使用任何public，private，protected修饰的字段和方法 classpathclasspath是一个环境变量，定义java如何搜索class的路径，在windows中用分号；分割，在Linux和mac中用冒号:分割，如果目录含有空格，这个路径就要用双引号括起来 先找当前目录，然后找classpathPATH的路径 运行java的时候可以通过java -cp classpath指定当前运行java时候的classpath jar包jar包是一种zip格式的压缩文件，包含若干个.class文件 jar包相当于目录，classpath可以包含jar文件 一个jar包中可以包含另一个jar包 JDK自带的class叫做rt.jar idea打包jar包的方法1.选择菜单File-&gt;Project Structure，将弹出Project Structure的设置对话框。 2.选择左边的Artifacts后点击上方的“+”按钮 3.在弹出的框中选择jar-&gt;from moduls with dependencies.. 4.选择要启动的类，然后 确定 5.应用之后选择菜单Build-&gt;Build Artifacts,选择Build或者Rebuild后即可生成，生成的jar文件位于工程项目目录的out/artifacts下。 String字符串类型String可以不用new来实例化，可以通过双引号String s = &quot;xxx&quot;直接赋值 String的内容是不可以变的，对比两个string是否相同要调用string的equal方法，equalIgnoreCase，这个方法可以忽略大小写 String提供的方法： contains：查看是否包含子串 indexOf：找到子串的索引位置 lastIndexOf：从后向前找 startswith：返回字符串是否由某个子串开始 endwith：返回字符串是否由某个子串结束 trim：移除首位的空白字符，String S = &quot;\t abc\r\n ；String S2 = S.trim()&quot; substring：提取子串，String S=&quot;hello, world&quot;; String S1 = S.substring(7)//&quot;world&quot;;s.substring(1,5)//&quot;ello&quot;，从0开始，包含最后一个数字 toUppercase, toLowerCase：转换大小写 replace：替换子串 replaceAll：用正则表达式替换子串 join：将一个String数组连接成一个字符串 valueOf：将一个整型转换为一个string类型，也可以用tostring方法转换为字符串 Interger.parseInt(“123”)：将一个String类型转换为一个int类型 toCharArray()：将String转换为char数组，String s =&quot;hello; char[] c = s.toCharArray();&quot; getBytes(“UTF-8”)：将string转换为bytes 打印一个array的方法：Arrays.toString(array) UTF-8和unicode的区别：utf-8是变长的，1-6个字节不等（英文字母只占用1个字节，节省内存）。而unicode所有内容都是2个字节的编码 StringBuilderStringBuilder是一个支持链式操作的字符串拼接对象，可以不停地apped，然后用toString变成需要的字符串 1234567public static void main(String[] args) &#123; StringBuilder sb = new StringBuilder(1000); for (int i = 0; i &lt; 100; i++) &#123; sb.append(String.valueOf(i)); &#125; System.out.println(sb.toString());&#125; JavaBean很多java类都是先定义一堆private字段，然后定义相应的get和set方法，这样的类就称为JavaBean 在idea中，定义完一个private字段，在字段上点击alt+enter，就可以快速生成get和set方法 enum枚举类用于定义枚举常量 123public enum Person &#123; a,b,c,d,e;&#125; 1234public static void main(String[] args) &#123; for (Person p: Person.values())&#123; System.out.println(p); &#125; 1System.out.println(Person.valueOf("a").name()); jdk常用工具类 Math类用于数学计算 Math有random方法，可以生成一个0-1之间的数0&lt;=x&lt;1 Random类用于构建伪随机数使用之前要先实例化random 123456789101112public static void main(String[] args) &#123; Random r = new Random(); System.out.println(r.nextInt()); System.out.println(r.nextLong()); System.out.println(r.nextFloat());//0-1之间的float System.out.println(r.nextDouble());//0-1之间的double&#125;//结果//453685453//-6144617524281204827//0.8796719//0.9157346073901224 异常处理异常异常处理的方式是用try，catch java中必须捕获的异常是Exception及其子类，但不包括RuntimeException及其子类 因为error是发生了严重错误，程序本身是无法处理的；而exception是运行时候的逻辑错误，程序可以捕获和处理这些错误，而RuntimeException是因为程序自身有bug，需要我们去修复程序 Main方法是捕获异常的最后机会，其余子函数可以用throws将异常抛出，由上层方法来捕获 异常捕获的顺序异常是按照catch的顺序依次捕获的，所以要把更小的异常（子类）放在前面，不然父类在前面，只要发生了错误就一定会被执行 finally无论是否有错都要执行就用finally multi-catch可以用或操作符|来同时捕获多个Exception printStackTraceprintStackTrace()方法可以打印出异常的传播路径，对于调试很有用 123456789101112131415161718192021222324public class Main &#123; public static void main(String[] args) &#123; process1(); &#125; static void process1()&#123; try &#123; process2(); &#125; catch (Exception e)&#123; e.printStackTrace(); &#125; &#125; static void process2()&#123; Integer.parseInt(null); &#125;&#125;//抛出如下异常：//java.lang.NumberFormatException: null// at java.base/java.lang.Integer.parseInt(Integer.java:614)// at java.base/java.lang.Integer.parseInt(Integer.java:770)// at test.Main.process2(Main.java:158)// at test.Main.process1(Main.java:151)// at test.Main.main(Main.java:147) JDK已定义的异常 自定义异常自定义异常，最好使用RuntimeException继承得到，其构造方法可以通过ide提供的alt+insert插入父类的构造方法 123456789101112131415161718package test;public class BaseExceptions extends RuntimeException &#123; public BaseExceptions() &#123; &#125; public BaseExceptions(String message) &#123; super(message); &#125; public BaseExceptions(String message, Throwable cause) &#123; super(message, cause); &#125; public BaseExceptions(Throwable cause) &#123; super(cause); &#125;&#125; 123456789101112131415161718package test;public class UserNotFoundException extends BaseExceptions &#123; public UserNotFoundException() &#123; &#125; public UserNotFoundException(String message) &#123; super(message); &#125; public UserNotFoundException(String message, Throwable cause) &#123; super(message, cause); &#125; public UserNotFoundException(Throwable cause) &#123; super(cause); &#125;&#125; 断言assert关键字，如果条件为true则继续执行，条件为false则抛出AssertionError，可以加入一个断言消息，打印出断言结果 断言是一种条件方式，只能在开发和测试阶段使用 1assert x&gt;0: "x&lt;0 now"+x; 日志jkd自带的日志系统在java.utils.logging，可以定义格式或者是重定向到文件等 12345678910111213141516public class Main &#123; public static void main(String[] args) &#123; Logger logger = Logger.getGlobal(); logger.info("create new person"); logger.log(Level.WARNING,"create failed"); logger.info("end"); &#125;&#125;//输出//9月 11, 2018 10:47:09 上午 test.Main main//信息: create new person//9月 11, 2018 10:47:09 上午 test.Main main//警告: create failed//9月 11, 2018 10:47:09 上午 test.Main main//信息: end common logging更常用的log方法是commom logging，一共六个日志级别如下 tips: idea添加jar包的方法 点击file，project structure 点击左边的module，点击dependencies，点击add 选择其中的add jar，选中后确定即可 log4jlog4j是目前最流行的日志框架，其可以输出到控制台，文件（file），或者是远程（socket） filter用于过滤：哪些日志需要输出，哪些日志不需要输出 layout：格式化输出 java反射与泛型反射class/interface的数据类型是Class 将通过Class实例来获取class信息的方法称为反射（reflection）——class实例—&gt;class信息 1234567//方法1Class cls = String.class;//方法2String s= "abcd";Class cls = s.getClass();//方法3Class cls = Class.forName("abc"); 反射的目的：获得某个object实例的时候，可以获得该object的class的所有信息 从class可以判断出class的类型，class提供以下几个方法： 12345678//1isInterface();//2isArray();//3isEnum();//4isPrimitive();//是否基本类型 判断类是否存在： 1Class.forName(name) 通过class获取Constructor 1234getConstructor(Class):获取某个public的ConstructorgetDeclaredConstructor(class)：获取某个ConstructorgetConstructor()：获取所有public的ConstructorgetDeclaredConstructor():获取所有Constructor 通过反射获得继承关系用class的getSuperclass()方法获取分类的class对象，注意：object和interface的父类是null getInterfaces()方法返回当前对象的interface 通过class的isAssignabelFrom()方法可以判断一个向上转型是否正确 注解注解是放在java源码的类、方法、字段、参数前的标签，用@开始，有点像python的装饰器 常用的注解包括： @Override：检查是否覆写 @Deprecated：告诉编译器该方法已经废弃，如果被调用出现警告 @SuppressWarnings(&#39;unused&#39;)：抑制警告 @Time(timeout=100)：时间检查 Check(min=0,max=100,value=55)：值的检查 定义注解用public @interface name来定义注解 元注解：注解可以修饰别的注解 用@Target定义Annotation可以被应用于源码的哪些位置 类或接口：ElementType.TYPE 字段：ElementType.FIELD 方法：ElementType.METHOD 构造方法：ElementType.CONSTRUCTOR 方法参数：ElementType.PARAMETER 123456@Target(ElementType.METHOD)public @interface Report&#123; int type() default 0; String level() default "info"; String value() default "";&#125; Annotaiton的生命周期，用Retention()来定义 用@Repeatable定义Annotation是否可以重复 用@Inherited定义子类是否可以继承父类的Anootation 处理Annotation通过反射可以处理注解，得到class对象后，可以用class.isAnnotationPresent(Class)来判断注解是否存在，用class.getAnnotation()得到Annotation 泛型就是用&lt;&gt;来泛化某个类型，比如arraylist在使用过程中，你要指定这个list当中存放的元素类型，就要用ArraryList&lt;String&gt; al = new ArrayList&lt;&gt;(); 集合Listlist是一种有序链表，每个元素都可以通过索引来确定位置 常用方法包括： list的实现有ArrayList和LinkedList两种： ArrayList就和数组是一样的结构，当添加的时候大小不够了，就创建一个更大数组，把之前的值全部复制过去，再加一个值 而LinkedList和链表一样的结构，上一个指向下一个 遍历list的方法 get遍历 1234List&lt;String&gt; list = new List&lt;&gt;();for(int i=0;i&lt;list.size();i++)&#123; String s = list.get(i);&#125; Iterator遍历 1234List&lt;String&gt; list = new List&lt;&gt;();for (Iterator&lt;String&gt; it = list.iterator();it.hasNext();)&#123; String s = it.next();&#125; foreach循环，最推荐这种方法 1234List&lt;String&gt; list = new List&lt;&gt;();for (String s:list)&#123; System.out.println(s);&#125; List和Array的转换 Object[] toArray() 12345List&lt;Interger&gt; list = new List&lt;&gt;();list.add(1);list.add(2);list.add(3);Object[] array = list.toArray(); &lt;T&gt; T[] toArray(T[] a) 12345List&lt;Interger&gt; list = new List&lt;&gt;();list.add(1);list.add(2);list.add(3);Integer[] array = list.toArray(list[size]); 查找某个元素是否存在 list.contains(Object o)，返回true包含，false不包含 list.indexOf(Object o)，返回正数就是有，返回-1就是不存在 Mapmap就是一种键值对映射的数据结构，与python中的dict是一样的 1234567public class Strudent&#123; public String name; public String address; public float grade;&#125;Map&lt;String,Student&gt; map = ...;Student target = map.get("xiao ming") map的常用方法 put：将key-value对放入map get：通过key获取value containsKey：判断key是否存在 遍历Map的方法 遍历key 12345Map&lt;String,Student&gt; map = ...;// 用keySet遍历key，用get方法获取值for (String key:map.keySet())&#123; Integer value = map.get(key);&#125; 同时遍历key和value 123456Map&lt;String,Student&gt; map = ...;// 用entrySet同时遍历key，valuefor (Map.Entry&lt;String,Integer&gt; entry:map.entrySet())&#123; String key = entry.getKey(); Integer value = entry.getValue();&#125; HashMap和TreeMapMap最常用的实现类是HashMap，其内部存储不保证有序 遍历时的顺序不一定是put的顺序，也不一定是key的顺序 SortedMap保证遍历时以key排序，其实现类是TreeMap 1234567Map&lt;String,Integer&gt; map = new TreeMap&lt;&gt;();map.put("orange",1);map.put("apple",2);map.put("banana",3);for (Map.Entry&lt;String,Integer&gt; entry:map.entrySet())&#123; System.out.println(entry.getKey()+" "+entry.getValue());&#125; Setset就是python里面的set，不包含重复值，常用方法包括 add remove contains size set不保证有序，HashSet是无序的，TreeSet是有序的 QueueQueue是一个FIFO的队列，常用方法包括： size()：获取长度 添加元素到队尾:add/offer 获取队列头部元素并删除:remove/poll 获取队列头部元素但不删除：element()/peek() Queue的实现对象是LinkedList() PriorityQueuePriorityQueue就是带有优先级顺序的Queue，其常用方法与Queue相同 Deque是Queue的一种实现，是双向队列 Stack是一种LIFO（last In First out）的结构，常用方法 push pop peek 使用Deque来实现stack，只调用push，pop，peek三个函数，这样就实现了栈 IOIO流，顺序读写数据的模式，单向流动，以字节为单位，byte类型 如果不是字节流，那么久用Reader/Writer表示字符流，字符流的最小单位是char，字符流输出的byte取决于编码方式 1234char[] hello = "hi你好";writeChars(hello,"utf-8");//output.txt，英文字符占一个字节，中文占3个字节//0x48, 0x69, 0xe4,0xbd,0xa0,0xe5,0xa5,0xbd Reader/Writer本质上是一个能自动编解码的InputStream/OutputStream 其实现类如下： File构造方法 1File f = new File("c\\Windows\\notepad.txt") file有三种路径 1234567File file = new File("./Person.java");System.out.println("绝对路径："+file.getAbsolutePath());// C:\Users\jeffrey\IdeaProjects\MyHelloWorld\.\Person.javaSystem.out.println("canonical（规范）路径："+file.getCanonicalPath());// C:\Users\jeffrey\IdeaProjects\MyHelloWorld\Person.javaSystem.out.println("相对路径："+file.getPath());// .\Person.java 规范路径就是绝对路径删掉.和.. 用isFile()判断是否为文件，isDirectory()判断是否为目录 构造file对象就算是文件不存在也不会报错，因此要用上面两个文件来判断 canRead()/canWrite()用于判断是否可以读/写 createNewFile()：创建文件 createTempFile():创建临时文件 delete()：删除文件 deleteOnExit()：在JVM退出时删除该文件 String[] list()：列出文件目录下的文件和子目录名 File[] listFiles()：列出文件和子目录名 Boolon mkdir()：创建目录 Boolon mkdirs()：创建目录，如果上层目录不存在，同样创建 InputStream是所有输入流的超类，最重要的方法是abstract int read()，读取下一个字节，并返回字节(0-255)，如果已经读到末尾，返回-1 完整读取一个inputstream流程如下：]]></content>
      <categories>
        <category>java</category>
        <category>编程学习</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[react+react-router搭建管理系统]]></title>
    <url>%2F2018%2F06%2F17%2Freact-react-router%E6%90%AD%E5%BB%BA%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[本地存储因为http是一种无状态的请求，如果需要记录访问者的身份，那么就需要借助cookie和session cookie是浏览器保存的一系列值，其字段及定义如下： 与cookie对应的是session，session由服务器端产生记录请求者身份，其字段定义如下： session在关闭页面之后就会自动删除 localStorage是H5引入的机制，是一些key-value的键值对，有域名限制（完全匹配，不存在域的概念），关闭浏览器之后内容仍然存在，用setItem和removeItem进行添加和删除 sessionStorage与localStorage很相似，在关闭浏览器之后消失 react-router页面的三种路由管理浏览器不同页面跳转的机制 包含三个部分： 历史：堆栈的结构，入栈和出栈记录访问历史 跳转：在不同页面之间的跳转，并且可以传递参数 事件：打开新页面或者退回上一页面的逻辑 常见的router： 页面Router：整个页面重新加载 hash router：跳转时只有页面的hash值变化，页面本身并没有重新加载 H5 Router：可以操作整个路径，既能操作hash又能操作页面 用浏览器尝试进行跳转，用下面这条指令可以跳到baidu： 12window.location.href = 'http://www.baidu.com'history.back() 点返回按钮，可以看到整个的路由历史 再试一下hash跳转： 12window.location = '#test'windows.onhashChange = ()=&gt;&#123;console.log('current hash', window.location.hash)&#125; //监听所有的hash改变的情况 发现只是在原本的地址后面加了一个#test 再试一下H5的跳转方法，H5是用history.pushState来手动改变地址，既可以hash跳转，也可以直接跳转到其他页面 1234567891011history.pushState('name','title','#test')history.pushState('name','title','/index/user')window.onpopstate = e=&gt;&#123; //监听后退的事件,也就是pop栈的时候 console.log('h5 router change',e.state ); console.log('绝对路径',window.location,href); console.log('相对路径',window.location.pathname); console.log('hash值',windows.location.hash); console.log('search值',windows.location.search);&#125; history.replaceState('name','title','#test')//替换当前的路由，但是不记录上一次的路由，就是直接替换，不入栈 react-router提供了两种router，&lt;BrowsorRouter&gt;和&lt;HashRouter&gt; &lt;Route&gt;：router里面的路由选项，哪个页面对应哪个组件 &lt;Switch&gt;：解决多次匹配的问题，返回第一个符合规则的匹配 &lt;Link&gt;和&lt;NavLink&gt;：跳转导航，相当于HTML当中的&lt;a&gt;，后者是加了选中状态的处理，适合做导航菜单 &lt;Redirect&gt;：用于自动跳转，匹配到某个路径的时候，自动跳转到另外的路径]]></content>
      <categories>
        <category>react</category>
        <category>前端</category>
      </categories>
      <tags>
        <tag>react</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django与React前后端分离的认证(一)]]></title>
    <url>%2F2018%2F06%2F17%2FDjango%E4%B8%8EReact%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E7%9A%84%E8%AE%A4%E8%AF%81-%E4%B8%80%2F</url>
    <content type="text"><![CDATA[难以想象如果一个Django应用没有用户认证，我们用一个简单的认证流程来解释一下Django和React的协作进行用户认证的过程。 第一部分用JWT token认证创建一个简单的Django后端。第二部分展示如何创建React/Redux前端，第三部分介绍如何应用JWT去刷新token。 最终你可以看到一个以django为后端，react/redux为前端的小应用。 什么是JWTjson web token是一种无状态的认证方法。生成的token只保存在客户端。一个JWT token本身可能包含了用户名，邮箱或者用户权限。 JWT可以提供两种类型的token，一种是长期刷新的token（用于token过期之后的重新获取），一种是短期访问的token（用于调用API服务） 建立后端代码首先用virtualenv建立新的环境，并安装相关库 1234567$ mkdir backend/ &amp;&amp; cd backend/$ python3.6 -m venv env$ source env/bin/activate$ pip install coreapi django djangorestframework \ djangorestframework-simplejwt$ pip freeze &gt; requirements.txt$ django-admin startproject config . 安装的coreapi库用于自动生成api的模式，用于描述有什么资源可以用，urls是什么，支持什么操作，如何去展现结果。 django-rest-framework-simplejwt 库用于执行JWT认证 然后在config/settings.py中配置： 1234567891011121314INSTALLED_APPS = [ ... 'rest_framework',]# Rest FrameworkREST_FRAMEWORK = &#123; 'DEFAULT_PERMISSION_CLASSES': ( 'rest_framework.permissions.IsAuthenticated', ), 'DEFAULT_AUTHENTICATION_CLASSES': ( 'rest_framework_simplejwt.authentication.JWTAuthentication', 'rest_framework.authentication.SessionAuthentication', ),&#125; 加入rest_framework到INSTALLED_APPS当中，用IsAuthenticated来保护所有的api访问权限，用JWTAuthentication和SessionAuthentication来保护认证的视图 修改config/urls.py： 123456789101112from django.conf.urls import url, includefrom django.views import genericfrom rest_framework.schemas import get_schema_viewfrom rest_framework_simplejwt.views import (TokenObtainPairView,TokenRefreshView,)urlpatterns = [ url(r'^$', generic.RedirectView.as_view(url='/api/', permanent=False)), url(r'^api/$', get_schema_view()), url(r'^api/auth/', include('rest_framework.urls', namespace='rest_framework')), url(r'^api/auth/token/obtain/$', TokenObtainPairView.as_view()), url(r'^api/auth/token/refresh/$', TokenRefreshView.as_view()),] 这里使用了get_schema_view去是的api视图可用，TokenObtainPairView 和TokenRefreshView 完成JWT认证的作用 为了简单，我们把echo API部分直接放在config/urls.py中 123456789101112class MessageSerializer(serializers.Serializer): message = serializers.CharField()class EchoView(views.APIView): def post(self, request, *args, **kwargs): serializer = MessageSerializer(data=request.data) serializer.is_valid(raise_exception=True) return Response( serializer.data, status=status.HTTP_201_CREATED)urlpatterns = [ ... url(r'^api/echo/$', EchoView.as_view())] 现在可以运行django代码 123$ ./manage.py migrate$ ./manage.py createsuperuser$ ./manage.py runserver]]></content>
      <categories>
        <category>网页</category>
        <category>编程学习</category>
      </categories>
      <tags>
        <tag>Django</tag>
        <tag>React</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[React与Django连接]]></title>
    <url>%2F2018%2F06%2F09%2FReact%E4%B8%8EDjango%E8%BF%9E%E6%8E%A5%2F</url>
    <content type="text"><![CDATA[React构建好了前端网页，那么后端该如何使用这个前端网页呢，就需要用到下面介绍的方法 Django首先处理Django方面的问题 安装virtualenv的管理包virtualenvwrapper，pip install virtualenvwrapper`. 创建virtualenv，mkvirtualenv name-of-virtual-env 创建Django项目，django-admin startproject nameOfProject 建立app，django-admin startapp mynewapp 把mynewapp加入到settings.py中 React首先安装nodejs和npm，然后： 安装create-react-app包create-react-app 建立一个新的前端app，create-react-app name-of-project 把这个React app拷贝到Django目录下 修改package.json，添加&quot;homepage&quot;: &quot;.&quot; npm start调试前端目录 直到效果完全ok之后打包前端文件npm run build得到一个build文件夹 Django settings修改然后是修改Django settings.py文件， 123456789101112131415#更改模板文件夹BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))TEMPLATES = [ &#123; ... 'DIRS': [ os.path.join(BASE_DIR, 'build') ], ... &#125;]#更改静态文件夹STATICFILES_DIRS = [ os.path.join(BASE_DIR, 'build/static'),] 然后再url中配置好url就可以run server进行访问了]]></content>
      <categories>
        <category>网页</category>
      </categories>
      <tags>
        <tag>Django</tag>
        <tag>React</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[react初探]]></title>
    <url>%2F2018%2F06%2F07%2Freact%E5%88%9D%E6%8E%A2%2F</url>
    <content type="text"><![CDATA[React是Facebook用来开发insgram的 MVC：Model，View，Control，称之为模型，视图，控制，react属于视图部分 ES5和ES6之间的转换工具叫做Babel，是Nodejs的一个包 npm与nodejs及react的安装安装好Nodejs和npm环境，查看是否安装成功 12node -vnpm -v 配置国内镜像 淘宝镜像提供了一个cnpm的工具，可以用cnpm命令来安装所有的包 1$ npm install -g cnpm --registry=https://registry.npm.taobao.org 也可以直接配置全局文件改变下载地址，mac和Linux的配置文件在~/.npm/.npmrc，windows的在node安装目录下/node_modules/npm/npmrc。在其中添加： 1registry=https://registry.npm.taobao.org 旧版react的配置方式mooc教程中用到的方法比较旧，具体是首先执行npm init，生成一个package.json文件，这个文件记录了项目的所有信息，然后通过npm install --sava xxxx各种包，--save的意思是将这个包的安装同步到package.json文件中 新版react的配置方式现在react官网已经提供了一个专门用于管理react项目的npm包——create-react-app，用npm install -g安装，-g的意思是global，全局安装 1234567npm install -g create-react-appcreate-react-app my-app#删除所有/src文件夹下面的内容cd my-apprm -f src/*#添加一个index.css在src/目录下，其内容在https://codepen.io/gaearon/pen/oWWQNa?editors=0100#添加一个index.js在src/目录下，其内容为 https://codepen.io/gaearon/pen/oWWQNa?editors=0010 再加入以下几行到index.js最上面，用于引用React的相关包 123import React from 'react';import ReactDOM from 'react-dom';import './index.css'; 然后在项目文件夹下运行npm star，打开浏览器http://localhost:3000，就可以看到一个九宫格页面 运行时如果发现端口占用，在windows下就执行 12netstat -ano | findstr 3000tskill xxx 在Linux下执行 12netstat -aux | grep 3000kill xxx webpack热加载配置通过npm install webpack --save和npm install webpack-dev-server --sava之后，新建一个webpack.config.js，输入以下内容用于打包整个文件，然后在命令行执行webpack，就生成了一个名为bundle.js的文件，你在html当中应该包含的就是这个bundle.js文件。 可以使用webpack --watch命令进入debug模式，这样在你保存文件之后就可以自动打包，不然每次都需要自己去执行webpack命令。 但是这样还需要自己刷新页面，如果需要自动刷新网页，运行webpack-dev-server --contentbase src --inline --hot，这样在你更改js之后网页会自动刷新 123456789101112131415161718192021222324252627282930313233var debug = process.env.NODE_ENV !== "production";var webpack = require('webpack');var path = require('path');module.exports = &#123; context: path.join(__dirname), devtool: debug ? "inline-sourcemap" : null, entry: "./src/js/root.js", module: &#123; loaders: [ &#123; test: /\.js?$/, exclude: /(node_modules)/, loader: 'babel-loader', query: &#123; presets: ['react', 'es2015'], plugins: ['react-html-attrs'], //添加组件的插件配置 &#125; &#125;, //下面是使用 ant-design 的配置文件 &#123; test: /\.css$/, loader: 'style-loader!css-loader' &#125; ] &#125;, output: &#123; path: __dirname, filename: "./src/bundle.js" &#125;, plugins: debug ? [] : [ new webpack.optimize.DedupePlugin(), new webpack.optimize.OccurenceOrderPlugin(), new webpack.optimize.UglifyJsPlugin(&#123; mangle: false, sourcemap: false &#125;), ],&#125;; 不过新的react的安装方式已经可以自动打包了，就不用手动安装webpack了 React基本概念React Virtual DOM在页面和DOM之间加了一层virtual DOM，dom本身是document object model，有了虚拟DOM之后就可以利用virtual DOM对页面进行更改，virtual DOM由于在数据结构上面的优化，使得原本对不同的DOM的比较的复杂度由$O(n^3)$变成了$O(n)$， React组件组件就是一个个小模块，小模块在不同的页面之间都需要用，那么就可以复用，这样开发起来就很快。 我们先开发一个页面头部文件，在src目录中新建components文件夹，在其中新建header.js： 12345678910import React, &#123;Component&#125; from 'react'export default class ComponentHeader extends Component &#123; render() &#123; return ( &lt;header&gt; &lt;h1&gt;这是头部&lt;/h1&gt; &lt;/header&gt; ) &#125;&#125; 这段代码的逻辑是首先从React这个包里面引入React和React.Component两个内容，{}的作用就是引入包当中的某个变量，然后定义一个外部可访问(export)的类叫做ComponentHeader，继承自引入的Component，类名一定要大写，在其中调用render方法，return一段html内容，注意：返回的一定是一个闭合的HTML标签，也就是最终是一个大的HTML节点，不能有多个，有多个的时候你可以尝试用一个大的节点把他们包裹起来 然后在index.js当中引用定义的ComponentHeader组件，render到html文件的header这个id之下，其中定义的ComponentHeader要用tag标记扩起来 123456import React from 'react';import ReactDOM from 'react-dom';import './index.css';import ComponentHeader from "./components/header";ReactDOM.render(&lt;ComponentHeader /&gt;,document.getElementById('header')); 用同样的方法我们可以建立footer.js和body.js 12345678910// footer.jsimport React, &#123; Component &#125; from 'react'export default class ComponentFooter extends Component &#123; render() &#123; return ( &lt;h1&gt;这是尾部&lt;/h1&gt; ) &#125;&#125; 123456789101112//indexBody.jsimport React, &#123; Component &#125; from 'react'export default class IndexBody extends Component &#123; render() &#123; return ( &lt;div&gt; &lt;h2&gt;页面Body的内容&lt;/h2&gt; &lt;/div&gt; ) &#125;&#125; 然后在index.js里面再定义一个class用于包含已有的三个header，indexbody,footer三个类 12345678910111213141516// index.jsimport ComponentHeader from "./components/header";import ComponentFooter from "./components/footer.js"import IndexBody from "./components/indexBody";export default class Index extends Component &#123; render() &#123; return ( &lt;div&gt; &lt;ComponentHeader /&gt; &lt;IndexBody /&gt; &lt;ComponentFooter /&gt; &lt;/div&gt; ) &#125;&#125; 注意：所有的class的name一定要是大写开头的，不然无法识别 JSX内置表达式123456789101112131415161718import React, &#123;Component&#125; from 'react'export default class IndexBody extends Component &#123; render() &#123; var userName = ''; var boolinput = false; var html = "this\u0020is" return ( &lt;div&gt; &lt;h2&gt;页面主体内容&lt;/h2&gt; &lt;p&gt;&#123;userName=='' ? '用户还没有登陆':'用户名:'+userName&#125;&lt;/p&gt; &lt;p&gt;&lt;input type="button" value="默认按钮" disabled=&#123;boolinput&#125;/&gt;&lt;/p&gt; &lt;p&gt;&#123;html&#125;&lt;/p&gt; &#123;/* 注释 */&#125; &lt;/div&gt; ) &#125;&#125; 三元表达式三元表达式主要是用来进行条件判断的，比如我们在上面的代码汇总，需要判断username是否为空，用三元表达式a==b?c:d，判断ab是否相等，如果相等执行c，如果不相等执行d，这个判断语句要包含在大括号中 1&lt;p&gt;&#123;userName=='' ? '用户还没有登陆':'用户名:'+userName&#125;&lt;/p&gt; 绑定参数如果要对一个input的button绑定是否disable的属性，只需要用一个大括号带参数就可以直接绑定成功 注意：绑定js参数的时候，没有引号，有引号会被解析为字符串 解析HTML如果我们现在有一串HTML代码，需要让render之后可以正确被解析，有两种方法： 使用在线的转码工具，将html代码转成unicode编码的内容，然后传给内容html，比如下面的空格被转换成\u0020再传给render 12var html = "this\u0020is"&lt;p&gt;&#123;html&#125;&lt;/p&gt; 使用不推荐的dangerouslySetInnerHTML，因为这种方法可能造成xss攻击，因此不推荐 12var html = "this\u0020is"&lt;p dangerouslySetInnerHTML==&#123;&#123;__html : html&#125;&#125;&gt;&lt;/p&gt; 生命周期react本身定义了一系列的关于页面加载状态的函数，你可以用这些函数来判断页面加载的状态，并在不同状态的时候定义不同的命令 常用的生命周期函数有如下几种，示意图如下 12345678910111213componentWillMount() &#123;&#125; //将要加载成功componentDidMount() &#123;&#125; //已经加载成功componentWillReceiveProps(nextProps) &#123;&#125;shouldComponentUpdate(nextProps, nextState) &#123;&#125;componentWillUpdate(nextProps, nextState) &#123;&#125;componentDidUpdate(prevProps, prevState) &#123;&#125;componentWillUnmount() &#123;&#125; React事件与属性state属性state用于存放react组件的状态，一般赋值为一个json类型，放在constructor里面 123456789101112131415161718192021222324import React, &#123;Component&#125; from 'react'export default class IndexBody extends Component &#123; constructor(props) &#123; super(props); this.state = &#123; username: 'carry', age: 20 &#125; &#125; render() &#123; setTimeout(() =&gt; &#123; this.setState(&#123;username: "ohjj"&#125;) &#125;, 4000); return ( &lt;div&gt; &lt;h2&gt;页面主体内容&lt;/h2&gt; &lt;p&gt;&#123;this.state.username&#125; &#123;this.state.age&#125;&lt;/p&gt; &#123;/* 注释 */&#125; &lt;/div&gt; ) &#125;&#125; 通过setState函数可以改变组件的状态值 props属性想要把外来的属性传给某个组件，就需要用到props属性，在render的内容中加入参数名={参数值}就可以直接传回参数，在对应的js文件中直接用{this.props.参数名}就可以调用 1234567891011121314151617181920212223242526272829303132333435363738//index.jsexport default class Index extends Component &#123; render() &#123; return ( &lt;div&gt; &lt;ComponentHeader/&gt; &lt;IndexBody userid=&#123;123456&#125;/&gt; &lt;ComponentFooter /&gt; &lt;App/&gt; &lt;/div&gt; ) &#125;&#125;// indexbody.jsexport default class IndexBody extends Component &#123; constructor(props) &#123; super(props); this.state = &#123; username: 'carry', age: 20 &#125; &#125; render() &#123; setTimeout(() =&gt; &#123; this.setState(&#123;username: "ohjj"&#125;) &#125;, 4000); return ( &lt;div&gt; &lt;h2&gt;页面主体内容&lt;/h2&gt; &lt;p&gt;&#123;this.state.username&#125; &#123;this.state.age&#125; &#123;this.props.userid&#125;&lt;/p&gt; &#123;/* 注释 */&#125; &lt;/div&gt; ) &#125;&#125; 事件与数据的双向绑定父页面向子页面传递参数是在父页面直接定义变量，在子页面使用props属性来获取。 那么子页面如何向父页面传递参数呢，就需要由父页面向子页面传递一个处理函数，处理函数的event参数可以取到子页面中的值，比如在子页面的输入框中输入内容，改变父页面的某个参数值： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748//父页面 indexbody.jsimport React, &#123;Component&#125; from 'react'import Bodychild from "./bodychild";export default class IndexBody extends Component &#123; constructor(props) &#123; super(props); this.state = &#123; username: 'carry', age: 20 &#125; &#125; changeUserInfo(age) &#123; this.setState(&#123;age: age&#125;) &#125; handleChildChange(event) &#123; this.setState(&#123;age: event.target.value&#125;); &#125; render() &#123; return ( &lt;div&gt; &lt;h2&gt;页面主体内容&lt;/h2&gt; &lt;input type="button" value="提交" onClick=&#123;this.changeUserInfo.bind(this,99)&#125;/&gt; &lt;p&gt;&#123;this.state.username&#125; &#123;this.state.age&#125;&lt;/p&gt; &lt;Bodychild handleChildChange=&#123;this.handleChildChange.bind(this)&#125;/&gt; &lt;/div&gt; ) &#125;&#125;//子页面 bodychild.jsimport React, &#123;Component&#125; from 'react';class Bodychild extends Component &#123; render() &#123; return ( &lt;div&gt; &lt;p&gt;子页面输入：&lt;input type="text" onChange=&#123;this.props.handleChildChange&#125;/&gt;&lt;/p&gt; &lt;/div&gt; ); &#125;&#125;export default Bodychild; bind方法bind方法和call方法以及apply方法差不多，主要是用于解决this的指向问题的， call方法参数第一个是需要执行的对象，后面依次表示不同的参数 12345678var a=&#123; age:10, fn:function getAge()&#123;console.log(this.age)&#125;&#125;a.fn();//输出10var b = a.fn();b; //输出undefined，因为此时的this指向b，this.age就相当于b.age，当然是未定义b.call(a) //输出10，call的格式是function.call(object,params) apply方法与call方法基本类似，只是apply后面第一个参数是object，第二个参数是一个打包好的array对象，用于存放所有的后面的参数 12345678var a=&#123; age:10, fn:function getAge(params)&#123;console.log(this.age+this.params)&#125;&#125;a.fn(5);//输出15var b = a.fn();b; //输出undefinedb.apply(a,[5]) //输出15，apply的格式是function.apply(object,[params]) bind方法与apply和call略有不同，但是三者都是用来改变this指向的 123456789var a=&#123; age:10, fn:function getAge(params)&#123;console.log(this.age+this.params)&#125;&#125;a.fn(5);//输出15var b = a.fn;b.bind(a);//发现没有任何输出，其实bind只是绑定了，但是没有执行var c = b.bind(a);c();//输出15，bind的格式是function.apply(object,params)() prop验证用propTypes来约束类中的props的类型，isRequired表示必须给定这个值 用defaultProps来给定props的默认值 1234567const defaultProps=&#123; userid:'默认的userid'&#125;;IndexBody.propTypes = &#123; userid: PropTypes.number.isRequired&#125;;IndexBody.defaultProps = defaultProps; 还有一个技巧：如果有多个参数从父页面传递到子页面，子页面需要再传给自身的子页面的时候，可以用...this.props，三个点的前两个表示上级页面，第三个点表示上级页面自身的this 1&lt;Bodychild &#123;...this.props&#125;/&gt; 组件refsrefs可以用来找到某个组件，类似于js当中的getElementById的作用，在某个组建中定义一个ref，在改变的时候只需要用this.refs.xxx 123456789101112131415changeUserInfo(age) &#123; this.setState(&#123; age: age &#125;); //第一种方法，原生js的方法 let mySubmitButton = document.getElementById('submitButton'); ReactDOM.findDOMNode(mySubmitButton).style.color = 'red'; //第二种方法，refs的方法 console.log(this.refs.submitButton); this.refs.submitButton.style.color = 'blue'&#125;render()&#123;&lt;input id="submitButton" ref="submitButton" type="button" value="提交" onClick=&#123;this.changeUserInfo.bind(this, 99)&#125;/&gt;&#125; 独立组件间共享Mixins官方完全不推荐这个方法，因为ES6本身语法不支持，并且可能造成很多问题 如果非要用可以安装一个react-mixin的库，在需要用到这个东西的地方用React.Mixin(类名.prototypem, 用到的mixins名称) React样式React内联样式直接定义在render函数里面，然后通过className引用，这样相当于在html当中直接嵌入了css代码，是比较不美观的 12345678910111213141516render() &#123; const styleHeader = &#123; header: &#123; backgroundColor: "#333333", color: "#FFFFFF", paddingTop: "15px", paddingBottom: "15px" &#125; &#125;; return ( &lt;header className="styleHeader"&gt; &lt;h1&gt;这是头部&lt;/h1&gt; &lt;/header&gt; )&#125; 还可以单独定义css文件 1234567891011121314151617// style.css.smallFontSize h1&#123; font-size: 12px;&#125;//header.jsimport React, &#123;Component&#125; from 'react'import '../css/style.css'export default class ComponentHeader extends Component &#123; render() &#123; return ( &lt;header className="smallFontSize"&gt; &lt;h1&gt;这是头部&lt;/h1&gt; &lt;/header&gt; ) &#125;&#125; 内联css当中的表达式内联css当中可以嵌套一些简单的三元条件表达式，下面这个例子是在点击使得状态miniHeader改变的时候，调整header的padding值 123456789101112131415161718192021222324252627282930export default class ComponentHeader extends Component &#123; constructor(props) &#123; super(props); this.state = &#123; miniHeader : false &#125; &#125; swithHeader()&#123; this.setState(&#123; miniHeader : !this.state.miniHeader &#125;) &#125; render() &#123; const styleHeader = &#123; header: &#123; backgroundColor: "#333333", color: "#FFFFFF", paddingTop: (this.state.miniHeader) ? "3px" : "15px", paddingBottom: (this.state.miniHeader) ? "3px" : "15px", &#125; &#125;; return ( &lt;header style=&#123;styleHeader.header&#125; onClick=&#123;this.swithHeader.bind(this)&#125;&gt; &lt;h1&gt;这是头部&lt;/h1&gt; &lt;/header&gt; ) &#125;&#125; css模块化css模块化就是在css引入的时候的第二种方法，引入css文件，给组件的ClassName赋值 123456import '../css/style.css' return ( &lt;header className="smallFontSize"&gt; &lt;h1&gt;这是头部&lt;/h1&gt; &lt;/header&gt; ) css与React内联样式互转如果你有一个很大的css文件，在开发React-native的时候，你只能使用内联样式，这时你可以使用在线转换工具把css转换为React内联样式，转换工具地址 Ant Design框架Ant Design是蚂蚁金服出的一个React UI框架，其中有一部分是介绍设计审美的，是非常值得一看的 通过https://ant.design/docs/react/use-with-create-react-app-cn进行使用 引入Ant Design现在从 yarn 或 npm 安装并引入 antd。 1$ yarn add antd 修改 src/App.js，引入 antd 的按钮组件。 123456789101112131415import React, &#123; Component &#125; from &apos;react&apos;;import Button from &apos;antd/lib/button&apos;;import &apos;./App.css&apos;;class App extends Component &#123; render() &#123; return ( &lt;div className=&quot;App&quot;&gt; &lt;Button type=&quot;primary&quot;&gt;Button&lt;/Button&gt; &lt;/div&gt; ); &#125;&#125;export default App; 修改 src/App.css，在文件顶部引入 antd/dist/antd.css。 1234567@import &apos;~antd/dist/antd.css&apos;;.App &#123; text-align: center;&#125;... 好了，现在你应该能看到页面上已经有了 antd 的蓝色按钮组件，接下来就可以继续选用其他组件开发应用了。其他开发流程你可以参考 create-react-app 的官方文档。 React-RouterReact-Router用于页面之间的跳转 刷新部分页面内容如果需要刷新部分页面内容，可以用BrowserRouter或者是HashRouter当中的一个，引入方法如下 1import &#123;HashRouter as Router, Route, Link&#125; from "react-router-dom"; 然后在index类当中加入链接地址和Route 123456789101112131415161718192021222324252627export default class Index extends Component &#123; render() &#123; return ( &lt;Router&gt; &lt;div&gt; &lt;ul&gt; &lt;li&gt;&lt;Link to=&#123;`/`&#125;&gt;首页&lt;/Link&gt;&lt;/li&gt; &lt;li&gt;&lt;Link to=&#123;`/list1`&#125;&gt;list1&lt;/Link&gt;&lt;/li&gt; &lt;li&gt;&lt;Link to=&#123;`/list2`&#125;&gt;list2&lt;/Link&gt;&lt;/li&gt; &lt;/ul&gt; &lt;ComponentHeader/&gt; &lt;IndexBody userid=&#123;1111&#125;/&gt; &lt;ComponentFooter/&gt; &lt;Button type="primary marb10"&gt;button&lt;/Button&gt; &lt;Input placeholder="请输入内容" size="small"/&gt; &lt;App/&gt; &lt;div&gt; &lt;Route path='/list1' component=&#123;List&#125;/&gt; &lt;Route path='/list2' component=&#123;List2&#125;/&gt; &lt;/div&gt; &lt;/div&gt; &lt;/Router&gt; ) &#125;&#125;ReactDOM.render(&lt;Index/&gt;, document.getElementById('root'));、 Route是专门用来改变内容的，Route那一部分在哪，就改变哪一部分的内容，比如现在Route在&lt;APP /&gt;后面，那么就改变&lt;App /&gt;后面的内容 重新定向到新页面如果需要定向到新页面，需要用到Switch参数，导入方法是： 1import &#123;HashRouter as Router, Switch, Route, Link&#125; from "react-router-dom"; 此时需要将Index当成一个普通的类，嵌套到另一个export的类当中（因为一个js页面只能有1个export的类），比如我们现在定义一个Root类，在Root类当中定义一个Router，在Router中嵌套Switch方法（因为官方规定Switch只能在Router当中使用），再在Switch当中嵌套一堆Route，用于定于需要路由的地址（第一个地址默认解析，后面的在你点的时候解析），代码如下： 123456789101112131415161718192021222324252627282930313233343536373839class Index extends Component &#123; render() &#123; return ( &lt;div&gt; &lt;ul&gt; &lt;li&gt;&lt;Link to=&#123;`/`&#125;&gt;首页&lt;/Link&gt;&lt;/li&gt; &lt;li&gt;&lt;Link to=&#123;`/list1`&#125;&gt;list1&lt;/Link&gt;&lt;/li&gt; &lt;li&gt;&lt;Link to=&#123;`/list2`&#125;&gt;list2&lt;/Link&gt;&lt;/li&gt; &lt;/ul&gt; &lt;ComponentHeader/&gt; &lt;IndexBody userid=&#123;1111&#125;/&gt; &lt;ComponentFooter/&gt; &lt;Button type="primary marb10"&gt;button&lt;/Button&gt; &lt;Input placeholder="请输入内容" size="small"/&gt; &lt;App/&gt; &lt;/div&gt; ) &#125;&#125;export default class Root extends Component &#123; render() &#123; return ( &lt;Router&gt; &lt;div&gt; &lt;Switch&gt; &#123;/*第一个默认解析*/&#125; &lt;Route exact path='/' component=&#123;Index&#125;/&gt; &lt;Route path='/list1' component=&#123;List&#125;/&gt; &lt;Route path='/list2' component=&#123;List2&#125;/&gt; &lt;/Switch&gt; &lt;/div&gt; &lt;/Router&gt; ) &#125;&#125;ReactDOM.render(&lt;Root/&gt;, document.getElementById('root')); 网站开发常用技巧及资源chrome模拟手机端直接在chrome的开发者工具中点审查元素旁边的按钮，就可以模拟手机的显示效果，还可以显示手机边框 findIcon找图标一个非常好的网站图标资源网站，地址：https://www.iconfinder.com/ 项目实战开发pc端页头的开发用到ant design的menu组件，还有ant desing的flex布局，flex布局将整个页面一共分为24列，我们这里左右各空2列，4列用于放logo，16列用于放menu 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374//pc_header.jsimport React, &#123;Component&#125; from 'react';// import ReactDOM from 'react-dom';import &#123;Row, Col, Menu, Icon&#125; from 'antd';import logo from '../img/logo.png'import '../css/pc.css'class PCHeader extends Component &#123; constructor(props) &#123; super(props); this.state = &#123; current : "top"&#125; &#125; render() &#123; return ( &lt;header&gt; &lt;Row&gt; &lt;Col span=&#123;2&#125;/&gt; &lt;Col span=&#123;4&#125;&gt; &lt;a href="/" className="logo"&gt; &lt;img src=&#123;logo&#125; alt="logo"/&gt; &lt;span&gt;ReactNews&lt;/span&gt; &lt;/a&gt; &lt;/Col&gt; &lt;Col span=&#123;16&#125;&gt; &lt;Menu mode="horizontal" selectedKeys=&#123;[this.state.current]&#125;&gt; &lt;Menu.Item key="top"&gt; &lt;Icon type="appstore" /&gt;头条 &lt;/Menu.Item&gt; &lt;Menu.Item key="shehui"&gt; &lt;Icon type="appstore" /&gt;社会 &lt;/Menu.Item&gt; &lt;Menu.Item key="guonei"&gt; &lt;Icon type="appstore" /&gt;国内 &lt;/Menu.Item&gt; &lt;Menu.Item key="guoji"&gt; &lt;Icon type="appstore" /&gt;国际 &lt;/Menu.Item&gt; &lt;Menu.Item key="yule"&gt; &lt;Icon type="appstore" /&gt;娱乐 &lt;/Menu.Item&gt; &lt;Menu.Item key="tiyu"&gt; &lt;Icon type="appstore" /&gt;体育 &lt;/Menu.Item&gt; &lt;Menu.Item key="keji"&gt; &lt;Icon type="appstore" /&gt;科技 &lt;/Menu.Item&gt; &lt;Menu.Item key="shishang"&gt; &lt;Icon type="appstore" /&gt;时尚 &lt;/Menu.Item&gt; &lt;/Menu&gt; &lt;/Col&gt; &lt;Col span=&#123;2&#125;/&gt; &lt;/Row&gt; &lt;/header&gt; ); &#125;&#125;PCHeader.propTypes = &#123;&#125;;export default PCHeader; 123456789101112131415/*pc.css*/.logo&#123; align-items: center; display: flex;&#125;.logo img&#123; width: 48px; height: 48px;&#125;.logo span&#123; font-size: 24px; padding-left: 5px;&#125; 注意**：引入图片的时候要用import的方法来引入，不然会找不到图片 menu菜单有两个属性，mode用于控制菜单的水平或者是竖直，selectedKeys用于设置一开始选中的标签 mode=&quot;horizontal&quot; selectedKeys={[this.state.current]} 移动端header的开发要判断是pc端还是移动端用到一个react-responsive这个库，通过npm install --save react-responsive进行安装 在index.js中进行判断是pc则返回fc端index，是手机则返回手机端index 1234567891011121314class Root extends Component &#123; render() &#123; return ( &lt;div&gt; &lt;MediaQuery query="(min-device-width: 1224px)"&gt; &lt;PCIndex/&gt; &lt;/MediaQuery&gt; &lt;MediaQuery query="(max-device-width: 1224px)"&gt; &lt;MobileIndex/&gt; &lt;/MediaQuery&gt; &lt;/div&gt; ) &#125;&#125; 在mobile header中先放入图标和名称，别的先不动 123456789101112// mobile_header.jsclass MobileHeader extends Component &#123;render() &#123; return ( &lt;header id="mobileheader"&gt; &lt;a href="/" className="logo"&gt; &lt;img src=&#123;logo&#125; alt="logo"/&gt; &lt;span&gt;ReactNews&lt;/span&gt; &lt;/a&gt; &lt;/header&gt; ） &#125; 12345678910111213141516171819202122232425html&#123; font-size: 50px;&#125;/*mobile.css*/#mobileheader&#123; flex: 1; padding-left: 5px;&#125;#mobileheader&#123; border-bottom: 1px solid #2db7f5;&#125;#mobileheader img&#123; height: 50px;&#125;#mobileheader span&#123; font-size: 35px; vertical-align: center; padding-left: 10px; color: #2db7f5;&#125; mobile及pc的footer开发两者内容基本相同，这里贴出一个mobile_footer.js 12345678910111213141516171819202122import React,&#123;Component&#125; from 'react';import &#123;Row, Col&#125; from 'antd';class MobileFooter extends Component &#123; render() &#123; return ( &lt;div&gt; &lt;Row&gt; &lt;Col span=&#123;2&#125;/&gt; &lt;Col span=&#123;20&#125; className="footer"&gt; @ 2018 ReactNews. All Rights Reseved. &lt;/Col&gt; &lt;Col span=&#123;2&#125;/&gt; &lt;/Row&gt; &lt;/div&gt; ); &#125;&#125;export default MobileFooter;]]></content>
      <categories>
        <category>js</category>
        <category>前端</category>
      </categories>
      <tags>
        <tag>js</tag>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo升级]]></title>
    <url>%2F2018%2F06%2F05%2Fhexo%E5%8D%87%E7%BA%A7%2F</url>
    <content type="text"><![CDATA[其实所谓的升级，也很简单，先进入Blog的目录，看看到底有哪些需要更新的： 12345678npm outdatedPackage Current Wanted Latest Locationhexo-deployer-git 0.2.0 0.2.0 0.3.1 hexo-sitehexo-generator-search 1.0.4 1.0.4 2.2.1 hexo-sitehexo-generator-seo-friendly-sitemap 0.0.19 0.0.19 0.0.21 hexo-sitehexo-renderer-ejs 0.2.0 0.2.0 0.3.1 hexo-sitehexo-renderer-marked 0.2.11 0.2.11 0.3.2 hexo-sitehexo-server 0.2.2 0.2.2 0.3.1 hexo-site 嗯，还是有不少东西需要更新的，简单修改一下 package.json 文件： 1234567891011121314151617181920212223242526&#123; "name": "hexo-site", "version": "0.0.0", "private": true, "hexo": &#123; "version": "3.5.0" &#125;, "dependencies": &#123; "hexo": "^3.5.0", "hexo-deployer-git": "^0.3.1", "hexo-deployer-rsync": "^0.1.3", "hexo-excerpt": "^1.1.2", "hexo-generator-archive": "^0.1.5", "hexo-generator-category": "^0.1.3", "hexo-generator-feed": "^1.2.0", "hexo-generator-index": "^0.2.1", "hexo-generator-search": "^2.2.1", "hexo-generator-seo-friendly-sitemap": "0.0.21", "hexo-generator-sitemap": "^1.1.2", "hexo-generator-tag": "^0.2.0", "hexo-renderer-ejs": "^0.3.1", "hexo-renderer-marked": "^0.3.2", "hexo-renderer-stylus": "^0.3.3", "hexo-server": "^0.3.1" &#125;&#125; 把 Hexo 的版本号从 3.3.8 修改为 3.5.0，其他的也根据情况更新一下。 都修改好了以后，就 npm 更新一下： 1npm install --save 搞掂，运行 Hexo 看看效果： 1234567891011121314151617$ hexo versionhexo: 3.5.0hexo-cli: 1.0.4os: Darwin 17.4.0 darwin x64http_parser: 2.7.0node: 8.9.4v8: 6.1.534.50uv: 1.15.0zlib: 1.2.11ares: 1.10.1-DEVmodules: 57nghttp2: 1.25.0openssl: 1.0.2nicu: 59.1unicode: 9.0cldr: 31.0.1tz: 2017b]]></content>
      <categories>
        <category>hexo</category>
        <category>工具</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JS Promise用法]]></title>
    <url>%2F2018%2F06%2F05%2FJS-Promise%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[基本用法Promise对象就是一个异步调用的对象，有两个参数resolve和reject，执行调用成功的情况下使用resolve，失败的时候使用reject。 在keystroke项目中，我用到了下面这个例子 123456789101112131415161718192021222324252627282930313233343536registerKeystroke() &#123; var username = $('#id_username').val(); var password = $('#id_password').val(); return this._sendRequest('/pc_data/', &#123;'username': username, 'password': password&#125;) .then(res1 =&gt; &#123; console.log('res1:' + res1); this._change_status(res1.toString()); return res1; &#125;) .then((res2) =&gt; &#123; console.log('res2:' + res2); return this._sendRequest('/server/register_keystroke/', &#123; 'login': username, 'password': password, "login_timestamps": this._loginInput.timeStamps, "password_timestamps": this._passwordInput.timeStamps, &#125;); &#125; ) .then( res3 =&gt; &#123; console.log('res3:' + res3); return res3; &#125;) _sendRequest(url, data) &#123; return new Promise((resolve) =&gt; &#123; $.post( url, JSON.stringify(data), (data) =&gt; resolve(data), 'json' ); &#125;) &#125;&#125; 先发送第一个请求到/pc_data/，如果成功，再发送一个到/server/register_keystroke/， ES6原生提供了Promise对象。所谓Promise对象，就是代表了未来某个将要发生的事件（通常是一个异步操作）。它的好处在于，有了Promise对象，就可以将异步操作以同步操作的流程表达出来，避免了层层嵌套的回调函数。此外，Promise对象还提供了一整套完整的接口，使得可以更加容易地控制异步操作。Promise对象的概念的详细解释，请参考《JavaScript标准参考教程》。 ES6的Promise对象是一个构造函数，用来生成Promise实例。下面是Promise对象的基本用法。 12345678910111213var promise = new Promise(function(resolve, reject) &#123; if (/* 异步操作成功 */)&#123; resolve(value); &#125; else &#123; reject(error); &#125;&#125;);promise.then(function(value) &#123; // success&#125;, function(value) &#123; // failure&#125;); 上面代码表示，Promise构造函数接受一个函数作为参数，该函数的两个参数分别是resolve方法和reject方法。如果异步操作成功，则用resolve方法将Promise对象的状态变为“成功”（即从pending变为resolved）；如果异步操作失败，则用reject方法将状态变为“失败”（即从pending变为rejected）。 promise实例生成以后，可以用then方法分别指定resolve方法和reject方法的回调函数。 下面是一个使用Promise对象的简单例子。 123456789function timeout(ms) &#123; return new Promise((resolve) =&gt; &#123; setTimeout(resolve, ms); &#125;);&#125;timeout(100).then(() =&gt; &#123; console.log('done');&#125;); 上面代码的timeout方法返回一个Promise实例对象，表示一段时间以后改变自身状态，从而触发then方法绑定的回调函数。 下面是一个用Promise对象实现的Ajax操作的例子。 1234567891011121314151617181920212223242526var getJSON = function(url) &#123; var promise = new Promise(function(resolve, reject)&#123; var client = new XMLHttpRequest(); client.open("GET", url); client.onreadystatechange = handler; client.responseType = "json"; client.setRequestHeader("Accept", "application/json"); client.send(); function handler() &#123; if (this.status === 200) &#123; resolve(this.response); &#125; else &#123; reject(new Error(this.statusText)); &#125; &#125;; &#125;); return promise;&#125;;getJSON("/posts.json").then(function(json) &#123; console.log('Contents: ' + json);&#125;, function(error) &#123; console.error('出错了', error);&#125;); 上面代码中，resolve方法和reject方法调用时，都带有参数。它们的参数会被传递给回调函数。reject方法的参数通常是Error对象的实例，而resolve方法的参数除了正常的值以外，还可能是另一个Promise实例，比如像下面这样。 12345678var p1 = new Promise(function(resolve, reject)&#123; // ... some code&#125;);var p2 = new Promise(function(resolve, reject)&#123; // ... some code resolve(p1);&#125;) 上面代码中，p1和p2都是Promise的实例，但是p2的resolve方法将p1作为参数，这时p1的状态就会传递给p2。如果调用的时候，p1的状态是pending，那么p2的回调函数就会等待p1的状态改变；如果p1的状态已经是fulfilled或者rejected，那么p2的回调函数将会立刻执行。 Promise.prototype.then方法：链式操作Promise.prototype.then方法返回的是一个新的Promise对象，因此可以采用链式写法。 12345getJSON("/posts.json").then(function(json) &#123; return json.post;&#125;).then(function(post) &#123; // proceed&#125;); 上面的代码使用then方法，依次指定了两个回调函数。第一个回调函数完成以后，会将返回结果作为参数，传入第二个回调函数。 如果前一个回调函数返回的是Promise对象，这时后一个回调函数就会等待该Promise对象有了运行结果，才会进一步调用。 12345getJSON("/post/1.json").then(function(post) &#123; return getJSON(post.commentURL);&#125;).then(function(comments) &#123; // 对comments进行处理&#125;); 这种设计使得嵌套的异步操作，可以被很容易得改写，从回调函数的“横向发展”改为“向下发展”。 Promise.prototype.catch方法：捕捉错误Promise.prototype.catch方法是Promise.prototype.then(null, rejection)的别名，用于指定发生错误时的回调函数。 123456getJSON("/posts.json").then(function(posts) &#123; // some code&#125;).catch(function(error) &#123; // 处理前一个回调函数运行时发生的错误 console.log('发生错误！', error);&#125;); Promise对象的错误具有“冒泡”性质，会一直向后传递，直到被捕获为止。也就是说，错误总是会被下一个catch语句捕获。 1234567getJSON("/post/1.json").then(function(post) &#123; return getJSON(post.commentURL);&#125;).then(function(comments) &#123; // some code&#125;).catch(function(error) &#123; // 处理前两个回调函数的错误&#125;); Promise.all方法，Promise.race方法Promise.all方法用于将多个Promise实例，包装成一个新的Promise实例。 1var p = Promise.all([p1,p2,p3]); 上面代码中，Promise.all方法接受一个数组作为参数，p1、p2、p3都是Promise对象的实例。（Promise.all方法的参数不一定是数组，但是必须具有iterator接口，且返回的每个成员都是Promise实例。） p的状态由p1、p2、p3决定，分成两种情况。 （1）只有p1、p2、p3的状态都变成fulfilled，p的状态才会变成fulfilled，此时p1、p2、p3的返回值组成一个数组，传递给p的回调函数。 （2）只要p1、p2、p3之中有一个被rejected，p的状态就变成rejected，此时第一个被reject的实例的返回值，会传递给p的回调函数。 下面是一个具体的例子。 12345678910// 生成一个Promise对象的数组var promises = [2, 3, 5, 7, 11, 13].map(function(id)&#123; return getJSON("/post/" + id + ".json");&#125;);Promise.all(promises).then(function(posts) &#123; // ...&#125;).catch(function(reason)&#123; // ...&#125;); Promise.race方法同样是将多个Promise实例，包装成一个新的Promise实例。 1var p = Promise.race([p1,p2,p3]); 上面代码中，只要p1、p2、p3之中有一个实例率先改变状态，p的状态就跟着改变。那个率先改变的Promise实例的返回值，就传递给p的返回值。 如果Promise.all方法和Promise.race方法的参数，不是Promise实例，就会先调用下面讲到的Promise.resolve方法，将参数转为Promise实例，再进一步处理。 Promise.resolve方法，Promise.reject方法有时需要将现有对象转为Promise对象，Promise.resolve方法就起到这个作用。 1var jsPromise = Promise.resolve($.ajax(&apos;/whatever.json&apos;)); 上面代码将jQuery生成deferred对象，转为一个新的ES6的Promise对象。 如果Promise.resolve方法的参数，不是具有then方法的对象（又称thenable对象），则返回一个新的Promise对象，且它的状态为fulfilled。 123456var p = Promise.resolve('Hello');p.then(function (s)&#123; console.log(s)&#125;);// Hello 上面代码生成一个新的Promise对象的实例p，它的状态为fulfilled，所以回调函数会立即执行，Promise.resolve方法的参数就是回调函数的参数。 如果Promise.resolve方法的参数是一个Promise对象的实例，则会被原封不动地返回。 Promise.reject(reason)方法也会返回一个新的Promise实例，该实例的状态为rejected。Promise.reject方法的参数reason，会被传递给实例的回调函数。 123456var p = Promise.reject('出错了');p.then(null, function (s)&#123; console.log(s)&#125;);// 出错了 上面代码生成一个Promise对象的实例p，状态为rejected，回调函数会立即执行。]]></content>
      <categories>
        <category>JavaScript</category>
      </categories>
      <tags>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FRP反向代理软件的使用（转）]]></title>
    <url>%2F2018%2F05%2F31%2FFRP%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E8%BD%AF%E4%BB%B6%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[对于没有公网 IP 的内网用户来说，远程管理或在外网访问内网机器上的服务是一个问题。通常解决方案就是用内网穿透工具将内网的服务穿透到公网中，便于远程管理和在外部访问。内网穿透的工具很多，之前也介绍过 Ngrok、Localtunnel。 今天给大家介绍另一款好用内网穿透工具 FRP，FRP 全名：Fast Reverse Proxy。FRP 是一个使用 Go 语言开发的高性能的反向代理应用，可以帮助您轻松地进行内网穿透，对外网提供服务。FRP 支持 TCP、UDP、HTTP、HTTPS等协议类型，并且支持 Web 服务根据域名进行路由转发。 FRP 项目地址：https://github.com/fatedier/frp FRP 的作用 利用处于内网或防火墙后的机器，对外网环境提供 HTTP 或 HTTPS 服务。 对于 HTTP, HTTPS 服务支持基于域名的虚拟主机，支持自定义域名绑定，使多个域名可以共用一个 80 端口。 利用处于内网或防火墙后的机器，对外网环境提供 TCP 和 UDP 服务，例如在家里通过 SSH 访问处于公司内网环境内的主机。 FRP 架构 FRP 安装FRP 采用 Go 语言开发，支持 Windows、Linux、MacOS、ARM等多平台部署。FRP 安装非常容易，只需下载对应系统平台的软件包，并解压就可用了。 这里以 Linux 为例，为了方便管理我们把解压后的目录重命名为 frp ： 123$ wget https://github.com/fatedier/frp/releases/download/v0.15.1/frp_0.15.1_linux_amd64.tar.gz$ tar xzvf frp_0.15.1_linux_amd64.tar.gz$ mv frp_0.15.1_linux_amd64 frp 更多平台的软件包下载地址：https://github.com/fatedier/frp/releases FRP 配置FRP 服务端配置配置 FRP 服务端的前提条件是需要一台具有公网 IP 的设备，得益于 FRP 是 Go 语言开发的，具有良好的跨平台特性。你可以在 Windows、Linux、MacOS、ARM等几乎任何可联网设备上部署。 这里以 Linux 为例，FRP 默认给出两个服务端配置文件，一个是简版的 frps.ini，另一个是完整版本 frps_full.ini。 我们先来看看简版的 frps.ini，通过这个配置可以快速的搭建起一个 FRP 服务端。 1234$ cat frps.ini[common]bind_port = 7000 默认配置中监听的是 7000 端口，可根据自己实际情况修改。 启动 FRP 服务端 1234$ ./frps -c ./frps.ini2018/01/25 10:52:45 [I] [service.go:96] frps tcp listen on 0.0.0.0:70002018/01/25 10:52:45 [I] [main.go:112] Start frps success2018/01/25 10:52:45 [I] [main.go:114] PrivilegeMode is enabled, you should pay more attention to security issues 通过上面简单的两步就可以成功启动一个监听在 7000 端口的 FRP 服务端。 FRP 客户端配置和 FRP 服务端类似，FRP 默认也给出两个客户端配置文件，一个是简版的 frpc.ini，另一个是完整版本 frpc_full.ini。 这里同样以简版的 frpc.ini 文件为例，假设 FRP 服务端所在服务器的公网 IP 为 4.3.2.1。 1234567$ vim frpc.ini[common]# server_addr 为 FRP 服务端的公网 IPserver_addr = 4.3.2.1# server_port 为 FRP 服务端监听的端口server_port = 7000 启动 FRP 客户端 123456$ ./frpc -c ./frpc.ini2018/01/25 11:15:49 [I] [proxy_manager.go:284] proxy removed: []2018/01/25 11:15:49 [I] [proxy_manager.go:294] proxy added: []2018/01/25 11:15:49 [I] [proxy_manager.go:317] visitor removed: []2018/01/25 11:15:49 [I] [proxy_manager.go:326] visitor added: []2018/01/25 11:15:49 [I] [control.go:240] [83775d7388b8e7d9] login to server success, get run id [83775d7388b8e7d9], server udp port [0] 这样就可以成功在 FRP 服务端上成功建立一个客户端连接，当然现在还并不能对外提供任何内网机器上的服务，因为我们并还没有在 FRP 服务端注册任何内网服务的端口。 FRP 使用实例下面我们就来看几个常用的例子，通过这些例子来了解下 FRP 是如何实现内网服务穿透的。 通过 TCP 访问内网机器这里以访问 SSH 服务为例， 修改 FRP 客户端配置文件 frpc.ini 文件并增加如下内容： 1234567$ cat frpc.ini[ssh]type = tcplocal_ip = 127.0.0.1local_port = 22remote_port = 6000 启动 FRP 客户端 1234567$ ./frpc -c ./frpc.ini2018/01/25 12:21:23 [I] [proxy_manager.go:284] proxy removed: []2018/01/25 12:21:23 [I] [proxy_manager.go:294] proxy added: [ssh]2018/01/25 12:21:23 [I] [proxy_manager.go:317] visitor removed: []2018/01/25 12:21:23 [I] [proxy_manager.go:326] visitor added: []2018/01/25 12:21:23 [I] [control.go:240] [3b468a55191341cb] login to server success, get run id [3b468a55191341cb], server udp port [0]2018/01/25 12:21:23 [I] [control.go:165] [3b468a55191341cb] [ssh] start proxy success 这样就在 FRP 服务端上成功注册了一个端口为 6000 的服务，接下来我们就可以通过这个端口访问内网机器上 SSH 服务，假设用户名为 mike： 1$ ssh -oPort=6000 mike@4.3.2.1 通过自定义域名访问部署于内网的 Web 服务有时需要在公有网络通过域名访问我们在本地环境搭建的 Web 服务，但是由于本地环境机器并没有公网 IP，无法将域名直接解析到本地的机器。 现在通过 FRP 就可以很容易实现这一功能，这里以 HTTP 服务为例：首先修改 FRP 服务端配置文件，通过 vhost_http_port 参数来设置 HTTP 访问端口，这里将 HTTP 访问端口设为 80。 1234$ vim frps.ini[common]bind_port = 7000vhost_http_port = 80 启动 FRP 服务端 12345$ ./frps -c ./frps.ini2018/01/25 13:33:26 [I] [service.go:96] frps tcp listen on 0.0.0.0:70002018/01/25 13:33:26 [I] [service.go:125] http service listen on 0.0.0.0:802018/01/25 13:33:26 [I] [main.go:112] Start frps success2018/01/25 13:33:26 [I] [main.go:114] PrivilegeMode is enabled, you should pay more attention to security issues 其次我们在修改 FRP 客户端配置文件并增加如下内容： 123456$ vim frpc.ini[web]type = httplocal_port = 80custom_domains = mike.hi-linux.com 这里通过 local_port 和 custom_domains 参数来设置本地机器上 Web 服务对应的端口和自定义的域名，这里我们分别设置端口为 80，对应域名为 mike.hi-linux.com。 启动 FRP 客户端 12345678$ ./frpc -c ./frpc.ini2018/01/25 13:56:11 [I] [proxy_manager.go:284] proxy removed: []2018/01/25 13:56:11 [I] [proxy_manager.go:294] proxy added: [web ssh]2018/01/25 13:56:11 [I] [proxy_manager.go:317] visitor removed: []2018/01/25 13:56:11 [I] [proxy_manager.go:326] visitor added: []2018/01/25 13:56:11 [I] [control.go:240] [296fe9e31a551e07] login to server success, get run id [296fe9e31a551e07], server udp port [0]2018/01/25 13:56:11 [I] [control.go:165] [296fe9e31a551e07] [web] start proxy success2018/01/25 13:56:11 [I] [control.go:165] [296fe9e31a551e07] [ssh] start proxy success 最后将 mike.hi-linux.com 的域名 A 记录解析到 FRP 服务器的公网 IP 上，现在便可以通过 http://mike.hi-linux.com:8080 这个 URL访问到处于内网机器上对应的 Web 服务。 HTTPS 服务配置方法类似，只需将 vhost_http_port 替换为 vhost_https_port， type 设置为 https 即可。 多个web应用的情况： 服务器端配置：frps.ini 12345[common]bind_port = 7000vhost_http_port = 80privilege_token = xxxxxxsubdomain_host = drawon.site 客户端配置：frpc.ini 12345678910111213141516171819202122232425[common]server_addr = 144.xxx.xxx.xxxserver_port = 7000privilege_token = xxxxxx[ssh]type = tcplocal_ip = 127.0.0.1local_port = 22remote_port = 6000[web]type = httplocal_port = 8891subdomain = dj[web1]type = httplocal_port = 8890subdomain = jupyter[web2]type = httplocal_port = 8892subdomain = data 在本地的8890,8891,8892端口部署三个网页，记得打开linux防火墙端口，然后在你的web控制台中，将dj,data,jupyter三个二级域名都绑定到A类型的解析，解析地址为frps运行的服务器地址。 通过密码保护你的 Web 服务由于所有客户端共用一个 FRP 服务端的 HTTP 服务端口，任何知道你的域名和 URL 的人都能访问到你部署在内网的 Web 服务，但是在某些场景下需要确保只有限定的用户才能访问。 FRP 支持通过 HTTP Basic Auth 来保护你的 Web 服务，使用户需要通过用户名和密码才能访问到你的服务。需要实现此功能主要需要在 FRP 客户端的配置文件中添加用户名和密码的设置。 12345678910$ vim frpc.ini[web]type = httplocal_port = 80custom_domains = mike.hi-linux.com# 设置认证的用户名http_user = abc# 设置认证的密码http_pwd = abc 这时访问 http://mike.hi-linux.com:8080 这个 URL 时就需要输入配置的用户名和密码才能访问。 该功能目前仅限于 HTTP 类型的代理。 给 Web 服务增加自定义二级域名在多人同时使用一个 FRP 服务端实现 Web 服务时，通过自定义二级域名的方式来使用会更加方便。 通过在 FRP 服务端的配置文件中配置 subdomain_host参数就可以启用该特性。之后在 FRP 客户端的 http、https 类型的代理中可以不配置 custom_domains，而是配置一个 subdomain 参数。 然后只需要将 *.{subdomain_host} 解析到 FRP 服务端所在服务器。之后用户可以通过 subdomain 自行指定自己的 Web 服务所需要使用的二级域名，并通过 {subdomain}.{subdomain_host} 来访问自己的 Web 服务。 首先我们在 FRP 服务端配置 subdomain_host 参数： 123$ vim frps.ini[common]subdomain_host = hi-linux.com 其次在 FRP 客户端配置文件配置 subdomain 参数： 12345$ vim frpc.ini[web]type = httplocal_port = 80subdomain = test 然后将泛域名 *.hi-linux.com 解析到 FRP 服务端所在服务器的公网 IP 地址。FRP 服务端 和 FRP 客户端都启动成功后，通过 test.hi-linux.com 就可以访问到内网的 Web 服务。 同一个 HTTP 或 HTTPS 类型的代理中 custom_domains 和 subdomain 可以同时配置。 需要注意的是如果 FPR 服务端配置了 subdomain_host，则 custom_domains 中不能是属于 subdomain_host 的子域名或者泛域名。 修改 Host Header通常情况下 FRP 不会修改转发的任何数据。但有一些后端服务会根据 HTTP 请求 header 中的 host 字段来展现不同的网站，例如 Nginx 的虚拟主机服务，启用 host-header 的修改功能可以动态修改 HTTP 请求中的 host 字段。 实现此功能只需要在 FRP 客户端配置文件中定义 host_header_rewrite 参数。 123456$ vim frpc.ini[web]type = httplocal_port = 80custom_domains = test.hi-linux.comhost_header_rewrite = dev.hi-linux.com 原来 HTTP 请求中的 host 字段 test.hi-linux.com 转发到后端服务时会被替换为 dev.hi-linux.com。 该功能仅限于 HTTP 类型的代理。 URL 路由FRP 支持根据请求的 URL 路径路由转发到不同的后端服务。要实现这个功能可通过 FRP 客户端配置文件中的 locations 字段来指定。 12345678910111213$ vim frpc.ini[web01]type = httplocal_port = 80custom_domains = web.hi-linux.comlocations = /[web02]type = httplocal_port = 81custom_domains = web.hi-linux.comlocations = /news,/about 按照上述的示例配置后，web.hi-linux.com 这个域名下所有以 /news 以及 /about 作为前缀的 URL 请求都会被转发到后端 web02 所在的后端服务，其余的请求会被转发到 web01 所在的后端服务。 目前仅支持最大前缀匹配，之后会考虑支持正则匹配。 通过 UDP 访问内网机器DNS 查询请求通常使用 UDP 协议，FRP 支持对内网 UDP 服务的穿透，配置方式和 TCP 基本一致。这里以转发到 Google 的 DNS 查询服务器 8.8.8.8 的 UDP 端口为例。 首先修改 FRP 客户端配置文件，并增加如下内容： 123456$ vim frpc.ini[dns]type = udplocal_ip = 8.8.8.8local_port = 53remote_port = 6001 要转发到内网 DNS 服务器只需把 local_ip 改成对应 IP 即可。 其次重新启动 FRP 客户端： 123456789$ ./frpc -c ./frpc.ini2018/01/25 14:54:17 [I] [proxy_manager.go:284] proxy removed: []2018/01/25 14:54:17 [I] [proxy_manager.go:294] proxy added: [ssh web dns]2018/01/25 14:54:17 [I] [proxy_manager.go:317] visitor removed: []2018/01/25 14:54:17 [I] [proxy_manager.go:326] visitor added: []2018/01/25 14:54:17 [I] [control.go:240] [33e1de8a771112a6] login to server success, get run id [33e1de8a771112a6], server udp port [0]2018/01/25 14:54:17 [I] [control.go:165] [33e1de8a771112a6] [ssh] start proxy success2018/01/25 14:54:17 [I] [control.go:165] [33e1de8a771112a6] [web] start proxy success2018/01/25 14:54:17 [I] [control.go:165] [33e1de8a771112a6] [dns] start proxy success 最后通过 dig 命令测试 UDP 包转发是否成功，预期会返回 www.google.com 域名的解析结果： 12345678910$ dig @4.3.2.1 -p 6001 www.google.com...;; QUESTION SECTION:;www.google.com. IN A;; ANSWER SECTION:www.google.com. 79 IN A 69.63.184.30... 转发 Unix 域套接字通过 TCP 端口访问内网的 Unix 域套接字，这里以和本地机器上的 Docker Daemon 通信为例。 首先修改 FRP 客户端配置文件，并增加如下内容： 123456$ vim frpc.ini[unix_domain_socket]type = tcpremote_port = 6002plugin = unix_domain_socketplugin_unix_path = /var/run/docker.sock 这里主要是使用 plugin 和 plugin_unix_path 两个参数启用了 unix_domain_socket 插件和配置对应的套接字路径。 其次重新启动 FRP 客户端： 1234567891011$ ./frpc -c ./frpc.ini2018/01/25 15:09:33 [I] [proxy_manager.go:284] proxy removed: []2018/01/25 15:09:33 [I] [proxy_manager.go:294] proxy added: [ssh web dns unix_domain_socket]2018/01/25 15:09:33 [I] [proxy_manager.go:317] visitor removed: []2018/01/25 15:09:33 [I] [proxy_manager.go:326] visitor added: []2018/01/25 15:09:33 [I] [control.go:240] [f6424f0deb8b6ff7] login to server success, get run id [f6424f0deb8b6ff7], server udp port [0]2018/01/25 15:09:33 [I] [control.go:165] [f6424f0deb8b6ff7] [ssh] start proxy success2018/01/25 15:09:33 [I] [control.go:165] [f6424f0deb8b6ff7] [web] start proxy success2018/01/25 15:09:33 [I] [control.go:165] [f6424f0deb8b6ff7] [dns] start proxy success2018/01/25 15:09:33 [I] [control.go:165] [f6424f0deb8b6ff7] [unix_domain_socket] start proxy success 最后通过 curl 命令查看 Docker 版本信息进行测试： 123$ curl http://4.3.2.1:6002/version&#123;&quot;Platform&quot;:&#123;&quot;Name&quot;:&quot;&quot;&#125;,&quot;Components&quot;:[&#123;&quot;Name&quot;:&quot;Engine&quot;,&quot;Version&quot;:&quot;17.12.0-ce&quot;,&quot;Details&quot;:&#123;&quot;ApiVersion&quot;:&quot;1.35&quot;,&quot;Arch&quot;:&quot;amd64&quot;,&quot;BuildTime&quot;:&quot;2017-12-27T20:12:29.000000000+00:00&quot;,&quot;Experimental&quot;:&quot;true&quot;,&quot;GitCommit&quot;:&quot;c97c6d6&quot;,&quot;GoVersion&quot;:&quot;go1.9.2&quot;,&quot;KernelVersion&quot;:&quot;4.9.60-linuxkit-aufs&quot;,&quot;MinAPIVersion&quot;:&quot;1.12&quot;,&quot;Os&quot;:&quot;linux&quot;&#125;&#125;],&quot;Version&quot;:&quot;17.12.0-ce&quot;,&quot;ApiVersion&quot;:&quot;1.35&quot;,&quot;MinAPIVersion&quot;:&quot;1.12&quot;,&quot;GitCommit&quot;:&quot;c97c6d6&quot;,&quot;GoVersion&quot;:&quot;go1.9.2&quot;,&quot;Os&quot;:&quot;linux&quot;,&quot;Arch&quot;:&quot;amd64&quot;,&quot;KernelVersion&quot;:&quot;4.9.60-linuxkit-aufs&quot;,&quot;Experimental&quot;:true,&quot;BuildTime&quot;:&quot;2017-12-27T20:12:29.000000000+00:00&quot;&#125; FRP 从 1.5 版本开始支持客户端热加载配置文件，并不用每次都重启客户端程序。具体方法在后文 FRP 客户端热加载配置文件部分讲解。 FRP 高级进阶给 FRP 服务端增加一个 Dashboard通过 Dashboard 可以方便的查看 FRP 的状态以及代理统计信息展示，要使用这个功能首先需要在 FRP 服务端配置文件中指定 Dashboard 服务使用的端口： 123456789101112131415$ vim frps.ini[common]# 指定 Dashboard 的监听的 IP 地址dashboard_addr = 0.0.0.0# 指定 Dashboard 的监听的端口dashboard_port = 7500# 指定访问 Dashboard 的用户名dashboard_user = admin# 指定访问 Dashboard 的端口dashboard_pwd = admin 其次重新启动 FRP 服务端： 1234567$ ./frps -c ./frps.ini2018/01/25 16:39:29 [I] [service.go:96] frps tcp listen on 0.0.0.0:70002018/01/25 16:39:29 [I] [service.go:125] http service listen on 0.0.0.0:80802018/01/25 16:39:29 [I] [service.go:164] Dashboard listen on 0.0.0.0:75002018/01/25 16:39:29 [I] [main.go:112] Start frps success2018/01/25 16:39:29 [I] [main.go:114] PrivilegeMode is enabled, you should pay more attention to security issues 最后通过 http://[server_addr]:7500 访问 Dashboard 界面，用户名密码默认都为 admin。 给 FRP 服务端加上身份验证默认情况下只要知道 FRP 服务端开放的端口，任意 FRP 客户端都可以随意在服务端上注册端口映射，这样对于在公网上的 FRP 服务来说显然不太安全。FRP 提供了身份验证机制来提高 FRP 服务端的安全性。要启用这一特性也很简单，只需在 FRP服务端和 FRP 客户端的 common 配置中启用 privilege_token 参数就行。 12[common]privilege_token = 12345678 启用这一特性后，只有 FRP 服务端和 FRP 客户端的 common 配置中的 privilege_token 参数一致身份验证才会通过，FRP 客户端才能成功在 FRP 服务端注册端口映射。否则就会注册失败，出现类似下面的错误： 12345672018/01/25 17:29:27 [I] [proxy_manager.go:284] proxy removed: []2018/01/25 17:29:27 [I] [proxy_manager.go:294] proxy added: [ssh web dns unix_domain_socket]2018/01/25 17:29:27 [I] [proxy_manager.go:317] visitor removed: []2018/01/25 17:29:27 [I] [proxy_manager.go:326] visitor added: []2018/01/25 17:29:27 [E] [control.go:230] authorization failed2018/01/25 17:29:27 [W] [control.go:109] login to server failed: authorization failedauthorization failed 需要注意的是 FRP 客户端所在机器和 FRP 服务端所在机器的时间相差不能超过 15 分钟，因为时间戳会被用于加密验证中，防止报文被劫持后被其他人利用。这个超时时间可以在配置文件中通过 authentication_timeout 这个参数来修改，单位为秒，默认值为 900，即 15 分钟。如果修改为 0，则 FRP 服务端将不对身份验证报文的时间戳进行超时校验。 FRP 客户端热加载配置文件当修改了 FRP 客户端中的配置文件，从 0.15 版本开始可以通过 frpc reload 命令来动态加载配置文件，通常会在 10 秒内完成代理的更新。 启用此功能需要在 FRP 客户端配置文件中启用 admin 端口，用于提供 API 服务。配置如下： 12345$ vim frpc.ini[common]admin_addr = 127.0.0.1admin_port = 7400 重启 FRP 客户端，以后就可通过热加载方式进行 FRP 客户端配置变更了。 1234567891011$ ./frpc -c ./frpc.ini2018/01/25 18:04:25 [I] [proxy_manager.go:326] visitor added: []2018/01/25 18:04:25 [I] [control.go:240] [3653b9a878f8acc7] login to server success, get run id [3653b9a878f8acc7], server udp port [0]2018/01/25 18:04:25 [I] [service.go:49] admin server listen on 127.0.0.1:74002018/01/25 18:04:25 [I] [control.go:165] [3653b9a878f8acc7] [ssh] start proxy success2018/01/25 18:04:25 [I] [control.go:165] [3653b9a878f8acc7] [web] start proxy success2018/01/25 18:04:25 [I] [control.go:165] [3653b9a878f8acc7] [dns] start proxy success2018/01/25 18:04:25 [I] [control.go:165] [3653b9a878f8acc7] [unix_domain_socket] start proxy success$ ./frpc reload -c ./frpc.inireload success 等待一段时间后客户端会根据新的配置文件创建、更新、删除代理。 需要注意的是 [common] 中的参数除了 start 外目前无法被修改。 启用 admin_addr 后，还可以通过 frpc status -c ./frpc.ini 命令在 FRP 客户端很方便的查看当前代理状态信息。 123456789101112131415$ ./frpc status -c ./frpc.iniProxy Status...TCPName Status LocalAddr Plugin RemoteAddr Errorssh running 127.0.0.1:22 4.3.2.1:6000unix_domain_socket running unix_domain_socket 4.3.2.1:6002UDPName Status LocalAddr Plugin RemoteAddr Errordns running 8.8.8.8:53 4.3.2.1:6001HTTPName Status LocalAddr Plugin RemoteAddr Errorweb running 127.0.0.1:80 mike.hi-linux.com:8080 给 FRP 服务端增加端口白名单为了防止 FRP 端口被滥用，FRP 提供了指定允许哪些端口被分配的功能。可通过 FRP 服务端的配置文件中 privilege_allow_ports参数来指定： 1234$ vim frps.ini[common]privilege_allow_ports = 2000-3000,3001,3003,4000-5000 privilege_allow_ports 可以配置允许使用的某个指定端口或者是一个范围内的所有端口，以 , 分隔，指定的范围以 - 分隔。 当使用不允许的端口注册时，就会注册失败。出现类似以下错误： 123456$ ./frpc status -c ./frpc.iniProxy Status...TCPName Status LocalAddr Plugin RemoteAddr Errorssh start error 127.0.0.1:22 4.3.2.1:60000 port not allowedunix_domain_socket start error unix_domain_socket 4.3.2.1:60002 port not allowed 启用 TCP 多路复用从 v0.10.0 版本开始，客户端和服务器端之间的连接支持多路复用，不再需要为每一个用户请求创建一个连接，使连接建立的延迟降低，并且避免了大量文件描述符的占用，使 FRP 可以承载更高的并发数。 该功能默认启用，如需关闭可以在 FRP 服务端配置文件和 FRP 客户端配置文件中配置，该配置项在服务端和客户端必须一致： 123# frps.ini 和 frpc.ini 中[common]tcp_mux = false FRP 底层通信启用 KCP 协议FRP 从 v0.12.0 版本开始，底层通信协议支持选择 KCP 协议，在弱网络环境下传输效率会提升明显，但是会有一些额外的流量消耗。 要开启 KCP 协议支持，首先要在 FRP 服务端配置文件中启用 KCP 协议支持： 12345$ vim frps.ini[common]bind_port = 7000# 指定一个 UDP 端口用于接收客户端请求 KCP 绑定的是 UDP 端口，可以和 bind_port 一样kcp_bind_port = 7000 其次是在 FRP 客户端配置文件指定需要使用的协议类型，目前只支持 TCP 和 KCP。其它代理配置不需要变更： 1234567$ vim frpc.ini[common]server_addr = 4.3.2.1# server_port 指定为 FRP 服务端里 kcp_bind_port 指定的端口server_port = 7000# 指定需要使用的协议类型，默认类型为 TCPprotocol = kcp 需要注意开放相关机器上的 UDP 端口的访问权限。 给 FRP 服务端配置连接池默认情况下，当用户请求建立连接后，FRP 服务端才会请求 FRP 客户端主动与后端服务建立一个连接。 当为指定的 FRP 服务端启用连接池功能后，FRP 会预先和后端服务建立起指定数量的连接，每次接收到用户请求后，会从连接池中取出一个连接和用户连接关联起来，避免了等待与后端服务建立连接以及 FRP 客户端 和 FRP 服务端之间传递控制信息的时间。 首先需要在 FRP 服务端配置文件中设置每个代理可以创建的连接池上限，避免大量资源占用，客户端设置超过此配置后会被调整到当前值： 123$ vim frps.ini[common]max_pool_count = 5 其次在 FRP 客户端配置文件中为客户端启用连接池，指定预创建连接的数量： 123$ vim frpc.ini[common]pool_count = 1 此功能比较适合有大量短连接请求时开启。 加密与压缩如果公司内网防火墙对外网访问进行了流量识别与屏蔽，例如禁止了 SSH 协议等，可通过设置 use_encryption = true，将 FRP 客户端 与 FRP 服务端之间的通信内容加密传输，将会有效防止流量被拦截。 如果传输的报文长度较长，通过设置 use_compression = true 对传输内容进行压缩，可以有效减小 FRP 客户端 与 FRP 服务端之间的网络流量，来加快流量转发速度，但是会额外消耗一些 CPU 资源。 这两个功能默认是不开启的，需要在 FRP 客户端配置文件中通过配置来为指定的代理启用加密与压缩的功能，压缩算法使用的是 snappy。 12345678$ vim frpc.ini[ssh]type = tcplocal_port = 22remote_port = 6000use_encryption = trueuse_compression = true 通过 FRP 客户端代理其它内网机器访问外网FRP 客户端内置了 http_proxy 和 socks5 插件，通过这两个插件可以使其它内网机器通过 FPR 客户端的的网络访问互联网。 要启用此功能，首先需要在 FRP 客户端配置文件中启用相关插件，这里以 http_proxy 插件为例： 12345678910$ vim frpc.ini[common]server_addr = 4.3.2.1server_port = 7000[http_proxy]type = tcpremote_port = 6000plugin = http_proxy 其次将需要通过这个代理访问外网的内部机器的代理地址设置为 4.3.2.1:6000，这样就可以通过 FRP 客户端机器的网络访问互联网了。 http_proxy 插件也支持认证机制，如果需要启用认证可通过配置参数 plugin_http_user 和 plugin_http_passwd 启用。 如需启用 Socks5 代理，只需将 plugin 的值更换为 socks5 即可。 通过代理连接 FRP 服务端在只能通过代理访问外网的环境内，FRP 客户端支持通过 HTTP_PROXY 参数来配置代理和 FRP 服务端进行通信。要使用此功能可以通过设置系统环境变量 HTTP_PROXY 或者通过在 FRP 客户端的配置文件中设置 http_proxy 参数来使用此功能。 1234567$ vim frpc.ini[common]server_addr = 4.3.2.1server_port = 7000protocol = tcphttp_proxy = http://user:pwd@4.3.2.2:8080 仅在 protocol = tcp 时生效，暂时不支持 kcp 协议。 安全地暴露内网服务对于一些比较敏感的服务如果直接暴露于公网上将会存在安全隐患，FRP 也提供了一种安全的转发方式 STCP。使用 STCP(secret tcp) 类型的代理可以避免让任何人都能访问到穿透到公网的内网服务，要使用 STCP 模式访问者需要单独运行另外一个 FRP 客户端。 下面就以创建一个只有自己能访问到的 SSH 服务代理为例，FRP 服务端和其它的部署步骤相同，主要区别是在 FRP 客户端上。 首先配置 FRP 客户端，和常规 TCP 转发不同的是这里不需要指定远程端口。 1234567891011$ vim frpc.ini[common]server_addr = 4.3.2.1server_port = 7000[secret_ssh]type = stcp# 只有 sk 一致的用户才能访问到此服务sk = abcdefglocal_ip = 127.0.0.1local_port = 22 其次在要访问这个服务的机器上启动另外一个 FRP 客户端，配置如下： 12345678910111213141516$ vim frpc.ini[common]server_addr = 4.3.2.1server_port = 7000[secret_ssh_visitor]type = stcp# STCP 的访问者role = visitor# 要访问的 STCP 代理的名字，和前面定义的相同。server_name = secret_ssh# 和前面定义的要一致sk = abcdefg# 绑定本地端口用于访问 ssh 服务bind_addr = 127.0.0.1bind_port = 6005 最后在本机启动一个 FRP 客户端，这样就可以通过本机 6005 端口对内网机器 SSH 服务进行访问，假设用户名为 mike： 12345678910$ ./frpc -c ./frpc.ini2018/01/26 15:03:24 [I] [proxy_manager.go:284] proxy removed: []2018/01/26 15:03:24 [I] [proxy_manager.go:294] proxy added: []2018/01/26 15:03:24 [I] [proxy_manager.go:317] visitor removed: []2018/01/26 15:03:24 [I] [proxy_manager.go:326] visitor added: [secret_ssh_visitor]2018/01/26 15:03:24 [I] [control.go:240] [60d2af2f68196537] login to server success, get run id [60d2af2f68196537], server udp port [0]2018/01/26 15:03:24 [I] [proxy_manager.go:235] [60d2af2f68196537] try to start visitor [secret_ssh_visitor]2018/01/26 15:03:24 [I] [proxy_manager.go:243] [secret_ssh_visitor] start visitor success$ ssh -oPort=6005 mike@127.0.0.1 点对点内网穿透在传输大量数据时如果都经过服务器中转的话，这样会对服务器端带宽压力比较大。FRP 提供了一种新的代理类型 XTCP来解决这个问题，XTCP 模式下可以在传输大量数据时让流量不经过服务器中转。 使用方式同 STCP 类似，需要在传输数据的两端都部署上 FRP 客户端上用于建立直接的连接。 首先在 FRP 服务端配置上增加一个 UDP 端口用于支持该类型的客户端: 12$ vim frps.inibind_udp_port = 7001 其次配置 FRP 客户端，和常规 TCP 转发不同的是这里不需要指定远程端口。 123456789101112$ vim frpc.ini[common]server_addr = 4.3.2.1server_port = 7000[p2p_ssh]type = xtcp# 只有 sk 一致的用户才能访问到此服务sk = abcdefglocal_ip = 127.0.0.1local_port = 22 然后在要访问这个服务的机器上启动另外一个 FRP 客户端，配置如下： 123456789101112131415$ vim frpc.ini[common]server_addr = 4.3.2.1server_port = 7000[p2p_ssh_visitor]type = xtcp# XTCP 的访问者role = visitor# 要访问的 XTCP 代理的名字server_name = p2p_sshsk = abcdefg# 绑定本地端口用于访问 ssh 服务bind_addr = 127.0.0.1bind_port = 6006 最后在本机启动一个 FRP 客户端，这样就可以通过本机 6006 端口对内网机器 SSH 服务进行访问，假设用户名为 mike： 12345678910$ ./frpc -c ./frpc.ini2018/01/26 16:01:52 [I] [proxy_manager.go:326] visitor added: [p2p_ssh_visitor secret_ssh_visitor]2018/01/26 16:01:52 [I] [control.go:240] [7c7e06878e11cc3c] login to server success, get run id [7c7e06878e11cc3c], server udp port [7001]2018/01/26 16:01:52 [I] [proxy_manager.go:235] [7c7e06878e11cc3c] try to start visitor [p2p_ssh_visitor]2018/01/26 16:01:52 [I] [proxy_manager.go:243] [p2p_ssh_visitor] start visitor success2018/01/26 16:01:52 [I] [proxy_manager.go:235] [7c7e06878e11cc3c] try to start visitor [secret_ssh_visitor]2018/01/26 16:01:52 [I] [proxy_manager.go:243] [secret_ssh_visitor] start visitor success$ ssh -oPort=6006 mike@127.0.0.1 目前 XTCP 模式还处于开发的初级阶段，并不能穿透所有类型的 NAT 设备，所以穿透成功率较低。穿透失败时可以尝试 STCP 的方式。 FRP 管理FRP 的部署安装比较简单，项目官方也没有提供相应的管理脚本。不过好在开源项目总是有网友热心提供部署和管理脚本。如果你觉得手动部署太麻烦，还可以使用下面的一键安装脚本。 项目地址：https://github.com/clangcn/onekey-install-shell/ 下载一键部署脚本12$ wget --no-check-certificate https://raw.githubusercontent.com/clangcn/onekey-install-shell/master/frps/install-frps.sh -O ./install-frps.sh$ chmod 700 ./install-frps.sh 安装 FRP 服务端这个一键部署脚本比较好用，为了提高国内用户下载安装包速度还提供了阿里云节点的安装源。整个脚本使用起来也比较简单，对一些常用的 FRP 服务端配置参数都做了交互式选择让用户可以方便的根据自己实际情况进行选择。脚本比较贴心的一点是对默认的公网地址进行了检测，省去了手动输入的麻烦。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136$ ./install-frps.sh installPlease select frps download url:[1].aliyun (default)[2].githubEnter your choice (1, 2 or exit. default [aliyun]):---------------------------------------Your select: aliyun---------------------------------------Loading network version for frps, please wait...frps Latest release file frp_0.15.1_linux_amd64.tar.gzLoading You Server IP, please wait...You Server IP:12.34.56.78Please input your server setting:Please input frps bind_port [1-65535](Default Server Port: 5443):7000frps bind_port: 7000Please input frps vhost_http_port [1-65535](Default vhost_http_port: 80):8080frps vhost_http_port: 8080Please input frps vhost_https_port [1-65535](Default vhost_https_port: 443):frps vhost_https_port: 443Please input frps dashboard_port [1-65535](Default dashboard_port: 6443):7500frps dashboard_port: 7500Please input dashboard_user (Default: admin):frps dashboard_user: adminPlease input dashboard_pwd (Default: IY0p1bOg):adminfrps dashboard_pwd: adminPlease input privilege_token (Default: 9BqswPpd1R0TfGR5):mikefrps privilege_token: mikePlease input frps max_pool_count [1-200](Default max_pool_count: 50):frps max_pool_count: 50##### Please select log_level #####1: info (default)2: warn3: error4: debug#####################################################Enter your choice (1, 2, 3, 4 or exit. default [1]):log_level: infoPlease input frps log_max_days [1-30](Default log_max_days: 3 day):frps log_max_days: 3##### Please select log_file #####1: enable (default)2: disable#####################################################Enter your choice (1, 2 or exit. default [1]):log_file: enable##### Please select tcp_mux #####1: enable (default)2: disable#####################################################Enter your choice (1, 2 or exit. default [1]):tcp_mux: true##### Please select kcp support #####1: enable (default)2: disable#####################################################Enter your choice (1, 2 or exit. default [1]):kcp support: true============== Check your input ==============You Server IP : 12.34.56.78Bind port : 7000kcp support : truevhost http port : 8080vhost https port : 443Dashboard port : 7500Dashboard user : adminDashboard password : adminPrivilege token : miketcp_mux : trueMax Pool count : 50Log level : infoLog max days : 3Log file : enable==============================================Press any key to start...or Press Ctrl+c to cancelfrps install path:/usr/local/frpsconfig file for frps ... donedownload frps ... donedownload /etc/init.d/frps... donesetting frps boot... done+--------------------------------------------------+| Manager for Frps, Written by Clang |+--------------------------------------------------+| Intro: http://koolshare.cn/thread-65379-1-1.html |+--------------------------------------------------+Starting Frps(0.15.1)... doneFrps (pid 3325)is running.+---------------------------------------------------------+| frps for Linux Server, Written by Clang |+---------------------------------------------------------+| A tool to auto-compile &amp; install frps on Linux |+---------------------------------------------------------+| Intro: http://koolshare.cn/thread-65379-1-1.html |+---------------------------------------------------------+Congratulations, frps install completed!==============================================You Server IP : 12.34.56.78Bind port : 7000KCP support : truevhost http port : 8080vhost https port : 443Dashboard port : 7500Privilege token : miketcp_mux : trueMax Pool count : 50Log level : infoLog max days : 3Log file : enable==============================================frps Dashboard : http://12.34.56.78:7500/Dashboard user : adminDashboard password : admin============================================== 配置 FRP 服务端1$ ./install-frps.sh config 更新 FRP 服务端1$ ./install-frps.sh update 卸载 FRP 服务端1$ ./install-frps.sh uninstall FRP 服务端日常管理FRP 服务端安装完成后，一键部署脚本还提供了一个日常管理 FRP 服务端的管理脚本来进行日常的启动、重启、停止等操作，非常的方便。 1Usage: /etc/init.d/frps &#123;start|stop|restart|status|config|version&#125; 参考文档http://www.google.comhttps://github.com/fatedier/frphttp://koolshare.cn/thread-65379-1-1.html]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vscode前端插件配置]]></title>
    <url>%2F2018%2F05%2F27%2Fvscode%E5%89%8D%E7%AB%AF%E6%8F%92%E4%BB%B6%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[vscode插件安装 Atom One Dark Theme 主题 VSCode Great Icons 图标主题 Beautify 美化vscode代码 Bracket Pair Colorizer 每一对括号用不同颜色区别 Code Runner node，python等代码不必开命令行即可运行 Eslint 语法检测 Git History git提交历史 GitLens 在代码中显示每一行代码的提交历史 HTML CSS Support vscode对html，css文件支持，便于你快速书写属性 Path Intellisense 路径识别苦战，比如书写图片路径时。遗憾就是，对webpack项目中的路径别名无法扩展 Prettier 格式化，使用大名鼎鼎的prettier对你的文件进行格式化，快捷键 alt+shift +F Python 添加对.py文件的支持，毕竟tab与空格的痛苦写过python的都知道 React Native Tools 添加对 React Native项目的支持，让便你书写es6以及jsx C/C++ 运行React Native项目时，有些文件的查看需要这个 Settings Sync 用于同步vscode配置（相对而言配置更复杂，可不安装） Sublime Text Keymap 启动sublimeText的快捷键配置。vscode上面自有一套快捷键设定，个人习惯sublime了 Vetur 添加对单文件.vue后缀文件的快速书写支持。computed,mounted等迅速书写 Vue 2 Snippets 新建vue模板（如何新建参考我另一篇文章） markdownlint 书写md文件的预览插件 language-stylus CSS预处理器styl后缀文件的识别扩展 View In Browser 迅速通过浏览器打开文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112&#123; // VScode主题配置 &quot;editor.tabSize&quot;: 2, &quot;editor.lineHeight&quot;: 24, &quot;editor.renderLineHighlight&quot;: &quot;none&quot;, &quot;editor.renderWhitespace&quot;: &quot;none&quot;, &quot;editor.fontFamily&quot;: &quot;Consolas&quot;, &quot;editor.fontSize&quot;: 15, &quot;editor.cursorBlinking&quot;: &quot;smooth&quot;, &quot;editor.multiCursorModifier&quot;: &quot;ctrlCmd&quot;, &quot;editor.formatOnPaste&quot;: true, // 是否允许自定义的snippet片段提示,比如自定义的vue片段开启后就可以智能提示 &quot;editor.snippetSuggestions&quot;: &quot;top&quot;, &quot;workbench.iconTheme&quot;: &quot;vscode-great-icons&quot;, &quot;workbench.colorTheme&quot;: &quot;One Dark Pro Vivid&quot;, &quot;workbench.startupEditor&quot;: &quot;newUntitledFile&quot;, &quot;html.suggest.angular1&quot;: false, &quot;html.suggest.ionic&quot;: false, &quot;files.trimTrailingWhitespace&quot;: true, // vetur插件格式化使用beautify内置规则 &quot;vetur.format.defaultFormatter.html&quot;: &quot;js-beautify-html&quot;, // VScode 文件搜索区域配置 &quot;search.exclude&quot;: &#123; &quot;**/dist&quot;: true, &quot;**/build&quot;: true, &quot;**/elehukouben&quot;: true, &quot;**/.git&quot;: true, &quot;**/.gitignore&quot;: true, &quot;**/.svn&quot;: true, &quot;**/.DS_Store&quot;: true, &quot;**/.idea&quot;: true, &quot;**/.vscode&quot;: false, &quot;**/yarn.lock&quot;: true, &quot;**/tmp&quot;: true &#125;, // 排除文件搜索区域，比如node_modules(贴心的默认设置已经屏蔽了) &quot;files.exclude&quot;: &#123; &quot;**/.idea&quot;: true, &quot;**/yarn.lock&quot;: true, &quot;**/tmp&quot;: true &#125;, // 配置文件关联，以便启用对应的智能提示，比如wxss使用css &quot;files.associations&quot;: &#123; &quot;*.vue&quot;: &quot;vue&quot;, &quot;*.wxss&quot;: &quot;css&quot; &#125;, // 配置emmet是否启用tab展开缩写 &quot;emmet.triggerExpansionOnTab&quot;: true, // 配置emmet对文件类型的支持，比如vue后缀文件按照html文件来进行emmet扩写 &quot;emmet.syntaxProfiles&quot;: &#123; &quot;vue-html&quot;: &quot;html&quot;, &quot;vue&quot;: &quot;html&quot;, &quot;javascript&quot;: &quot;javascriptreact&quot;, // xml类型文件默认都是单引号，开启对非单引号的emmet识别 &quot;xml&quot;: &#123; &quot;attr_quotes&quot;: &quot;single&quot; &#125; &#125;, // 在react的jsx中添加对emmet的支持 &quot;emmet.includeLanguages&quot;: &#123; &quot;jsx-sublime-babel-tags&quot;: &quot;javascriptreact&quot; &#125;, // 是否开启eslint检测 &quot;eslint.enable&quot;: false, // 文件保存时，是否自动根据eslint进行格式化 &quot;eslint.autoFixOnSave&quot;: false, // eslint配置文件 &quot;eslint.options&quot;: &#123; &quot;plugins&quot;: [ &quot;html&quot;, &quot;javascript&quot;, &#123; &quot;language&quot;: &quot;vue&quot;, &quot;autoFix&quot;: true &#125;, &quot;vue&quot; ] &#125;, // eslint能够识别的文件后缀类型 &quot;eslint.validate&quot;: [ &quot;javascript&quot;, &quot;javascriptreact&quot;, &quot;html&quot;, &quot;vue&quot;, &quot;typescript&quot;, &quot;typescriptreact&quot; ], // 快捷键方案,使用sublime的一套快捷键 &quot;sublimeTextKeymap.promptV3Features&quot;: true, // 格式化快捷键 shirt+alt+F // prettier进行格式化时是否安装eslint配置去执行，建议false &quot;prettier.eslintIntegration&quot;: true, // 如果为true，将使用单引号而不是双引号 &quot;prettier.singleQuote&quot;: true, // 细节,配置gitlen中git提交历史记录的信息显示情况 &quot;gitlens.advanced.messages&quot;: &#123; &quot;suppressCommitHasNoPreviousCommitWarning&quot;: false, &quot;suppressCommitNotFoundWarning&quot;: false, &quot;suppressFileNotUnderSourceControlWarning&quot;: false, &quot;suppressGitVersionWarning&quot;: false, &quot;suppressLineUncommittedWarning&quot;: false, &quot;suppressNoRepositoryWarning&quot;: false, &quot;suppressResultsExplorerNotice&quot;: false, &quot;suppressUpdateNotice&quot;: true, &quot;suppressWelcomeNotice&quot;: false &#125;, // 开启apicloud在vscode中的wifi真机同步 &quot;apicloud.port&quot;: &quot;23450&quot;, // 设置apicloud在vscode中的wifi真机同步根目录 &quot;apicloud.subdirectories&quot;: &quot;/apiclouduser&quot;, // git是否启用自动拉取 &quot;git.autofetch&quot;: true,&#125;]]></content>
      <categories>
        <category>编程学习</category>
        <category>工具</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vscode设置及插件同步]]></title>
    <url>%2F2018%2F05%2F25%2Fvscode%E8%AE%BE%E7%BD%AE%E5%8F%8A%E6%8F%92%E4%BB%B6%E5%90%8C%E6%AD%A5%2F</url>
    <content type="text"><![CDATA[vscode同步设置&amp;扩展插件首先安装同步插件： Settings Sync 第二步：进入你的github如图： 打开设置选项： 新建一个token： 如图： 记住这个token值 转到vscode 按shift+alt +u 在弹出窗里输入你的token,然后等下会生成syncSummary.txt文件在窗口中打开这样就算成功了。 syncSummary.txt这个文件里有个gist值或者到用户设置文件中查看gist的值，这个值用来你再另一台电脑上来下载你的设置，在设置中可以找到这个git的值 下载你的设置方法为：打开vscode——按alt+shift+d 在弹出窗里输入你的gist值，等待片刻便同步成功。 如果要重置同步设置：按ctrl+p 输入 ‘&gt;sync’ 就可以重新配置你的token来同步了]]></content>
      <categories>
        <category>编程学习</category>
        <category>工具</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Coursera-deeplearning-ai-（五）]]></title>
    <url>%2F2018%2F05%2F16%2FCoursera-deeplearning-ai-%EF%BC%88%E4%BA%94%EF%BC%89%2F</url>
    <content type="text"><![CDATA[这篇博文主要讲的是关于deeplearning.ai的第五门课程的内容，《Sequence Models》 Week one循环神经网络循环神经网络的主要应用：语音识别，音乐生成，感觉分类，DNA序列分析，机器翻译，视频行为识别，人名的识别 常用的符号 X：输入数据 $x^{(i) \langle t \rangle }$：第i个输入样本序列中的第t个值 $T_x^{(i)}$：第i个输入样本的长度 y：目标数据 $x^{(i) \langle t \rangle }$：第i个输出序列中的第t个值 单词的表示首先准备好一个字典，每个词一个one-hot向量，把出现的标记为1，没有出现的标记为0，如果遇到字典中不存在的单词，我们建立一个unknown的词，标记为unknown 为什么不用标准神经网络标准神经网络将单词的表示输入一个网络，然后再输出一个y的向量，但是 每个句子的长度不同，因此输入的x和输出的y的长度在变化 标准神经网络不会分享他们之间学到的特征信息 因此标准神经网络不适合于这个问题 循环神经网络先输入一个$x^{ \langle 1 \rangle }$，输出$y^{ \langle 1 \rangle }$和$a^{ \langle 1 \rangle }$；然后输入$x^{ \langle 2 \rangle }$，通过$a^{ \langle 1 \rangle }$的信息和$x^{ \langle 2 \rangle }$的信息共同输出$y^{ \langle 2 \rangle }$和$a^{ \langle 2 \rangle }$，后面的步骤相似，由之前的所有信息得到当前的输出y，右边是循环神经网络的另一种表示方式，不过在这门课当中我们用左边的表示方式，通常会构造一个$a^{ \langle 0 \rangle }$，一般构造为0向量 但是这样的循环神经网络有个缺点就是只利用了前面的信息，而没有利用后面的信息，比如在判断人名的情况下，我们要判断下图中的Teddy是不是一个人名，我们如果用循环神经网络只能利用前面的信息，下面两个图的判断结果应该相同，解决这个问题的方法是之后会讲解的双向循环神经网络(Bidirectional RNN) BRNN 循环神经网络中$a^{ \langle t \rangle }$和$y^{ \langle t \rangle }$的计算方法如下，$w{a \ }$如果和a相乘的时候就是$w{aa}$，和x相乘的时候就是$w{ax}$，注意这里所有层是共享的同一组参数。上下两个激活函数可以不同，一般来说$g_1$是tanh（偶尔也可以是Relu），$g_2$根据任务不同一般是sigmoid或softmax \begin{align} a^{\langle t \rangle} &= g_1(w_{aa}a^{ \langle t-1 \rangle } + w_{ax}x^{ \langle t \rangle }+b_a)\\\\ y^{ \langle t \rangle } &= g_2(w_{ya}a^{ \langle t \rangle } +b_y) \end{align}上面的公式可以通过矩阵进行简化，用$wa$表示$[w{aa}| w_{ax}]$的横排并列，用$[a^{ \langle t-1 \rangle },x^{ \langle t \rangle }]$表示$a^{ \langle t-1 \rangle }$ 与$x^{ \langle t \rangle }$的纵向stack，最后公式简化为下图右边的第一个和左边的最下面那个，即 \begin{align} a^{ \langle t \rangle } &= g(w_{a}[a^{ \langle t-1 \rangle } ,x^{ \langle t \rangle }]+b_a)\\\\ y^{ \langle t \rangle } &= g(w_{y}a^{ \langle t \rangle } +b_y) \end{align} 循环神经网络的反向传播循环神经网络的反向传播用到的损失函数就是逻辑回归中的交叉熵损失函数 不同类型的循环神经网络现在为止学到的循环神经网络的输入输出的大小是一样的，也存在一些不一样的情况，比如机器翻译中原句和目标句的长度可能就不一样 我们通过输入输出的数量的不同，进行划分，下图左边的是many-to-many RNN，并且输入数量等于输出的，比如之前的人名识别，中间是many-to-one RNN，比如情感分类，一大段话只需要输出一个情感值，也存在one-to-one的情况，不过很少见 还有one-to-many结构，比如音乐生成，给个数字生成一段音乐，还有many-to-many的输入输出长度不同的情况，比如机器翻译的应用 总结来说，RNN的不同结构有以下几种 语言建模和序列生成给定一句话：“cats average 15 hours of sleep a day”，首先你要对这句话进行标记 比如你用一个字典标注，这个字典包含10000个词，你此时还要生成两个额外的词，一个是&lt;EOS&gt;，表示end of sentence，句子的结束标志，还有一个是&lt;UNK&gt;，表示unkonwn words，未知单词 标记完之后你开始计算每个单词出现的概率，然后计算第二个单词在第一个单词出现的概率，计算第三个单词在第一、二个单词出现的概率，一直到最后一个单词 采样新序列我们之前计算每个$y^{ \langle t \rangle }$是通过选择最大的概率，但是在这里介绍一个新的方法，是通过随机采样作为下一个循环神经网络的输入，直到采样到&lt;UNK&gt;的时候结束 除了以单词作为字典，还可以用字母作为字典，可以处理位置单词的情况，但是这种方法计算量更大，用得很少 梯度消失RNN不擅长捕捉长期依赖关系，比如下图中的was和were和前面的cat和cats的搭配关系，如果中间隔了太多内容，那么他们之间的关系是很弱的 除了梯度消失以外还有梯度爆炸的问题，还有梯度爆炸的问题，这只需要进行梯度裁剪即可(gradient clapping)，将超过某个值的梯度按比例缩小后再减 Gated Recurrent Unit选通循环单元(Gated Recurrent Unint)能够很大程度上地改善循环神经网络无法学习长期依赖关系和梯度消失这两个问题。 我们先来看看普通的RNN unit，用$x^{ \langle t \rangle }$和$a^{ \langle t-1 \rangle }$计算出$a^{ \langle t \rangle }$，然后经过softmax计算出$\hat y^{ \langle t \rangle }$，过程如下图所示 我们再来看看Gated Recurrent Unit，首先引入一个C表示memory cell，引入一个$\Gamma$表示选通的值（gated），每次是否更新C的值由选通信号来决定，$\Gamma=1$则改变memory cell，$\Gamma=0$则不改变，我们用sigmoid函数来表示$\Gamma$，因为sigmoid函数的值大多数都在0和1附近，那么一个GRU单元的定义如下： 我们把公式整理一下： \begin{align} \tilde C&=\tanh(W_c[c^{ \langle t-1 \rangle },x^{ \langle t \rangle }]+b_c)\\\\ \Gamma_u&=\sigma(W_u[c^{ \langle t-1 \rangle },x^{ \langle t \rangle }]+b_u)\\\\ c^{ \langle t \rangle }&=\Gamma_u \times \tilde c^{ \langle t \rangle }+(1-\Gamma_u) c^{ \langle t-1 \rangle } \end{align}其中$\tilde C$表示C的更新值，$\Gamma_u$表示选通函数，有时候我们会再加上一个选通函数$\Gamma_r$，整个GRU的定义如下： \begin{align} \tilde C&=\tanh(W_c[\Gamma_r\times c^{ \langle t-1 \rangle },x^{ \langle t \rangle }]+b_c)\\\\ \Gamma_u&=\sigma(W_u[c^{ \langle t-1 \rangle },x^{ \langle t \rangle }]+b_u)\\\\ \Gamma_r&=\sigma(W_r[c^{ \langle t-1 \rangle },x^{ \langle t \rangle }]+b_r)\\\\ c^{ \langle t \rangle }&=\Gamma_u\times \tilde c^{ \langle t \rangle }+(1-\Gamma_u) c^{ \langle t-1 \rangle } \end{align}LSTMLSTM全称是(long short term memory)，长短期记忆 LSTM是GRU的更一般化的形式，其引入了另外两个选通参数$\Gamma_f$（forget）和$\Gamma_o$（output），还有这里的$\Gamma_u$表示的是update 我们来看一个图示的LSTM单元 双向循环神经网络(Biderectional RNN)目前为止，循环神经网络可以使用前面的信息，但是还不能使用之后的信息，要同时使用上下文信息，需要使用BRNN，双向循环神经网络 下图是一个4层的双向循环神经网络，不光有向前传播的，还有向后传播的，这样就可以同时利用前后文的信息，这个图中是没有循环部分的。标准双向循环神经网络有个缺点就是要整句话的信息才可以进行判断，在一些语音识别之类的任务的时候需要用的是更加复杂的BRNN。BRNN的结构如下图 深层RNN利用RNN,GRU,LSTM,BRNN综合形成一个深度循环神经网络 我们现在用方括号来代表所在的layer，比如现在有一个三层的RNN，来看看$a^{[2] \langle 3 \rangle }$是怎么计算的，它既有左边的值，又有下面的值，一起算出$a^{[2] \langle 3 \rangle }$，一般来说3层的RNN已经非常深了（因为计算量非常大），通常上面得到的y还可以通过几层普通的神经网络来获得，这样可以使模型更加复杂 Week Two词嵌入(Word Embedding)嵌入是一个数学概念，表示单射的，结构保持的映射。 词嵌入(Word Embedding)并不是要把单词进行镶嵌，而是把单词嵌入到另一个空间中，要做到单射和结构保持，重点关注的是映射。词嵌入主要是在NLP当中将单词映射成由实数构成的向量上。 最简单的词表达方式就是用一个one-hot向量表示，在你的字典中标出存在的位置。这种方法存在的缺陷就是同类的词汇之间的距离不一定很近，比如apple和orange之间的距离可能是很远的，但是他们都属于水果，这种深层的关系没有被挖掘 那么我们需要对词当中的特征进行表达，这就是word embedding，比如我们可以从下面这几个词里面学到大约300维度的特征，包括性别，是否与皇家有关等等，这就对每个词进行了特征表达，每个词都被镶嵌到一个300维的向量中，这样分类之后orange和apple的距离就很近了 词镶嵌的可视化，是将高维的词镶嵌转换到2维，这个方法叫做t-SNE，可以看到，同类的词汇距离更近 如何使用词嵌入我们得到了词嵌入向量之后，使用循环神经网络进行判别，比如在人名识别的任务中，我们先用大量的没有标记的词汇来学习词嵌入的表达，然后用可能10000个词来进行训练，最后进行判别，这是一种典型的迁移学习 因此基于词嵌入的方法，一共分为三步，第一步用大量数据学习word embedding，第二步迁移到一个数据量较小的任务上，如果这个迁移之后的任务的数据量足够大，那么我们就还需要对迁移之后的数据来改变词嵌入，一般来说不用改变 词嵌入的属性类比问题，我们提出一个问题，man-woman，相当于king-？，那么这个问号是什么呢。我们用之前学到的词嵌入来进行表达两两词嵌入向量的距离。我们发现$e{man}$和$e{woman}$之间的距离和$e{king}$与$e{quene}$之间的距离基本相等，因此可以认为man-woman等价于king-quene的关系。 类比问题的做法是”?”代表的词计算出来，用$e{man}-e{woman}=e{king}-e?$表示，那就是要找到词w，$arg\maxwsim(e_w,w{king}-e{man}+e{woman})$ 最常用的相似性度量方式是Cosine similarity，定义为$sim(u,v)=\frac{u^Tv}{||u||_2||v||_2}$，当然也可以用欧氏距离，但是cos相似度用的更多 嵌入矩阵你进行了word embedding的学习之后，最后的输出是一个嵌入矩阵，这个矩阵就是每个单词一列，所有单词组合得到的矩阵，如下图，乘以一个原本的one-hot的字典类型的表示之后，就可以得到这个单词的嵌入向量，但是实际中，我们只需要去查找这个embedding的向量，而不是做一个很高纬度的乘法 如何进行word embedding的学习一开始进行word embedding方面的研究的时候，模型比较复杂，但是后来人们发现简单的模型的效果也很好。我们在这里先讲一些复杂的模型，然后简化他们，因为复杂的模型更容易让你理解为什么他们会有效。 还是以“I want a glass of orange __”这句单词预测的句子为例，你先把所有的one-hot向量通过embedding matrix E 变成一个embedding vector，然后把他们stacking到一起，输入一个神经网络，最后经过一个softmax单元，输出概率最高的单词，当然你也可以只使用之前的四个单词，删除最开始的I和want 除了用之前的四个单词，你还可以使用左右各四个单词，也可以用之前的一个单词，也可以用最近的一个单词等等 Word2Vec利用上一节中提到的方法，给定一个词作为context，一个词为target，通过一个embedding matrix，相乘之后经过一个softmax层，得到一个估计y，训练这一过程，来得到embedding matrix的参数 主要有两种思想：一种是CBOW方法，是根据上下文来预测当前词语的概率，且上下文所有的词对当前词出现概率的影响的权重是一样的，因此叫continuous bag-of-words模型。如在袋子中取词，取出数量足够的词就可以了，至于取出的先后顺序是无关紧要的。 Skip-gram刚好相反：根据当前词语来预测上下文的概率。 实际使用这个方法的时候有两个比较大的缺陷： 计算量很大，计算概率时的分母求和的内容非常多，这就导致计算很复杂，这个问题在这后会用Negtive sampling解决 如果使用sample方法，那么文中出现的很多的那些无意义的连词出现的概率会比较大，比如the,a,and之类的，这个问题通过huffman 树来解决 Huffuman树是通过每次选择最小的两个节点合并成一颗新的树，然后不断往上，直到合并完所有节点，我们来看个例子 有了Huffman树，我们再将Huffman编码应用到机器学习中，最初Huffman编码用于编码传输，比如现在你要传一段由6个单词组成的文章（文章长度未知，可能是几十个单词，几百个单词都有可能），那么你需要$2^3$个编码来编码传输，这有两个问题，第一个问题是现在存在编码的浪费，二是不同概率的单词所用的编码是一样的，我们希望经常出现的单词应该编码长度短，不常出现的应该编码长度长，一次综合来取得最短共同长度，举个例子 负采样上一章节中计算p(t|c)的计算复杂度很高，因此我们在这一章中引入了负采样的方法，负采样就是先选一个context，然后选择一个真正的target，把他的y标记成1，然后选择k个负样本（也就是不是context的上下文的那种单词），然后把他们输入一个sigmoid函数，计算k+1个概率，因此大大减少了计算复杂度 Glove word vectorsGlove全称：Global Vectors for Word Representation ，是以两个单词i,j互相在对方的上下文（比如前后10个单词之内）中出现的次数来表示的，如果两个次数越接近，两个单词就越相近 我们需要优化以下的目标，为了避免出现log0的情况，我们引入一个权重项，在$x_{ij}=0$的时候，让权重也等于0 Word embedding应用1——情感分类如果我有一个word embedding的矩阵，我有一句话之后，就可以算出每个单词的word embedding 向量，然后对其平均或者求和来通过一个softmax单元，得到评分为1-5的概率，但这样有个缺点，如左下角的句子所示，没有考虑上下文文本的关系，左下角这个句子有三个good，分类器很可能认为是一个正面评论 为了利用上下文信息，需要使用RNN进行分类，是一个many-to-one的结构 Week Three序列到序列的模型我们有一句法语需要翻译，首先我们将法语输入一个RNN（比如LSTM单元），编码之后，再经过一个解码的RNN单元，把每次输出的单词作为下一个单元的输入，直到解码结束。事实证明，只要你拥有足够的训练数据（法语到英文的转换内容），你的系统可以表现的很好 在图像标注的问题当中，也需要类似的办法。比如给定一张图像，然后给一句话对其进行描述，需要对新的图像同样进行描述的任务就称为图像标注。先用一个CNN对图像进行编码，比如一个AlexNet，然后将这个得到的编码输入一个RNN，输出一句描述。 选择可能性最大的句子我们在进行机器翻译的时候，不是每次选择一个出现概率最大的词语，而是选择出现那一整句话最大概率的情况，也就是所有单词联合概率最大的情况。 比如我们看看下面这个例子，假如我们 现在已经选了两个单词”Jane is”，然后你现在要选第三个单词，可能going在英语中出现的概率更大，但是going这一句并没有上面那一整句的翻译效果好，因此我们要选择一整句出现概率大的情况 因此此时要引入beam search algorithm beam search algorithm加入你要找到最大的联合概率，那么你每一步都要评估你字典那么多个概率，比如你字典中有10000个单词，如果你要翻译为1个长度为10的句子，那么你就要计算$10000^{10}$这个多个概率，从中选择最大的。 beam search的思想就是每次你只选择n个最大的概率向后计算，比如你现在beam=3，那么你每次只选择概率最大的3个短语向后计算，如下图，第一个单词概率最大的3个是”in, jane, sptember”，然后你以$\hat y^{ \langle 1 \rangle }$分别是”in, jane, sptember”，向后计算第二个单词，选出集中概率最大的三个，比如现在是”in september, jane is, jane visits”，然后再以这三个向后计算第三个单词，直到最后一个 细化beam searchlength normalization是一种可以让beam search表现得更好的方法 一个很靠后的单词，是前面所有条件概率的乘积，那么越靠后这个概率可能越小，为了使计算机不会因为float值的存储长度限制而损失精度，一般用log函数进行表示 此外，长度越长，明显概率越小，为了使得最后的结果不是一堆长度很短的内容，我们使用长度对其归一化，也可以是长度的某个指数 beam search的错误分析在做机器翻译的时候，出现错误你需要去看看是beam search的错误还是RNN的错误 此时只需要比较RNN和beam search 两者的概率，如果RNN输出的概率大于beam search的概率，就是beam search的错误；反之则是RNN的错误。然后比较很多例子的错误来源，看哪个错误占得比例大， 就是哪个的主要错误。 Bleu score机器翻译与图片识别不一样，图片识别往往只有一个最终结果，但机器翻译有时候会存在好几句的翻译效果是一样好的情况，那么如何评价你翻译的好坏呢？这个时候就要引入Bleu score 首先我们看看单个单词程度的精度评价，原本的精度评价方式是在原句中存在且在翻译结果中也存在的单词的出现次数除以目标句子的总长，但下面这个时候这个评价指标就会失效。我们对其进行修正，用目标句和参考句中都出现的单词，其在参考句中出现次数的最大值，除以结果句的长度 但是我们有时候不光是需要一个单词的精度，还要看看相邻单词的次数，此时的方法如下，对所有二元组，用其在所有参考句中出现的次数之和，除以目标句中出现的次数之和 同样你还可以计算出三元组，四元组等等的结果，把他们加起来再放到e的指数上面，作为一个评估指标 注意力模型处理翻译问题的过程中，不论是对于人或者机器，如果句子过长，那么你很难去记住一个句子，然后把他们全部翻译出来。正确的处理方式应该是先看一部分，然后翻译一部分，直到翻译完所有内容。 我们以翻译法语到英语为例，假如你正在翻译”jane visite l’Afrique en septembre”，那么你翻译的第一个结果$s^{ \langle 1 \rangle }$到底需要关注哪些单词呢？我们在这里计算出一个注意力权重系数，$\alpha^{ \langle t,t^\prime \rangle }$表示在生成第t个翻译内容的单词时，需要对原文的$t^\prime$那个单词关注多少 计算attention model 的方法，是先在下面用一个双向RNN，上面一个单向RNN，对每个词计算出注意力权重系数，然后加起来作为上面的单向RNN的输入。当然真正计算的时候还要加一个softmax单元，保证每一个注意力权重系数小于1 语音识别语音识别就是把一段音频数据转换成对应的文字，这个问题可以使用注意力模型。 同时，由于输出可能远大于输入，我们需要对输出的结果进行删减，方法是删除所有细小停顿，然后拼凑成一个个单词，这里用到的损失函数叫做CTC cost 语音识别需要大量的训练数据，一般来说学术论文需要几千个小时的数据，商业系统需要100000小时数据 触发词检测标记一段数据，出现触发词的下一个标记标记为1，直到结束标记为0]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>deeplearning</tag>
        <tag>机器学习</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Coursera-deeplearning-ai-（四）]]></title>
    <url>%2F2018%2F05%2F10%2FCoursera-deeplearning-ai-%EF%BC%88%E5%9B%9B%EF%BC%89%2F</url>
    <content type="text"><![CDATA[这篇博文主要讲的是关于deeplearning.ai的第四门课程的内容，《Convolutional Neural Networks》 Week One计算机视觉在处理计算机视觉问题的时候，我们可能处理的图片很大，之前我们用的都是64*64*3维度的图片，这样的图片不够清晰，如果我们用1000*1000*3大小的图片，每张图片的维度就是300w，这就需要很多的数据来调参，并且对系统的资源占用非常大，此时就要用到卷积的技巧，它是卷积神经网络的基础 利用卷积进行边缘检测的示例比如我有如下左边这张图，我想检测这张图上面有些上面，我首先要用边缘检测，分别检测出他的横向边缘和纵向边缘 边缘检测需要用到卷积，那么上面是卷积呢？ 首先，假设我们现在有一张6*6的灰度图片（仅有一个rgb通道），我们定义一个3*3的filter，当然有些地方把这个filter称为kernel，我们这里就用filter来表示，那么现在用这个3*3的filter在66的图像上面移动，每移动一个位置进行元素乘积求和，最终得到一个4\4的结果矩阵，如下图 比如左上角的-5，是把3*3的矩阵放在6*6的矩阵的左上角得到的，也就是$-5=3\times1+1\times1+2\times1+0\times0+5\times0+7\times0+1\times(-1)+8\times(-1)+2\times(-1)$ 然后向右移动一个单位得到-4，一直移动下去得到右边的4*4矩阵 再举一个直观的例子，比如我们现在有个黑白分明的6*6灰度图片，我们要检测它的垂直边缘，用一个3*3的filter卷积，得到一个4*4的垂直边缘结果，如下 4*4矩阵中间那块白色的就是边缘，此时看起来边缘很大，那是因为我们这里的原始图片太小了，如果原始图片的大小是1000*1000，那么这个边缘就非常合理了。这里这个边缘也显示了边缘的大体趋势，是正确的 卷积函数在几乎所有深度学习框架当中都有包含，比如TensorFlow当中的tf.nn.conv2d 更多的边缘检测边缘有着正边缘和负边缘的说法，从黑到白和从白到黑是不同的，如下图所示： 当然，还有水平边缘和垂直边缘的区分，很容易想到水平边缘的filter就是大概将竖直边缘filter转动90度 然后，根据filter使用的不同，也可以得到不同的边缘，比如常用的还有sobel filter，参数是1,2,1，还有scharr filter，参数是3,10,3，甚至你可以将这3*3的filter的9个值都设置为参数，通过反向传播来学习他们，由此你可以检测出任意角度的边缘，比如45度，70度，73度等等 padding 扩充上面讲到的直接卷积的方法有两个明显的缺点： 图片会被缩小，你输入的是6*6的图片，最终得到的4*4的图片，比原始图片大小小了，如果经过若干层网络的卷积之后，得到的图片就相当小了 边缘信息利用得太少了，比如左上角那个像素，你在计算的过程中只会用到1次，但是中间的像素会用到很多次，那么左上角那个像素包含的信息的权重就被减小了 假设我们输入一个n*n的图片，用一个f*f的filter进行卷积，那么最终得到的是一个n-f+1的图片 这时，我们可以使用padding的方法，一次解决上面提到的两个问题，所谓的padding就是将原来的图片向外扩充，扩充的值全部填成0，如下图所示 假如我们扩充的大小是p，那么最终得到的图片大小就是n+2p-f+1，要使得最终的图片大小等于初始大小，那么p=(f-1)/2，f通常都是一个奇数，不是奇数的时候就要混合padding，就是左右padding的范围不一样 带步长的卷积通常的卷积是每次移动一格，但是如果你加上步长的话，每次就可以移动步长那么多格，比如你现在有一个7*7的图像，然后有个3*3的filter，如果你每次移动2步，那么最终得到的是一个3*3的图像 这个计算方法是加入你有一个n*n的图像，有一个f*f的filter，stride步长要s，padding的大小p，那么最终得到的图像大小为floor((n+2p-f)/2 +1)，其中floor表示向下取整，以防这是一个非整数的情况 我们在神经网络中用的卷积准确来说应该叫做交叉相关，真正的卷积的filter应该先向右翻转90度，再上下翻转（翻转是为了满足矩阵卷积的结合律），但是因为约定，所以我们在神经网络中的交叉相关都被称为卷积 卷积RGB图像我们之前卷积的都是黑白图像，如果我们需要卷积三通道的RGB图像，我们应该怎么做呢？ 如下图，在卷积RGB图像的时候，我们可以用一个同样有三通道的filter进行卷积，filter的每个通道与RGB的红绿蓝三通道相乘并全部求和，最终得到的卷积结果是只有一个通道的而不是三个通道的 当我们需要同时取得图像的垂直边缘，水平边缘或者更多的边缘的时候，我们应该怎么做呢？ 如果你需要同时取得多个边缘，你只需要同时使用多个filter即可，得到的结果是很多张边缘图，你也可以把他们stack起来 那么我们现在总结一下各个层的维度 输入的图片的维度是: $n\times n \times n_c$，其中$n_c$是指图片通道的数量 filter的维度是$f\times f \times n_c$，这里的filter的通道数和图片的通道数应该相同 得到的边缘结果的维度是$(n-f+1)\times (n-f+1) \times n_c^\prime$，其中$n_c^\prime$表示拥有的filter的数量 单层卷积神经网络首先你输入一个RGB三通道的图像，大小是6*6*3，然后通过两个filter，大小是3*3*3，得到两个4*4的Z，分别加上bias b1,b2，然后通过Relu函数进行非线性变换，得到4*4*2 将这个单层的卷积神经网络与神经网络比较，这里的输入图像就是x,也就是$a^{[0]}$，通过的filter相当于w，之后的b相当于偏差，relu函数相当于激活函数g，得到的4*4*2的输出相当于$a^{[1]}$ 让我们来看看这里面的参数及其维度 用L来表示一个卷积层，$f^{[l]}$表示filter的大小，$p^{[l]}$表示padding的大小，$s^{[l]}$表示stride的大小，$n_c^{[l]}$表示第l层filter的数量 那么输入的维度就是$n_H^{[l-1]}\times n_W^{[l-1]}\times n_c^{[l-1]}$ 输出的维度是$n_H^{[l]}\times n_W^{[l]}\times n_c^{[l]}$ 其中的$n_H^{[l]}$和$n_W^{[l]}$可以用$n_H^{[l]}=\lfloor \frac{n_H^{[l-1]}+2p^{[l]}-f^{[l]}}{s^{[l]}}+1 \rfloor$来计算 每一个filter的大小是：$f^{[l]} \times f^{[l]} \times n_c^{[l-1]}$，因为filter的通道要和输入相同 激活函数$a^{[l]}$的大小是$n_H^{[l]}\times n_W^{[l]}\times n_c^{[l]}$，如果是批处理$A^{[l]}$的大小是$m \times n_H^{[l]}\times n_W^{[l]}\times n_c^{[l]}$ 权重w的大小是$f^{[l-1]}\times f^{[l-1]}\times n_c^{[l-1]} \times n_c^{[l]}$ 偏差的大小是$n_c^{[l]}$ 简单的卷积网络下图是一个简单的神经网络的例子，输入层的维度是39*39*3，第一层的$f^{[1]}=3$，$s^{[1]}=1$，$p^{[1]}=0$，有10个filter，那么第一层的输出是37*37*10；第二层的$f^{[2]}=5$，$s^{[1]}=2$，$p^{[2]}=0$，filter个数是20，第二层的输出是17*17*20；第三层的$f^{[3]}=5$，$s^{[3]}=2$，$p^{[3]}=0$，filter个数是40，输出是7*7*40 然后，将得到的7*7*40的图像flatten成一个7*7*40=1960*1的向量，然后把这个向量输入一个logistics或softmax函数，以此进行分类 通常来说，卷积网络的图像大小会越来越小，但通道数会越来越多 卷及网络中的典型层有： Convolution (conv) Pooling（pool） Fully connected (FC) Pooling Layers利用pooling layer去减小表达的大小，加速计算，并使得某些特征更加稳定 pooling layer最常用的就是max pooling，就是用一个filter去移动，但是不是相乘求和，而是求出这个filter移动过程中的最大值，如下所示 还有一种pooling叫做average pooling，不是求最大值而是平均值，这种pooling用的非常少 一个完整的卷积神经网络示例如图，我们输入一个32*32*3的网络，经过一个conv1层，f=5,s=1，得到一个28*28*6的输出，然后经一个maxpoo层pool1，得到14*14*6，这个conv1和pool1被合称为layer1，因为layer只算那些有参数的层，pool层没有参数，所以conv1和pool1合称一层layer1 然后经过conv2,f=5,s=1，得到10*10*16，然后经过pool2，得到5*5*16 此时flatten成400*1的向量，然后用普通的神经网络继续传输，此时用普通神经网络的层被称之为fully connected层，W[3]的参数是(120,400)，所以a[3]=(120,1)，然后w[4]=(84,120)，得到a[4]=(84,1)，然后经过一个softmax层，因为我们这里是分类数字0-9，所以最后的输出是(10,1)，然后选择概率最大那个 为什么要用卷积神经网络卷积神经网络可以显著地减少参数，我们来看个例子 如下图你有一个卷积层，本来大小是32*32*3，经过一个卷积层之后大小成了28*28*6，那么你用到的参数个数应该是5*5*6+6=156个，如果你直接用全联通层，那么你需要的参数个数是32*32*3*28*28*6=14M个，明显这里的参数就非常多了 还有种解释是卷及网络有参数共享和稀疏连接的好处 如图，你通过卷积层得到的每一个值，都只与自己的那9个卷积的值相关，与别的值不相关，这就是稀疏连接的意思，各个值之间不干扰 参数共享的意思是，比如你有一个3*3的filter，可以进行垂直边缘检测，那么这个filter无论是在同一张图的哪个地方，都可以进行边缘检测，而不是说只能在某个地方进行 利用TensorFlow搭建卷积神经网络这周的编程作业就是利用TensorFlow搭建卷积神经网络，那么我们对程序回顾一下 read data先看看数据读入的程序 数据是存在f5文件中的，用h5py进行读取，然后通过key访问，查看key的方法是list(data.keys())，然后访问某个key下的所有数据的方法是data[&#39;key&#39;][:]，如果不加最后的[:]，那么你取到的是一个h5对象，然后将y reshape成一个行向量 123456789101112131415def load_dataset(): train_dataset = h5py.File('datasets/train_signs.h5', "r") train_set_x_orig = np.array(train_dataset["train_set_x"][:]) # your train set features train_set_y_orig = np.array(train_dataset["train_set_y"][:]) # your train set labels test_dataset = h5py.File('datasets/test_signs.h5', "r") test_set_x_orig = np.array(test_dataset["test_set_x"][:]) # your test set features test_set_y_orig = np.array(test_dataset["test_set_y"][:]) # your test set labels classes = np.array(test_dataset["list_classes"][:]) # the list of classes train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0])) test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0])) return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes one_hot transfer接下来是一个one_hot y label 的转换 123def convert_to_one_hot(Y, C): Y = np.eye(C)[Y.reshape(-1)].T return Y np.eye后面跟一个array，就可以制造一个多行的one_hot值 1234567np.eye(6)[np.array([1,2,1,1,1,1])]#array([[0., 1., 0., 0., 0., 0.],# [0., 0., 1., 0., 0., 0.],# [0., 1., 0., 0., 0., 0.],# [0., 1., 0., 0., 0., 0.],# [0., 1., 0., 0., 0., 0.],# [0., 1., 0., 0., 0., 0.]]) 当然你也可以用tf.one_hot函数来实现 12345678indices = [1,2,3]depth = 3one = tf.one_hot(indices, depth)with tf.Session() as sess: print(sess.run(one))#[[1. 0. 0.] #[0. 1. 0.] #[0. 0. 1.]] Create Placeholder12345678910111213141516171819202122# GRADED FUNCTION: create_placeholdersdef create_placeholders(n_H0, n_W0, n_C0, n_y): """ Creates the placeholders for the tensorflow session. Arguments: n_H0 -- scalar, height of an input image n_W0 -- scalar, width of an input image n_C0 -- scalar, number of channels of the input n_y -- scalar, number of classes Returns: X -- placeholder for the data input, of shape [None, n_H0, n_W0, n_C0] and dtype "float" Y -- placeholder for the input labels, of shape [None, n_y] and dtype "float" """ ### START CODE HERE ### (≈2 lines) X = tf.placeholder(dtype=tf.float32,shape=(None, n_H0, n_W0, n_C0)) Y = tf.placeholder(dtype=tf.float32,shape=(None,n_y)) ### END CODE HERE ### return X, Y tf.placeholder是建立占位符 None是因为不确定每次输入多少张图片，然后X的维度是height，width，n_c0，y的维度是n_y initialize_parameters12345678910111213141516171819202122# GRADED FUNCTION: initialize_parametersdef initialize_parameters(): """ Initializes weight parameters to build a neural network with tensorflow. The shapes are: W1 : [4, 4, 3, 8] W2 : [2, 2, 8, 16] Returns: parameters -- a dictionary of tensors containing W1, W2 """ tf.set_random_seed(1) # so that your "random" numbers match ours ### START CODE HERE ### (approx. 2 lines of code) W1 = tf.get_variable('W1',shape=[4,4,3,8],initializer=tf.contrib.layers.xavier_initializer(seed = 0)) W2 = tf.get_variable('W2',shape=[2,2,8,16],initializer=tf.contrib.layers.xavier_initializer(seed = 0)) ### END CODE HERE ### parameters = &#123;"W1": W1, "W2": W2&#125; return parameters tf.get_variable 用于建立变量，第一维的参数是f=4,个数是8个；第二维的参数是f=2，个数是16个 Forward propagation我们这里输入parameter和X，网络的结构如下 CONV2D -&gt; RELU -&gt; MAXPOOL -&gt; CONV2D -&gt; RELU -&gt; MAXPOOL -&gt; FLATTEN -&gt; FULLYCONNECTED 用tf.nn.conv2d(X,W1,strides=[1, 1, 1, 1],padding=&#39;SAME&#39;)进行卷积，输入A和W，步长的输入方式是[batch,s,s,depth]，batch表示每次跳过多少张图片，depth表示跳过多少通道；padding的方法是’SAME’ 每个conv2d的输出是Z，relu之后是A，maxpool之后是P 把图片flatten到一维， P2 = tf.contrib.layers.flatten(P2) tf.contrib.layers.fully_connected(P2, num_outputs=6, activation_fn=None)表示全连接层，不用activation_fn是因为最终计算cost的时候会自动用到softmax函数 1234567891011121314151617181920212223242526272829303132333435363738394041# GRADED FUNCTION: forward_propagationdef forward_propagation(X, parameters): """ Implements the forward propagation for the model: CONV2D -&gt; RELU -&gt; MAXPOOL -&gt; CONV2D -&gt; RELU -&gt; MAXPOOL -&gt; FLATTEN -&gt; FULLYCONNECTED Arguments: X -- input dataset placeholder, of shape (input size, number of examples) parameters -- python dictionary containing your parameters "W1", "W2" the shapes are given in initialize_parameters Returns: Z3 -- the output of the last LINEAR unit """ # Retrieve the parameters from the dictionary "parameters" W1 = parameters['W1'] W2 = parameters['W2'] ### START CODE HERE ### # CONV2D: stride of 1, padding 'SAME' Z1 = tf.nn.conv2d(X,W1,strides=[1, 1, 1, 1],padding='SAME') # RELU A1 = tf.nn.relu(Z1) # MAXPOOL: window 8x8, sride 8, padding 'SAME' P1 = tf.nn.max_pool(A1,ksize=[1, 8, 8, 1],strides=[1, 8, 8, 1],padding='SAME') # CONV2D: filters W2, stride 1, padding 'SAME' Z2 = tf.nn.conv2d(P1,W2,strides=[1, 1, 1, 1],padding='SAME') # RELU A2 = tf.nn.relu(Z2) # MAXPOOL: window 4x4, stride 4, padding 'SAME' P2 = tf.nn.max_pool(A2,ksize=[1, 4, 4, 1],strides=[1, 4, 4, 1],padding='SAME') # FLATTEN P2 = tf.contrib.layers.flatten(P2) # FULLY-CONNECTED without non-linear activation function (not not call softmax). # 6 neurons in output layer. Hint: one of the arguments should be "activation_fn=None" Z3 = tf.contrib.layers.fully_connected(P2, num_outputs=6, activation_fn=None) ### END CODE HERE ### return Z3 计算代价tf.nn.softmax_cross_entropy_with_logits(logits = Z3, labels = Y)，logists表示输出，label表示真正的标签 12345678910111213141516171819# GRADED FUNCTION: compute_cost def compute_cost(Z3, Y): """ Computes the cost Arguments: Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (6, number of examples) Y -- "true" labels vector placeholder, same shape as Z3 Returns: cost - Tensor of the cost function """ ### START CODE HERE ### (1 line of code) cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=Z3, labels=Y)) ### END CODE HERE ### return cost 建立model先获取shape，然后定义placeholder 123456(m, n_H0, n_W0, n_C0) = X_train.shape n_y = Y_train.shape[1]costs = [] # To keep track of the cost# Create Placeholders of the correct shapeX, Y = create_placeholders(n_H0,n_W0,n_C0,n_y) 然后定义参数w1，w2 1parameters = initialize_parameters() 然后进行前向传播 1Z3 = forward_propagation(X,parameters) 然后计算cost 1Z3 = forward_propagation(X,parameters) 设置optimizer 1optimizer = tf.train.AdamOptimizer().minimize(cost) 进行参数初始化 1init = tf.global_variables_initializer() 然后开始循环epochs，其中的minibatch的取法如下： 123456789101112131415161718192021222324252627282930313233343536373839def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0): """ Creates a list of random minibatches from (X, Y) Arguments: X -- input data, of shape (input size, number of examples) (m, Hi, Wi, Ci) Y -- true "label" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples) (m, n_y) mini_batch_size - size of the mini-batches, integer seed -- this is only for the purpose of grading, so that you're "random minibatches are the same as ours. Returns: mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y) """ m = X.shape[0] # number of training examples mini_batches = [] np.random.seed(seed) # Step 1: Shuffle (X, Y) permutation = list(np.random.permutation(m)) shuffled_X = X[permutation,:,:,:] shuffled_Y = Y[permutation,:] # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case. num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning for k in range(0, num_complete_minibatches): mini_batch_X = shuffled_X[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:,:,:] mini_batch_Y = shuffled_Y[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:] mini_batch = (mini_batch_X, mini_batch_Y) mini_batches.append(mini_batch) # Handling the end case (last mini-batch &lt; mini_batch_size) if m % mini_batch_size != 0: mini_batch_X = shuffled_X[num_complete_minibatches * mini_batch_size : m,:,:,:] mini_batch_Y = shuffled_Y[num_complete_minibatches * mini_batch_size : m,:] mini_batch = (mini_batch_X, mini_batch_Y) mini_batches.append(mini_batch) return mini_batches 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113# GRADED FUNCTION: modeldef model(X_train, Y_train, X_test, Y_test, learning_rate = 0.009, num_epochs = 100, minibatch_size = 64, print_cost = True): """ Implements a three-layer ConvNet in Tensorflow: CONV2D -&gt; RELU -&gt; MAXPOOL -&gt; CONV2D -&gt; RELU -&gt; MAXPOOL -&gt; FLATTEN -&gt; FULLYCONNECTED Arguments: X_train -- training set, of shape (None, 64, 64, 3) Y_train -- test set, of shape (None, n_y = 6) X_test -- training set, of shape (None, 64, 64, 3) Y_test -- test set, of shape (None, n_y = 6) learning_rate -- learning rate of the optimization num_epochs -- number of epochs of the optimization loop minibatch_size -- size of a minibatch print_cost -- True to print the cost every 100 epochs Returns: train_accuracy -- real number, accuracy on the train set (X_train) test_accuracy -- real number, testing accuracy on the test set (X_test) parameters -- parameters learnt by the model. They can then be used to predict. """ ops.reset_default_graph() # to be able to rerun the model without overwriting tf variables tf.set_random_seed(1) # to keep results consistent (tensorflow seed) seed = 3 # to keep results consistent (numpy seed) (m, n_H0, n_W0, n_C0) = X_train.shape n_y = Y_train.shape[1] costs = [] # To keep track of the cost # Create Placeholders of the correct shape ### START CODE HERE ### (1 line) X, Y = create_placeholders(n_H0,n_W0,n_C0,n_y) ### END CODE HERE ### # Initialize parameters ### START CODE HERE ### (1 line) parameters = initialize_parameters() ### END CODE HERE ### # Forward propagation: Build the forward propagation in the tensorflow graph ### START CODE HERE ### (1 line) Z3 = forward_propagation(X,parameters) ### END CODE HERE ### # Cost function: Add cost function to tensorflow graph ### START CODE HERE ### (1 line) cost = compute_cost(Z3,Y) ### END CODE HERE ### # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer that minimizes the cost. ### START CODE HERE ### (1 line) optimizer = tf.train.AdamOptimizer().minimize(cost) ### END CODE HERE ### # Initialize all the variables globally init = tf.global_variables_initializer() # Start the session to compute the tensorflow graph with tf.Session() as sess: # Run the initialization sess.run(init) # Do the training loop for epoch in range(num_epochs): minibatch_cost = 0. num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set seed = seed + 1 minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed) for minibatch in minibatches: # Select a minibatch (minibatch_X, minibatch_Y) = minibatch # IMPORTANT: The line that runs the graph on a minibatch. # Run the session to execute the optimizer and the cost, the feedict should contain a minibatch for (X,Y). ### START CODE HERE ### (1 line) _ , temp_cost = sess.run([optimizer,cost], feed_dict=&#123;X:minibatch_X, Y: minibatch_Y&#125;) ### END CODE HERE ### minibatch_cost += temp_cost / num_minibatches # Print the cost every epoch if print_cost == True and epoch % 5 == 0: print ("Cost after epoch %i: %f" % (epoch, minibatch_cost)) if print_cost == True and epoch % 1 == 0: costs.append(minibatch_cost) # plot the cost plt.plot(np.squeeze(costs)) plt.ylabel('cost') plt.xlabel('iterations (per tens)') plt.title("Learning rate =" + str(learning_rate)) plt.show() # Calculate the correct predictions predict_op = tf.argmax(Z3, 1) correct_prediction = tf.equal(predict_op, tf.argmax(Y, 1)) # Calculate accuracy on the test set accuracy = tf.reduce_mean(tf.cast(correct_prediction, "float")) print(accuracy) train_accuracy = accuracy.eval(&#123;X: X_train, Y: Y_train&#125;) test_accuracy = accuracy.eval(&#123;X: X_test, Y: Y_test&#125;) print("Train Accuracy:", train_accuracy) print("Test Accuracy:", test_accuracy) return train_accuracy, test_accuracy, parameters 然后run这个optimizer和cost 1_ , temp_cost = sess.run([optimizer,cost], feed_dict=&#123;X:minibatch_X, Y: minibatch_Y&#125;) Week Two经典网络LeNet-5这个网络是在1998年提出的，结果如下图 一共有大概60K个参数，第一层是6个5*5的conv layer，然后是一个f=2,s=2的pool layer（当时用的的average pool，不过后来证明max pool更有效），然后再来16个5*5的conv layer，然后是一个f=2,s=2的pool layer，然后将这个5*5*16的volume flatten为一个(400,1)的向量，经过一个fc（fully connected) layer，变成120*1,在经过一个fc layer，变成84*1的，再经过一个softmax得到一个10*1的$\hat{y}$，用于判别手写数字0-9 AlexNetAlexNet是在2012年提出的，这个网络让人们开始觉得深度学习的确可以在图像和自然语言处理等方面表现的很好 这个网络的结构是一个conv layer，跟一个max pool layer，再来一个conv layer，跟一个max-pool layer，接下来3个conv layer，跟一个max-pool layer，这时flatten为一个9216*1的向量，然后接一个FC layer，再接一个FC layer，再接一个softmax，得到输出 参数的个数为$(11113+1)96+(5596+1)256+(33256+1)384+(33384+1)3842 + 92164096 + 40964096+10004096=62811648$，约为60million个 VGG-16这个网络在2015年提出，整个网络中用到的filter都是3*3的,padding都是same，用到的max-pool layer 都是f=2,s=2, 先是2层conv 64的 conv layer，然后经过一个pool layer，接下来2层128个的conv layer，接下来一个pool layer，再接下来3层256个的conv layer，接一个pool layer，再接一个3层512个的conv layer，接一个pool layer，接一层512个的conv layer，接一个pool layer，接2层FC layer，接一层softmax 为什么叫VGG-16呢，因为这个网络里有参数的层一个是16个 同时提出的还有VGG-19，但是VGG-16的效果一般来说跟VGG-19差不多，并且参数要相对少一些，所以一般都用VGG-16 VGG-16参数非常多，大概有138million个，即使对于现代计算机，计算起来也是比较吃力的 残差网络(ResNet)残差网络首先要理解什么是残差块(Residual block) 假如你现在有一个如下的2层的神经网络，每次经过一个线性层，然后一个ReLU非线性层，到达下一层，如图所示 从左到右依次进行的被称为full path，然而如果你直接将$a^{[l]}$加到最后一个ReLU之前，这样的方法叫做short cut 或者是 skip connection，此时我们称这样一个有跳跃连接的整体为一个Residual block 如果我们有一个10层的神经网络，每2层形成一个残差块，那么这个网络就被称为残差网络，如下图 残差网络在实际中表现比普通网络更好，具体表现在：随着网络层数的增加，普通网络的训练错误会先降低后增加（因为层数增多，普通网络的训练越来越难，到后面规定的iteration还没有收敛，所以training error又增加了）；但是残差网络会一直下降，直到基本不下降的状态，不会出现training error上升的情况 我们用plain表示普通网络，ResNet表示残差网络，得到如下的training error和layers的示意图 为什么残差网络可以表现得更好 Lets see some example that illustrates why resNet work. We have a big NN as the following: X --&gt; Big NN --&gt; a[l] Lets add two layers to this network as a residual block: X --&gt; Big NN --&gt; a[l] --&gt; Layer1 --&gt; Layer2 --&gt; a[l+2] And a[l] has a direct connection to a[l+2] Suppose we are using RELU activations. Then: a[l+2] = g( z[l+2] + a[l] ) = g( W[l+2] a[l+1] + b[l+2] + a[l] ) Then if we are using L2 regularization for example, W[l+2] will be zero. Lets say that b[l+2] will be zero too. Then a[l+2] = g( a[l] ) = a[l] with no negative values. This show that identity function is easy for a residual block to learn. And that why it can train deeper NNs. Also that the two layers we added doesn’t hurt the performance of big NN we made. Hint: dimensions of z[l+2] and a[l] have to be the same in resNets. In case they have different dimensions what we put a matrix parameters (Which can be learned or fixed) a[l+2] = g( z[l+2] + ws * a[l] ) # The added Ws should make the dimentions equal ws also can be a zero padding. Using a skip-connection helps the gradient to backpropagate and thus helps you to train deeper networks 主要起作用的原因是redidual network 阻止了梯度消失和梯度爆炸之类的问题 $1\times 1$的卷积（network in network）1*1的卷积主要是为了改变图片的通道数目，比如你现在有一个28*28*192的图片，你可以将它变成32通道的，以此来减少计算量，也可以把它变成192通道的，这相当于在原来的图片上加了一个192通道的图片，这将使得模型更复杂，以此来表征更加复杂的模型 Inception Network在设计神经网络的时候，你可能会想如何去选择conv layer 所用的filter的大小，以及max-pool的大小，这个时候其实你可以把所有你可能会想要用到的conv layer和max-pool layer联结起来，形成一个复杂的网络，具体如下： 所有的conv layer和max-pool layer都用到了same padding，这样保证经过一个layer之后的维度不变，以便大家能够联结起来 但是inception network造成的问题就是计算量太大，比如我们现在来看看5*5这组filter的乘法的数目，一共输出是28*28*32个，每个输出所要求的乘法数目是5*5*192，所以全部乘起来之后是28*28*32*5*5*192=120M次 我们可以用上一节提到的1*1的conv 层进行计算次数的优化，用1*1的conv 层计算出一个 bottleneck layer（瓶颈层:和瓶颈一样，先变小，再变大），然后再计算乘法。具体来说是将28*28*192的图片先经过一个1*1的个数为16的层，变成28*28*16的层，然后再经过5*5的层，计算数量缩减为12.4M，如下图 一个Inception module如下图所示，包含1*1的conv layer 和 3*3的conv layer(前面有一个1*1的bottleneck layer)和5*5的conv layer(前面有一个1*1的bottleneck layer)，以及一个3*3的max-pool layer（后面有一个1*1的layer用于减小通道数） 一个完整的inception network如下图所示，由多个inception module组成，中间还有一个side branch，用中间某一层的输出进行预测 使用开源的深度学习实现当你遇到一个想要去实现的网络的时候，从头开始动手实现是非常困难的，因为有很多调参之类的问题需要你去解决，那么你完全可以使用google 去搜索github上面的结果，比如你先想要实现ResNet， 你只需要在google上面搜索ResNet github，很容易就能找到一个结果，并且这些开源代码往往用了大量的原始数据进行训练，你只需要下下来进行迁移学习就行了 迁移学习比如你现在想要是别的两只猫，分别叫做tigger和misty，但是你拥有的这两只猫的图片很少，所以你从网上下了一个在非常大数据集上面训练的模型(比如image net上训练过的模型)，然后你直接去掉输出层，把前面的所有层的参数都freeze住，对最后一层进行训练，就得到了你的猫分类器 当然，如果你数据量大一些，你可以少冻住几层，多训练几层，这个freeze的方法，通常是将输入输进去，用原来的网络参数计算直到你要自己训练的那层，把这些数据存下来作为新网络的输入。后面网络参数的初始化可以直接用别人训练好的参数作为反向传播 除非你数据量非常大，不然你都不要完全重新训练网络 数据提升数据提升主要有两种方法，一种是在图片内容上的变换，一种是色彩上的变换 内容上的变换主要有：镜像变换，随机裁剪，旋转，扭曲等等，如下图 色彩上的变换主要是：增加或减少RGB色彩，比较高级的方法叫做PCA color augmentation，效果如图 计算机视觉任务的经验一般来说，数据越多，你所需要进行的手动修改的部分就越少，如图 在标准数据集或者是竞赛当中有一些比较常用的方法： Ensembling：训练多个神经网络并平均输出 多种图片裁剪的数据提升方法：原图以及镜像图片的正中心，左上角，右上角，左下角，右下角图片，这个方法被称为crop-10，因为一共裁剪出10张 在使用开源框架的时候，通常可以： 用论文中提出的框架，因为一般计算机视觉任务有通用性 使用开源框架 使用pre-trained model并调整你模型中的参数 Keras tutorialKeras更像是sklearn的过程，每一层的叠加都是可见的，然后最后compile一下model，fit model，然后evaluate model 具体来说，我们看看一个1层的卷积神经网络怎么实现的 先用Input函数得到输入，用ZeroPadding2d函数进行zero padding，用Conv2D进行卷积，用BatchNormalization进行批量正则化（每一层都进行正则化而不只是输入正则化），经过一个激活函数Activation(‘relu’)，用MaxPooling2D经过一个max pool，然后Flatten，然后用一个sigmoid函数得到输出，最后用model=Model(inputs=..., outputs=... ,name=&#39;...&#39;)建立模型 1234567891011121314151617181920212223def model(input_shape): # Define the input placeholder as a tensor with shape input_shape. Think of this as your input image! X_input = Input(input_shape) # Zero-Padding: pads the border of X_input with zeroes X = ZeroPadding2D((3, 3))(X_input) # CONV -&gt; BN -&gt; RELU Block applied to X X = Conv2D(32, (7, 7), strides = (1, 1), name = 'conv0')(X) X = BatchNormalization(axis = 3, name = 'bn0')(X) X = Activation('relu')(X) # MAXPOOL X = MaxPooling2D((2, 2), name='max_pool')(X) # FLATTEN X (means convert it to a vector) + FULLYCONNECTED X = Flatten()(X) X = Dense(1, activation='sigmoid', name='fc')(X) # Create model. This creates your Keras model instance, you'll use this instance to train/test the model. model = Model(inputs = X_input, outputs = X, name='HappyModel') return model You have now built a function to describe your model. To train and test this model, there are four steps in Keras: Create the model by calling the function above Compile the model by calling model.compile(optimizer = &quot;...&quot;, loss = &quot;...&quot;, metrics = [&quot;accuracy&quot;]) Train the model on train data by calling model.fit(x = ..., y = ..., epochs = ..., batch_size = ...) Test the model on test data by calling model.evaluate(x = ..., y = ...) If you want to know more about model.compile(), model.fit(), model.evaluate() and their arguments, refer to the official Keras documentation. 现在建立模型的方法就是四步： 定义模型：happyModel = HappyModel(X_train.shape[1:]) compile模型，定义其中的optimizer和loss以及metrics，happyModel.compile(optimizer = &quot;Adam&quot;, loss = &quot;binary_crossentropy&quot;, metrics = [&quot;accuracy&quot;]) fit模型：happyModel.fit(x = X_train, y = Y_train, epochs = 5, batch_size = 16)，这里的batch-size选为16，一开始用了64，效果非常不好 evaluate模型：preds = happyModel.evaluate(x = X_, y = ...) keras当中比较有用的两个函数： 模型的每一层的参数个数：happyModel.summary() plot_model(happyModel, to_file=&#39;HappyModel.png&#39;)SVG(model_to_dot(happyModel).create(prog=&#39;dot&#39;, format=&#39;svg&#39;))上面两行用于打印模型的结构 Keras to ResNet首先导入一些需要用到的库 Keras是一个模型级的库，提供了快速构建深度学习网络的模块。Keras并不处理如张量乘法、卷积等底层操作。这些操作依赖于某种特定的、优化良好的张量操作库。Keras依赖于处理张量的库就称为“后端引擎”。Keras提供了三种后端引擎Theano/Tensorflow/CNTK，并将其函数统一封装，使得用户可以以同一个接口调用不同后端引擎的函数 123456789101112131415161718192021import numpy as npfrom keras import layersfrom keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2Dfrom keras.models import Model, load_modelfrom keras.preprocessing import imagefrom keras.utils import layer_utilsfrom keras.utils.data_utils import get_filefrom keras.applications.imagenet_utils import preprocess_inputimport pydotfrom IPython.display import SVGfrom keras.utils.vis_utils import model_to_dotfrom keras.utils import plot_modelfrom resnets_utils import *from keras.initializers import glorot_uniformimport scipy.miscfrom matplotlib.pyplot import imshow%matplotlib inlineimport keras.backend as KK.set_image_data_format('channels_last')K.set_learning_phase(1) # 设置为训练/测试模式 ，分别是0/1 建立一个identity block identity block是x[l]和 x[l+2]的size一样，就可以直接相加 用filters的list来存储三层的filter的个数，记录下一开始的X作为X_shortcut 然后开始主路的设计：先一个conv layer，然后一个BatchNormalization，axis=3，是除了3以外的所有维度都normalization，也可以写成axis=-1，然后是一个Activation(‘relu’)层 接下来的两层基本与第一层相同，只是filter的个数分别是F2,F3，filter的size中间那层是(f,f) 第三层结束之后得到的X加上一开始的X_shortcut，就是最终进入activation的值，这里的加法必须要用keras.layers.Add()()([x1,x2])或keras.layers.add([x1, x2])进行，直接用加号会出错 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950# GRADED FUNCTION: identity_blockdef identity_block(X, f, filters, stage, block): """ Implementation of the identity block as defined in Figure 3 Arguments: X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev) f -- integer, specifying the shape of the middle CONV's window for the main path filters -- python list of integers, defining the number of filters in the CONV layers of the main path stage -- integer, used to name the layers, depending on their position in the network block -- string/character, used to name the layers, depending on their position in the network Returns: X -- output of the identity block, tensor of shape (n_H, n_W, n_C) """ # defining name basis conv_name_base = 'res' + str(stage) + block + '_branch' bn_name_base = 'bn' + str(stage) + block + '_branch' # Retrieve Filters F1, F2, F3 = filters # Save the input value. You'll need this later to add back to the main path. X_shortcut = X # First component of main path X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X) X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X) X = Activation('relu')(X) ### START CODE HERE ### # Second component of main path (≈3 lines) X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X) X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X) X = Activation('relu')(X) # Third component of main path (≈2 lines) X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X) X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X) # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines) X = Add()([X, X_shortcut]) # added = keras.layers.Add()([x1, x2]) ## equivalent to added = keras.layers.add([x1, x2]) X = Activation('relu')(X) ### END CODE HERE ### return X 然后开始tensorflow测试一下identity block，定义一个A_prev的placeholder，类型是float，shape=[3,4,4,6]，X设为一个[3,4,4,6]的随机矩阵，用A_prev建立一个identity block，三层filter的个数是2,4,6，第二层的filter的形状是2*2，然后用sess run 变量初始化，接着run一下这个identity block，feed_dict数据是A_prev:x,K.learning_phase(): 0用于转换为训练模式 12345678910tf.reset_default_graph()with tf.Session() as test: np.random.seed(1) A_prev = tf.placeholder("float", [3, 4, 4, 6]) X = np.random.randn(3, 4, 4, 6) A = identity_block(A_prev, f = 2, filters = [2, 4, 6], stage = 1, block = 'a') test.run(tf.global_variables_initializer()) out = test.run([A], feed_dict=&#123;A_prev: X, K.learning_phase(): 0&#125;) print("out = " + str(out[0][1][1][0])) 建立一个convlutional blockconvlutional block就是shortcut不是直接加到a[l+2]上面的，而是经过了一个conv layer和batch norm之后加的 与建立identity layer的方法类似，记录X为X_shortcut，这里的shortcut到后面是要经过运算的，不是直接加的 每个conv layer 有一个kernel的initializer，kernel_initializer = glorot_uniform(seed=0)就是常用的Xavier 初始化 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657# GRADED FUNCTION: convolutional_blockdef convolutional_block(X, f, filters, stage, block, s = 2): """ Implementation of the convolutional block as defined in Figure 4 Arguments: X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev) f -- integer, specifying the shape of the middle CONV's window for the main path filters -- python list of integers, defining the number of filters in the CONV layers of the main path stage -- integer, used to name the layers, depending on their position in the network block -- string/character, used to name the layers, depending on their position in the network s -- Integer, specifying the stride to be used Returns: X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C) """ # defining name basis conv_name_base = 'res' + str(stage) + block + '_branch' bn_name_base = 'bn' + str(stage) + block + '_branch' # Retrieve Filters F1, F2, F3 = filters # Save the input value X_shortcut = X ##### MAIN PATH ##### # First component of main path X = Conv2D(F1, (1, 1), strides = (s,s),padding='valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X) X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X) X = Activation('relu')(X) ### START CODE HERE ### # Second component of main path (≈3 lines) X = Conv2D(F2, (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X) X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X) X = Activation('relu')(X) # Third component of main path (≈2 lines) X = Conv2D(F3, (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X) X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X) ##### SHORTCUT PATH #### (≈2 lines) X_shortcut = Conv2D(F3, (1, 1), strides = (s,s), padding = 'valid', name = conv_name_base + '1', kernel_initializer = glorot_uniform(seed=0))(X_shortcut) X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut) # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines) X = Add()([X, X_shortcut]) X = Activation('relu')(X) ### END CODE HERE ### return X 同样来测试一下我们建立的convolutional block 12345678910tf.reset_default_graph()with tf.Session() as test: np.random.seed(1) A_prev = tf.placeholder("float", [3, 4, 4, 6]) X = np.random.randn(3, 4, 4, 6) A = convolutional_block(A_prev, f = 2, filters = [2, 4, 6], stage = 1, block = 'a') test.run(tf.global_variables_initializer()) out = test.run([A], feed_dict=&#123;A_prev: X, K.learning_phase(): 0&#125;) print("out = " + str(out[0][1][1][0])) 建立一个50层的ResNet结构如下图所示，分为5个stage，其中的conv block就是我们在上面建立的convolutional block，其中的ID block就是我们上面建立的identity block 我们先给一个大小就可以定义一个输入的tensor，用Input方法实现 先进入一个zero padding，然后一个conv layer，batch norm，relu，max pool，接下来就是一大堆的block，然后接一个AvgPool，flatten一下，接一个FC layer，就得到了输出 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869# GRADED FUNCTION: ResNet50def ResNet50(input_shape = (64, 64, 3), classes = 6): """ Implementation of the popular ResNet50 the following architecture: CONV2D -&gt; BATCHNORM -&gt; RELU -&gt; MAXPOOL -&gt; CONVBLOCK -&gt; IDBLOCK*2 -&gt; CONVBLOCK -&gt; IDBLOCK*3 -&gt; CONVBLOCK -&gt; IDBLOCK*5 -&gt; CONVBLOCK -&gt; IDBLOCK*2 -&gt; AVGPOOL -&gt; TOPLAYER Arguments: input_shape -- shape of the images of the dataset classes -- integer, number of classes Returns: model -- a Model() instance in Keras """ # Define the input as a tensor with shape input_shape X_input = Input(input_shape) # Zero-Padding X = ZeroPadding2D((3, 3))(X_input) # Stage 1 X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X) X = BatchNormalization(axis = 3, name = 'bn_conv1')(X) X = Activation('relu')(X) X = MaxPooling2D((3, 3), strides=(2, 2))(X) # Stage 2 X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1) X = identity_block(X, 3, [64, 64, 256], stage=2, block='b') X = identity_block(X, 3, [64, 64, 256], stage=2, block='c') ### START CODE HERE ### # Stage 3 (≈4 lines) X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2) X = identity_block(X, 3, [128, 128, 512], stage=3, block='b') X = identity_block(X, 3, [128, 128, 512], stage=3, block='c') X = identity_block(X, 3, [128, 128, 512], stage=3, block='d') # Stage 4 (≈6 lines) X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2) X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b') X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c') X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d') X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e') X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f') # Stage 5 (≈3 lines) X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2) X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b') X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c') # AVGPOOL (≈1 line). Use "X = AveragePooling2D(...)(X)" X = AveragePooling2D(pool_size=(2, 2))(X) ### END CODE HERE ### # output layer X = Flatten()(X) X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X) # Create model model = Model(inputs = X_input, outputs = X, name='ResNet50') return model 接下来定义我们的model 1model = ResNet50(input_shape = (64, 64, 3), classes = 6) 然后compile model，指定optimizer和loss以及metric 1model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) 导入数据 12345678910111213141516X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()# Normalize image vectorsX_train = X_train_orig/255.X_test = X_test_orig/255.# Convert training and test labels to one hot matricesY_train = convert_to_one_hot(Y_train_orig, 6).TY_test = convert_to_one_hot(Y_test_orig, 6).T# number of training examples = 1080# number of test examples = 120# X_train shape: (1080, 64, 64, 3)# Y_train shape: (1080, 6)# X_test shape: (120, 64, 64, 3)# Y_test shape: (120, 6) 1080张64*64的三通道图片，测试时120张64*64的三通道图片 接下来fit model 1model.fit(X_train, Y_train, epochs = 20, batch_size = 32) 最后evaluate模型 123preds = model.evaluate(X_test, Y_test)print ("Loss = " + str(preds[0]))print ("Test Accuracy = " + str(preds[1])) 同样summary()和plot_model看看参数以及网络结构 123model.summary()plot_model(model, to_file='model.png')SVG(model_to_dot(model).create(prog='dot', format='svg')) Week Three 检测算法目标定位目标检测主要有两类任务，一类是image classification 和 classification with localization，往往只有一个目标需要标记，另一类是detection，往往有多个目标需要标记 当你需要标记目标位置的时候，你的神经网络的输出不仅是一个softmax的概率值，还有图像中心点的x，y坐标以及红框的宽和高的值，假设我们现在检测三类目标，分别是行人，汽车，摩托车，以及三类都没有的纯背景的情况，那么你的y应该设置为 y=\begin{bmatrix}P_c \\b_x \\b_y \\b_h \\b_w \\c_1 \\c_2 \\c_3 \end{bmatrix}其中$P_c$表示的是图中有无目标，如果有目标那么就要定位$b_x,b_y,b_h,b_w$，以及他们的分类$c_1,c_2,c_3$ 当$P_c = 1$的时候，y的所有参数都是需要关心的 当$P_c = 0$，除了$P_c $以外的其余参数都不用关心，图中用问号表示 损失函数可以表示为 L(\hat y,y)=\left\{\begin{matrix} (\hat y_1,y_1)^2+\ldots+(\hat y_8,y_8)^2 & if & y=1\\ (\hat y_1,y_1)^2 & if & y=0 \end{matrix}\right.特征点检测当你检测一个人或者是一个姿势的时候，你可能需要的不是像检测汽车那样只要一个中心点，你可能需要很多个点来检测人脸的五官，或者不同的点来检测一个人的姿势，此时你的y就有很多个点 利用滑动窗口进行目标检测用一个正方形框在图像上以一定步长滑动，每次检测框内的图像，这就是滑动窗口的含义，用不同大小的框可以多次进行 但是滑动窗口的计算成本非常大，如果你的步长选的比较小（精度比较高），那么你要输入系统的图片非常多，计算量就非常大 使用卷积实现滑动窗口使用卷积实现滑动窗口，首先要看看如何把FC层转换为卷积层，在本来应该flatten的地方，再用一组f大小与原图相等的filter，将它变成1*1的volume，然后反复使用1*1的filter，直到最后大小等于1*1*4 同样，在滑动窗口的过程中，有很多的卷积步骤是重复的，因此我们可以使用卷积来避免每个滑动窗口都经历整个卷积神经网络 获得更加精确的边界框YOLO(You Only Look Once)算法是一个很好用的目标检测算法，先讲图片分割成很多个小的矩形，每个矩形中间如果有某个目标对象的中心点，那么这个方框的Y的第一个值$P_c$就为1，否则为0，最后得到一个3*3*8的volume，这个volume就是预测的结果，因为这个算法使用了卷积的方法，因此速度很快 我们来看个例子，比如下图，原图是100*100的大小，我们划分成3*3的格子，绿色和橙色格子有目标，找出中心点，然后标记出方框，绿色块的y值如右边的绿色y所示，橙色如橙色标识的y所示，其余的都是紫色标记 通常我们划分的块会更多一些，以便更加精确地定位图像 边框的标记方法是给出中心点的坐标x，y，已经图像的高度h和宽度w，因为我们对每个小方块的坐标定义为左上角是(0,0)，右下角是(1,1)，所以x,y一定是在0到1之间的值，但是目标的大小可能超出一个方块，所以h和w可以是大于0的任何值（当然也可以大于1），如下图 交并比（intersection over union）交并比：一个方框与真实结果的交集与其并集的比，用于评价目标检测算法的精度 最好情况的交并比是1，一般来说，如果你的交并比（IoU）&gt;=0.5，就认为你的检测是正确的 非最大值抑制(Non-max Suppression)加入你在下图中检测汽车，你把图片分成了19*19大小的网格，两辆车的中心分别是绿色点和黄色点，理论上来说它们各自的中心点应该只会被标记一次，但是你在运行网络的时候，每一个网格都是独立运行的，所以旁边的网格可能也会认为自己就在图片中心，同一个目标可能会被标记好多次，因此引入非最大值抑制的策略来保证每个目标只被标记一次 假设我们现在已经得到了很多个框，你需要去找到哪个框是真的有效的，如下图 具体做法如下： 首先，你将那些概率值都低于0.6的框给删除 只要这里还剩任何框：选择现在概率最大的框最为结果，删除任何与这个结果IoU大于等于0.5的盒子 只要还有框没有标记就跳到第二步 Anchor BoxAnchor Box是用来当你需要检测多个目标的时候，你先给几个预先给定的anchor box，将结果的y联合起来 比如你现在检测行人和车辆，行人的车辆应该是高长的，车辆的扁宽的，本来y是8维的，然后现在连接起来就有16维 然后我们将两个anchor box 和 我们之前圈出来的框计算IoU，图像将被分到高IoU的部分 YOLO算法的完整描述如果你在进行一个定位行人，汽车，摩托车的YOLO算法，如下图，先将图片分成3*3的网格，对每一个网格进行检测，现在设定了2个anchor box，那么最终的输出是3*3*16的结果 我们来看看如何做预测，如下图，我们将最终的结果全为$P_c$全为0的分类成背景，为1的部分去找对应的c的分类 我们再来看看如何使用non-max suppress，先从图中移除那些概率很低的框，然后分别对三个类别（行人，汽车，摩托车）进行non-max suppress得到最终的预测 Week four人脸识别的术语人脸识别任务大致分为两类，分别是face verification 和 face recognition： face verification：指的是给一张图片，判定是否是你要找的那个人，是一个二分类的问题 face recognition：是给一张图片，判定他是谁，是一个多分类问题 单样本学习问题(one shot learning)通常识别任务要求在只有一张图片的情况下进行识别，但是从传统来说，只有一个训练样本的效果是很差的 解决的办法就是，学习出一个相似性函数，给定两张图片，如果两张图片的相似度比较大（距离比较小），那么两张图片就是同一个人。我们设定一个阈值，如果小于这个阈值，我们认为是同一个人，如果大于这个阈值，我们认为是不同的人。这样，即使有新的人加入这个系统，你的系统依然可以进行判断 孪生网络（Siamese Network）普通的卷积神经网络是先经过几个卷基层，然后经过一个FC layer，最后一个softmax进行判别，我们在这里删除最后的softmax层，将最后的FC层的输出作为一张图片的编码 将这些输出的编码作为结果，计算距离，并使得同一个人的不同图片距离小，不同人的图片距离大，以此作为目标进行反向传播，具体的loss函数被称为triple loss function 三重损失函数（triple loss function）我们每次进行训练的图片应该有三张：Anchor，Positive，Negative，分别代表原始图片，同一个人的图片，另一个人的图片，计算Anchor和Positive以及Negative之间的距离，记作d(A,P)和d(A,N)，计算方法是通过神经网络给出的编码，计算欧式距离，要求同一个人的不同图片距离小(d(A,P)小)，不同人的图片距离大（d(A,N)大），并且他们之间不能是基本相同的大小，因为那样对于分类器来说是比较难区分的，我们把差距超过一定范围$\alpha$的才能称为不同人，如下图所示 那么损失函数可以是上图中的右式移到左边，那么要求这个损失小于等于0，那么我们取Loss为 L(A,P.N)=max(||f(A)-f(N)||^2-||f(A)-f(N)||^2+\alpha,\:0)那么代价函数就是 J=\sum_{i=1}^mL(A^{(i)},P^{(i)},N^{(i)})训练的数据要足够的大，一个人应该有好几张图片，如果只有一张图片是很难训练的 如何选择APN也是有要求的，如果你A,P,N都随机选择，那么两张不同人的图片距离一般来说是肯定大于一个人的两张图片的，所以我们应该选那些尽可能接近的距离值去训练，也就是d(A,P)和d(A,N)要尽量靠近一些 在深度学习中，这些系统的名字一般选择为xxNet或者是Deepxx，比如这里的FaceNet和之前提到的DeepFace 二分类的人脸识别另一种进行人脸识别的方法是二分类，当你有一个新的图片需要分类的时候，将它输入一个已经训练好的卷积神经网络，得到一个编码，与系统中另一张图片的编码经过一个logistic单元，最终的$\hat y$如果为1，证明图片来自同一个人，否则来自于不同人 这里有个节省计算能力的好办法，就是系统中的图片，你应该全部先通过卷及网络算出编码，直接存储编码，这样每次你只需要将新图片经过这个神经网络得到编码，再做一个logistic计算就可以了 风格迁移什么是风格迁移如下图，我们将原图(Content)称为C，风格图（Style）称为S，生成的图片（Gnerated image）称为G 深度卷积神经网络究竟学的是什么卷积神经网络的前面层，是一些图片的边缘信息，越到后面的层，信息越丰富 风格迁移的代价函数我们用C表示Content这张图，用S表示Style这张图，G代表Generated image，要求定义的代价函数在最小化时使用梯度下降： J(G) = \alpha J_{content}(C,G) + \beta J_{style}(S,G)风格迁移的过程： 随机初始化G 进行梯度下降，是的cost function变小，然后输出的图像和C和S的混合越来越像 Content cost function你用第$l$层的卷积网络去计算你的content cost function，这个层数不能太靠前（前面全是边缘信息），也不能太靠后（太靠后已经是完整的图片了），你的Content cost function只需要计算第$l$层的Content和Generated 的输出的相似度，我们在这里使用L-2范数 J_{content}(C,G)=||a^{[l](C)}-a^{[l](G)}||^2Style cost function要定义S和G的风格相似度，我们要来看看如何定义风格的相似，这里引入一个Style matrix的概念，用于定义不同层之间的像素值的乘积和，用$a_{i,j,k}^{[l]}$表示第$l$层的一个像素点，用$G^{[l]}$表示第l层的Style Matrix G^{[l](S)}_{kk\prime} = \sum_{i=1}^{n_H^{[l]}}\sum_{j=1}^{n_W^{[l]}}a_{ijk}^{[l](S)}a_{ijk\prime}^{[l](S)} \\ G^{[l](G)}_{kk\prime} = \sum_{i=1}^{n_H^{[l]}}\sum_{j=1}^{n_W^{[l]}}a_{ijk}^{[l](G)}a_{ijk\prime}^{[l](G)} \\第l层的style cost function就用这两个style function的相似度来计算 \begin{array}{rcl} J_{style}^{[l]}(S,G) &=& \frac{1}{(...)}||G^{[l](S)}-G^{[l](G)}||^2 \\ &=& \frac{1}{(2n_H^{[l]}n_W^{[l]}n_C^{[l]})^2}\sum_k\sum_{k{\prime}}(G^{[l](S)}_{kk\prime}-G^{[l](G)}_{kk\prime}) \end{array}通常一层的效果不够好，因此我们多用几层 J_{style}(S,G)=\sum_l\lambda^{[l]}J_{style}^{[l]}(S,G)最终的J就是把content和style的J加起来 J(G) = \alpha J_{content}(C,G) + \beta J_{style}(S,G)1D和3D数据的卷积1D数据通常是信号数据，你用的卷积核应该也是1D的，比如你一开始是14*1的信号，卷积16个5*1的filter，变成 3D图像通常有CT图，视频之类的，有长，宽，深度三个维度，]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>deeplearning</tag>
        <tag>机器学习</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Coursera-deeplearning-ai-（三）]]></title>
    <url>%2F2018%2F05%2F07%2FCoursera-deeplearning-ai-%EF%BC%88%E4%B8%89%EF%BC%89%2F</url>
    <content type="text"><![CDATA[这篇博文主要讲的是关于deeplearning.ai的第三门课程的内容，《Structuring Machine Learning Projects》 Week one机器学习策略简介当你构建了一个机器学习系统，但是结果达不到你的要求的时候，你可能会尝试以下的方法 collect more data collect more diverse training set train algorithm longer with gradient descent try Adam instead of gradient descent try bigger network try smaller network try dropout add L2 regularization network architecture activation functions # hidden units … Orthogonalization(正交化)正如同调整电视或者是汽车的控制一样，通常一个按钮用于调整一个方面，这样才方便调整到你希望的结果，如果一个按钮控制很多个方面，那么你很难将结果调整到合适 在机器学习的过程中，通常需要调整如下图的四个目标 首先是要在训练集上面表现够好（基本达到人工识别的水平），如果效果不够好，尝试更大的网络，或者好的优化算法比如Adam 第二要在dev set 上面表现够好，如果不过好，尝试正则化或者更大的训练集 其次在test set上面表现够好，如果不够好，需要尝试更大的dev set（因为你之前在dev set上面表现已经足够好了，但是在test set上面表现不够好，很可能是因为dev set取的太小了） 最后要求在现实世界的问题中表现够好，如果不够好，那么就要改变你的dev set 或者是 cost function，因为你之前在dev和test上用定义好的cost function已经能达到很好的结果，而在现实世界中不行，那可能就是你的cost function定义不够符合现实问题 设定目标单一数值化评价矩阵加入有A,B两个分类器，其精确率和召回率分别如下，精确率的定义是你分类为猫的样本中真正是猫的比例，召回率是所有是猫的图片最终被正确分类为猫的比例 两个定义倒不是非常重要，重要的是我们通常会需要在这两者当中做折中 如果你尝试了很多组超参的组合，你就需要不仅仅是在2个分类器之间选择，而是在十几个分类器之间选择了 为了能够同时照顾到精确率和召回率，引入一个F1 score，这个指标同时考虑了精确率和召回率 F1score 的定义是precision和recall的调和平均数（hormonic mean），表示为$F_1=\frac{2}{1/P+1/R}$,P和R分别表示精确率和召回率 满足(statisficing)和优化(optimizing)矩阵加入你现在有两个系统，第一个是用来分类猫图片的，但是又要考虑时间；第二个是用来唤醒关键字的，要同时考虑准确率和false positive（没有说话但是被唤醒了） 第一个猫图片系统可以用&lt;=100ms的值的最大精确度来衡量 第二个可以用在24小时内被唤醒小于等于1次的，最大化精度的系统 训练，开发，测试集的分布开发集和测试集需要来自于同一个分布，如果不同，你在开发集上面得到了很好的精度，运用到测试集的时候，就相当于是找另外一个问题的最优值，这样效果一般来说都不够好 在传统的机器学习项目中，因为数据量不是很大，比如有100个，1000个或者10000个数据，通常train和test的比例是7 0%和30%，如果需要dev set的情况就是60%train，20%dev，20%test 在数据量比较大的时候，比如100w条数据的时候，可能98%的train，1%的dev和test，因为1w条dev和test已经绰绰有余了 改变dev/test setd和评估矩阵比如你现在有一个分类猫图片的分类器，其中一个错误率低，但是存在一些色情图片，这个时候就要改变你的评估矩阵，加入一个系数，这个系数当图片不是色情图片的时候为1，是色情图片的时候为10或者100，这样如果是色情图片，错误率就会变得很高，实现了你的要求 再来看个例子，假如你的分类器的dev和test的数据都是高清的猫图片，而最后应用的时候的图片的质量都很差，此时你分不出来猫图片，这个时候我们就要考虑改变dev/test set，或者改变评价指标 与人工分辨水平的比较当你的系统超过了人类的精度的时候，可能就接近一个称之为贝叶斯优化错误或者是贝叶斯错误的值了，这个值是理论上的最佳精度，你不论如何用更复杂的模型或者是调参都无法逾越这个值 与人类相比的原因是因为人类擅长很多方面，只要你的系统还不如人类做得好，你就可以用人工标注出更多的数据，以及分析为什么人工做的比机器好，更好的分析偏差和方差 可避免的偏差和方差训练集误差和贝叶斯误差之间的距离成为可避免的偏差，训练集误差和开发集误差之间的差距成为可避免的偏差，如下图所示 两者当中，哪个大我们就专注于减少哪一个 超过人工水平人类尤其擅长感知任务，比如图片分类，自然语言处理和语音识别，机器更擅长数据挖掘，找寻数字规律等任务 机器在感知领域能够超越人工水平是非常棒的效果，现在越来越多领域已经可以超越人类 改进模型效果的策略如下图，改进模型表现，主要有两点，首先是可以在训练集上面表现的很好，然后是扩展到开发集和测试集 具体来说，对于不同的问题，有如下的策略 Week Two错误分析加入你现在建立了一个分类猫的分类器，但是你发现其中有些狗的图片也被分成了猫，那么你是否需要去找更多的狗的图片并标记好，放在你的训练样本中呢？ 这个时候我们就需要进行错误分析，看看我们对某个方向的努力是否值得 错误分析的步骤： 找出100个错误标记的开发集样例 计算这里有多少张本来是狗，结果分成了猫的情况 如果这里100张分错的样例中只有5张是狗，那么也就是5%的错误原因来源于狗的图片。如果你之前的错误率是10%，那么你最多也就只能减少5%，达到9.5%，这显然不太值得去做 如果这100张分错的样例中有50张是狗，那么就是50%的错误原因来源于狗的图片。如果你之前错误率是10%，那么现在可以减少50%，达到5%，这就值得去做了 当然，我们可能会找到很多个方向去优化，比如在猫的分类器的问题中： 解决狗被分成猫的情况 解决大型猫科动物（狮子，老虎等等）被认为是猫的情况 解决模糊图片分错的问题 这个时候，我们找出大概100张分错的图片，然后列一个表格，对每个分错的图片进行归因，最终得到每个因素的影响的比例，为我们提供改进的参考，如下图： 清理标记错误的数据当训练集中存在标记错误的数据的时候，只要比例不是很大，深度学习系统是可以克服这样的情况的 当开发集和测试集中存在错误标记的数据的时候，我们就把错误标记也看作一个影响因素，然后加入一列在上面的错误分析表中，如果影响大则去纠正，否则就先纠正别的 快速建立你的第一个系统，并迭代假如你现在正在建立一个语音识别的系统，你可能考虑很多下图左边的影响，比如背景噪声，方言的影响等等。 但是正确的做法应该如右边所示，首先建立一个开发和测试集以及评价矩阵，然后快速建立一个系统，之后使用偏差/方差分析和错误分析来进行迭代，优化你的系统 不匹配的训练和开发/测试集数据假设你现在有一个分类猫的app，你能从网上找到的猫图片都是高清的，但是用户用手机上传的都是不够清晰的，这时就有一个训练与开发/测试集数据不匹配的问题 假设你能从网上找到20w张高清猫图，而用户那种模糊的图只有1w张 现在有两种方案： 随机混合所有数据，用20500张训练，2500张开发集，2500张测试集 将20w张高清图和5k张模糊图用于训练，2500张模糊图作为开发集，2500张模糊图作为测试集 显然第一种方法是错误的，因为如果你随机混合之后，2500张开发集中只有119张来自于模糊图，你最终的目标是去识别模糊图中的猫，这样一来目标就设置错了 因此我们选用第二种方法 再假设你现在在开发一个语音激活的后视镜系统，你有别的语音数据50w条，而语音控制后视镜的你有2w条，那么正确的方法应该是50w条语音加上1w条控制语音作为训练，5k条控制语言作为开发集，5k条控制语言作为测试集 不同分布数据的偏差/方差分析假设你现在有一个猫分类器，training error是1%，dev error 是10%。同时，你已经知道你的训练数据和dev/test数据分布不同，训练图清晰，dev/test数据不清晰。那么你这个1%到10%的差距，到底来源于high variance还是来自于数据的不匹配呢？此时就说不清了 我们在可能存在数据不匹配的情况下，再划分一个training-dev set，用于衡量究竟是high variance 还是数据不匹配对系统造成了印象，分类方式如下图，原来的train set分成了train和training-dev，原来的dev和test不变 接下来在新的train set上面训练，并用training-dev set和dev/test set进行测试，根据结果来判断到底是high variance造成的问题，还是数据不匹配造成的问题，那么怎么判断呢，我们来看几个例子 例1. 你现在的training error 是1%，training-dev error是9%，dev error 是10%，可以看到，即使数据分布相同时，数据的variance依然很高，所以我们先处理high variance的问题 例2. 你现在的training error 是1%，training-dev error是1.5%，dev error 是10%。可以看到，数据分布相同时的差距很小，而数据分布不同的时候差距很大， 应该着重处理数据失配(missmatch)问题 human error和training error之间的差距是avoid bias，需要更复杂的模型或者超参数 traning error 和 training-dev error之间的差距是high variance，需要正则化 training-dev error 和 dev error之间的差距是data missmatch dev error 和 test error 之间的差距是 overfitting dev set，要找一个更大的dev error 解决data missmatch解决data missmatch的方法，总体来说就是构造与dev/test相同分布的数据 我们举个例子，比如你现在有很多安静环境下的录音，同时还有少量汽车噪音下的录音，我们最终的dev/test数据是这个汽车噪音下的录音，因此我们可以将安静环境下的录音与单纯的汽车噪音混合，这样我们就快要得到更多汽车噪音下的数据 但是在混合的时候也要注意，比如你现在有10000小时的安静录音，1小时的汽车噪音，你将这1小时的汽车噪音重复到10000次得到10000小时的汽车噪音，这对人耳来说可能是正常的，但是对于深度学习算法来说，可以就会对这1小时的汽车噪声产生过拟合。因此正确的做法是尽可能收集10000小时的汽车噪声，然后与这10000小时的安静录音混合。 迁移学习假如你现在有两个任务A和B，你有大量的A的数据，只有少量B的数据，但是你最终想要去识别B，此时，只要A和B是同一类的数据（比如都是图片，或者都是语音），那么我们就可以使用迁移学习 迁移学习就是用数据量大的A数据先构建模型，然后去掉输出层（数据量非常少的时候，如果数据量稍微多一些，可以多去掉几层），用数据量少的B的数据进行训练，最终这个系统能够很好地分类B 举个例子，比如你现在有个分类猫的分类器，但是你想要能够分类x光，那么你先用猫的数据建立分类猫的分类器，然后去掉输出层，再用x光的数据进行训练，就得到了一个分类x光的分类器 再比如说你有一个语音识别的分类器，现在要建立一个唤醒词的分类器，那么你只需要去掉输出层，然后再训练唤醒词分类器即可，这个唤醒词分类器可以只有1层，也可以扩展为好几层 多任务学习假设你正在做一个自动驾驶物体检测的问题，检测一张图上是否有行人，车辆，路标和交通灯，如果有则标记出来，比如下面这张图的标记为y=(0,1,1,0) 所谓的多任务学习就是一次学习出的分类器可以分类多个目标，比如上述的问题，我们把四个的loss放到一起，甚至有些分类没有标记也是可以学习的，你只需要在计算loss的时候只算标记好的类型，如下图 多任务学习和softmax回归的区别：多分类可以有多个类别是1，而softmax回归只能有一个类别为1 端到端的深度学习传统的机器学习方法，是输入原始数据，然后分好几步提取特征，最终得到分类结果 端到端的学习，就是直接输入原始数据，得到最终的分类结果，这是需要大量的数据作为支撑的 举个例子，在人脸识别这个问题中，你是不能使用端到端的方法的，因为在人脸识别的时候，人脸可能处于图中任何位置，因此没有这么多的数据支撑你进行端到端的识别。你应该分成两个子任务，首先是提取出人脸这个任务，然后再是人脸的比较任务 再比如机器翻译这个任务，用端到端的方法是很合适的，因为翻译的数据足够多，可以支撑你的端到端方法 决定是否使用端到端的方法端到端学习的优劣势 优势： 数据自我解释 很少的需要动手去设计的中间步骤 劣势： 需要大量数据 不能使用手动设计的步骤中的有效内容 是否使用端到端的方法，最主要的问题就是你是否有足够的数据去找出x到y的映射 比如在自动驾驶的过程中，目标检测的过程我们用的是深度学习的方法，在路径规划的时候用的是motion planning 的方法，然后到如何控制油门刹车，方向盘之类的时候用的是控制学]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>deeplearning</tag>
        <tag>机器学习</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[download-from-coursera-jupyter-notebook]]></title>
    <url>%2F2018%2F05%2F02%2Fdownload-from-coursera-jupyter-notebook%2F</url>
    <content type="text"><![CDATA[为了从coursera上面下载写过的jupyter notebook，可以在根目录下新建一个notebook，执行以下代码，然后生成一个currdir.tar的文件，下载这个文件即可 123456789101112131415161718import osimport tarfiletarFileName='currdir.tar'def RecursiveFiles(dn='.',ignoreTarFile=tarFileName): ignore=&#123;'.pynb_checkpoints','pycache',ignoreTarFile&#125; for dirname,subdirs,files in os.walk(dn): if os.path.basename(dirname) in ignore: continue for fn in files: fname=os.path.join(dirname,fn) yield(fname) #return # 这个return在我的notebook中要注释掉，网上说有些情况下要不注释，因此需要尝试一下def makeTarFile(dn='.',tfn=tarFileName): tar=tarfile.open(tfn,'w') for name in RecursiveFiles(dn,tfn): tar.add(name) tar.close()makeTarFile()]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>coursera</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode 322 解答--动态规划]]></title>
    <url>%2F2018%2F04%2F23%2Fleetcode-322-%E8%A7%A3%E7%AD%94-%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%2F</url>
    <content type="text"><![CDATA[题目给定不同面额的硬币(coins)和一个总金额(amount)。写一个函数来计算可以凑成总金额所需的最少的硬币个数。如果没有任何一种硬币组合方式能组成总金额，返回-1。 示例 1:coins = [1, 2, 5], amount = 11return 3 (11 = 5 + 5 + 1) 示例 2:coins = [2], amount = 3return -1. 注意: 你可以认为每种硬币的数量是无限的。 解答动态规划的思路是用一个数组来存放需要的值，在零钱问题中，用dp[i]来表示凑齐钱数i所需要的最少硬币。 考虑凑齐钱数amount需要的最少硬币：如果需要coin[j] 硬币一枚，那么就相当于求dp[amount-coin[j]]，j的遍历范围是从0到len(coin)-1 本来我们应该要把所有dp赋值为正无穷，但是因为就算是最小的面值为1，那么组成amount也只需要amount枚硬币，因此我们把所有的值都赋值为amount+1，首先定义一个迭代的起始值，组成0元钱只需要0枚硬币，即dp[0]=0 接下来开始遍历所有的coins，再遍历所有的dp，dp[i]应该等于自身和dp[i-c]+1当中小的那个，相当于用了一枚面值为c的硬币之后，dp[i-c]所用的最少的硬币，加上这一枚面值c硬币需要的总数 123456789class Solution(object): def coinChange(self, coins, amount): dp = [amount+1 for _ in range(amount+1)] dp[0] = 0 for c in coins: for i in range(c,amount+1): dp[i] = min(dp[i],dp[i-c]+1) return -1 if dp[amount]==amount+1 else dp[amount] 变形：给定不同面额的硬币(coins)和一个总金额(amount)。写一个函数来计算可以凑成总金额可能的组合情况。如果没有任何一种硬币组合方式能组成总金额，返回0。 这里的区别和上面只是初始dp的方法和起始值dp[0]不同 此时的dp[0]=1，因为用所有硬币组合成0元钱只有一种方法，那就是所有的硬币都取0枚 然后dp其余值初始化为0，因为一开始是没有组成后面的可能的，迭代条件变为dp[i] = dp[i] + dp[i-c]，表示用一枚硬币c的时候，组合的情况 123456789class Solution(object): def coinChange(self, coins, amount): dp = [0 for _ in range(amount+1)] dp[0] = 1 for c in coins: for i in range(c,amount+1): dp[i] += dp[i-c] return -1 if dp[amount]==amount+1 else dp[amount] 循环数组的不相邻求和最大值因为结果不能同时包含最后一个值和第一个值，因此做两次调用，一次是1到最后，一次是0到倒数第二个，取其中最大值 迭代的条件是dp[i] = max(my_list[i]+dp[i-2],dp[i-1])，因为要么当前值加上跳过上一个值的和，要么不要当前值，要上一个值的和，取两者的最大值 1234567891011121314def sum_max(my_list): dp = [0 for _ in my_list] dp[0] = my_list[0] dp[1] = max(my_list[1],my_list[0]) dp[2] = max(my_list[1],my_list[0] + my_list[2]) for i in range(3,len(my_list)): dp[i] = max(my_list[i]+dp[i-2],dp[i-1]) # if max(dp) == dp[i]: return max(dp)if __name__ == '__main__': test_list = [10,3,5,7,9] print(max(sum_max(my_list=test_list[1:]),sum_max(test_list[:-1])))]]></content>
      <categories>
        <category>编程练习</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>动态规划</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[selenium 爬取ajax动态网页]]></title>
    <url>%2F2018%2F04%2F16%2Fselenium-%E7%88%AC%E5%8F%96ajax%E5%8A%A8%E6%80%81%E7%BD%91%E9%A1%B5%2F</url>
    <content type="text"><![CDATA[最近有一个爬取教育部数据库的任务，一开始用了requests库，能获取到网页验证码什么的，但是各种的ajax动态加载太麻烦了，最后想到了用selenium进行爬取 初始化webdriver，用chrome进行爬取，此时需要下载chrome的驱动，下载地址 123456789url1 = 'https://isisn.nsfc.gov.cn/egrantindex/funcindex/prjsearch-list'from selenium.webdriver.support.ui import WebDriverWaitfrom selenium.webdriver.common.by import Byfrom selenium.webdriver.support import expected_conditions as ECfrom selenium.webdriver.common.keys import Keysfrom selenium.webdriver.support.ui import Selectbrowser = webdriver.Chrome()browser.get(url1) 接下来填充网页内容，因为有ajax动态加载的部分，我们填入一部分之后需要等待一会，用time.sleep(0.5)等0.5秒就行了 1234browser.find_element_by_name('subjectCode').click()browser.find_element_by_name('subjectCode').send_keys('F030203')time.sleep(0.5)browser.find_element_by_name('subjectCode').send_keys(Keys.RETURN) 然后对下拉选择的内容用Select对象进行选择 1234s1 = Select(browser.find_element_by_id('f_grantCode'))s1.select_by_index(1)s2 = Select(browser.find_element_by_id('f_year'))s2.select_by_value('2017') 用pytesseract进行验证码识别，在安装pytesseract之后，还要安装Tesseract-OCR这个程序，在安装完成之后，只需要 一句code = pytesseract.image_to_string(im)就可以进行验证码识别，这样识别的精度并不高，因此我们需要用try ，except来catch意外 12345678910111213141516import pytesseractdef get_captcha(browser): browser.get_screenshot_as_file('screenshot.jpg') element = browser.find_element_by_id('img_checkcode') left = int(element.location['x']) top = int(element.location['y']) right = int(element.location['x'] + element.size['width']) bottom = int(element.location['y'] + element.size['height']) im = Image.open('screenshot.jpg') im = im.crop((left, top, right, bottom)) im.save('screenshot.jpg') im = Image.open('screenshot.jpg') pytesseract.pytesseract.tesseract_cmd = 'C:\\Program Files (x86)\\Tesseract-OCR\\tesseract' code = pytesseract.image_to_string(im) return code 输入验证码，并保存网页。 123456code = get_captcha(browser)print(code)browser.find_element_by_id('f_checkcode').send_keys(code)browser.find_element_by_id('searchBt').click()with open('my.html','w',encoding='utf-8') as f: f.write(browser.page_source) 如果验证失败，一直输入直到成功 123456789while True: try: if browser.find_element_by_id('f_checkcode'): code = get_captcha(browser) browser.find_element_by_id('f_checkcode').clear() browser.find_element_by_id('f_checkcode').send_keys(code) browser.find_element_by_id('searchBt').click() except: break 进入搜索结果之后需要点击下一页，直到最后一页，此时用到的方法就是通过看next button上面的class，直到class变成disable就可以停止了，用正则表达式，正则表达式搜不到的时候返回是None，但是好像返回的是字符串类型的None，判断是应该是 while re.search(xxx) is None 1234567def click_next_page(): code = get_captcha(browser) browser.find_element_by_id('checkCode').send_keys(code) browser.find_element_by_css_selector('.ui-icon.ui-icon-seek-next').click()while re.search('ui-state-disabled',browser.find_element_by_id('next_t_TopBarMnt').get_attribute("class")) is None: click_next_page() 然后把所有网页的内容用beautifulsoup进行解析就行了 1soup = BeautifulSoup(browser.page_source,'lxml')]]></content>
      <categories>
        <category>编程练习</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Coursera-deeplearning-ai-（二）]]></title>
    <url>%2F2018%2F04%2F11%2FCoursera-deeplearning-ai-%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[这篇博文主要讲的是关于deeplearning.ai的第二门课程的内容，《Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization》 Week one设置训练，验证，测试集设置神经网络时，有很多的值需要你自己设置，比如隐藏层的数量，隐藏点的个数，学习率，激活函数的类型等等…… 数据通常被分为三部分：训练集，hold-out交叉验证集（或者成为开发集dev），测试集。分布如下图所示： 多年前，数据较少：70%的训练数据和30%的测试数据，或者60%训练数据，验证集和测试集各占20% 但现在数据越来越多，100w的总数据，验证集和测试集可能都只需要1w个就行了，剩下的98w数据都可以用于训练，比例为98/1/1 数据更多的时候，可能开发集和测试集所占的比例更小 数据不平衡训练集，开发集，测试集的数据分布不同，比如图片识别中，两边的数据来源不同（一边是高清图片，一边是模糊图片），这时候只需要保证开发集和测试集在同一个分布即可。 偏差方差深度学习中有一个问题叫做“偏差-方差困境”，要在偏差和方差之间权衡 如何判断是高方差还是高偏差往往通过训练集误差和开发集误差的对比来进行判断： 训练集误差小，开发集误差大，证明过拟合了，高方差 训练集误差大，开发集误差约等于训练集误差，证明欠拟合，高偏差 训练集误差大，开发集误差远大于训练集，证明高偏差且高方差，这是因为在某些数据上过拟合，而在大部分数据上欠拟合 训练集误差小，开发集误差也很小，这就是最理想的状态 下面这个分类猫的例子比较直观解释了上面四种情况，注意，此时所谓的大小是因为我们设置的贝叶斯先验错误为0%，所以认为1%小，15%大。如果贝叶斯先验概率不是0%而是15%，那么15%的错误率也是很小的了。并且此时要求训练集和开发集的数据分布是相同的（如果一个是高质量数据，一个是低质量数据，那么两个本来错误率就不一样）。 机器学习的基本准则训练好模型之后： 首先询问，是否存在高偏差（在训练集上面的表现），如果存在，那么你可以尝试使用更大的网络（更多层和更多隐藏点），或者尝试训练更多的迭代次数。尝试多种方法，直到将偏差减小到一个可以接受的范围。 再看看是否有较高的方差（在开发集上面的表现），如果存在，那么比较好的办法就是增加训练数据，或者是正则化 正则化如果发现过拟合，那么就是方差过大，首先应该尝试的方法就是正则化 以逻辑回归为例，为了最小化代价函数$J(W,b)=\frac{1}{m}\sum_{i=1}^{m}L(\hat{y}^{(i)},y^{(i)})$，我们在后面加上一个W的范数，常用的范数为二范数，代价函数变为： $J(W,b)=\frac{1}{m}\sum{i=1}^{m}L(\hat{y}^{(i)},y^{(i)})+\frac{\lambda}{2m}||w||^{2}{2}$ 其中的$\lambda$是正则化参数，$||w||^{2}{2}$称为w的二范数，$||w||^{2}{2}=\sum{j=1}^{n{x}}w_j^2=w^Tw$ 为什么只对w正则化而忽略b呢，这是因为在过拟合的情况下，w的维度非常大，而b只有一个参数，影响相对于w来说可以忽略 偶尔也用一范数，但很少用，具体的逻辑回归的正则化方法如下 神经网络的正则化神经网路的正则化的方法和逻辑回归基本一样，只是w的二范数成了w矩阵的元素平方和，这个值被称为Frobenius norm（弗罗贝尼乌斯范数） 在反向传播的时候，反向传播的$dw^{[l]}$就成了原本的反向传播的值（下图中间绿色方框行，由代价函数J求导得到），加上$\frac{\lambda}{m}w^{[l]}$，w的更新公式就成了这样: $w^{[l]}=(1-\frac{\alpha\lambda}{m})w^{[l]}-\alpha(原本的反向传播值)$ 所以正则化之后，每次更新相当于只是在原本的w前面乘以一个略小于1的值$1-\frac{\alpha\lambda}{m}$，再减去原本的反向传播的值，因此神经网络的正则化又被称之为权重衰减 为什么正则化可以消除过拟合如图，如果过拟合，我们在加入正则化之后，如果把$\lambda$设置的非常大，那么为了是代价函数最小，w必须非常小，那么w的很多值就为0了，多层神经网络看上去就像是一个简单神经网路一样 另一个直观解释是当你使用tanh之类的激活函数的时候，当$\lambda$非常大的时候，那么w非常小，因此z也非常小，经过激活函数变化之后的a也非常小，因此a值只能在0附近变化，这一段tanh函数基本相当于一个线性函数，也就是多层神经网络变化之后基本相当于在做线性变换，就变成一个接近线性变化的值 dropout 正则化dropout正则化，也就是丢弃法正则化，也成为随机失活正则化。 对每个点进行抛硬币，50%的概率丢弃该点，得到一个丢弃一部分的神经网络，这个方法虽然听上去不可靠，但是实际表现却不错 随机失活正则化的实现方法： 假设有一个L=3的神经网络，先设置一个保留率keep-prob，随机产生一个3*n的矩阵，与keep-prob比较之后产生d3，让原本的w乘以这个d3，再除以一个keep-prob以消除引入随机失活的影响（因为你引入随机失活，相当于对某层的a乘以一个keep-prob，那么我要结果一样，就要除以一个keep-prob） 举个例子为什么要除以keep-prob，比如我们现在第三层有50个点，如果keep-prob为0.8的话，那么这层大概平均来说有10个点要失效，$z^{[4]}=w^{[4]}a^{[3]}+b^{[4]}$，那么此时的$a^{[3]}$的期望就变成了原来的80%，为了使得$z^{[4]}$的期望不变，我们就需要将$a^{[3]}$除以一个keep-prob来确保$z^{[4]}$期望不变。 随机失活正则化的理解直观解释：因为你不知道哪一个神经元可能被丢弃，所以你不能过分依赖某个神经元，因此权重就不得不分散 在真正使用的时候，如果你担心某层容易过拟合，那么就把这一层的留存率设置的低一些；如果确认不会过拟合，那就把留存率设置接近1，比如在输入层这里留存率就应该是1 其它正则化方法在图片处理的时候，如果你没有更多的数据，比如处理猫之类的：你可以将图片进行水平翻转，或者放大旋转之类的，处理数字的时候：可以扭曲加旋转 另一种方法叫做早终止方法（early stopping） 画出训练集的代价函数和开发集的代价函数，选择两者都还比较小的值 归一化（normalization）归一化可以加速训练过程 归一化的过程：减去均值（$x-\mu$），将方差归一化$(x-\mu)/\sigma$ 归一化过程中一定要注意，对训练集和测试集都需要归一化 梯度消失和梯度爆炸比如你的激活函数是g(z)=z，然后$\hat{y}=w^{[l]}w^{[l-1]}…w^{[2]}w^{[1]}$，只要所有w都是对角矩阵，他的某一项大于1，则出现梯度爆炸，求出的梯度非常大，或者是梯度消失，求出的梯度基本为0 权重初始化和深度网络特殊地初始化可以部分解决梯度爆炸和梯度消失的问题 在使用Relu激活函数的时候： $W^{[L]}=np.random.randn(shape)*np.sqrt(1/n)$ 梯度检验根据导数的定义，对代价函数进行求导： 检查：两个导数之间的欧式距离/两个导数的2范数之和，如果基本等于$\epsilon$的话，那就说明正确了，如果大于$\epsilon$很多的话，就说明错了 梯度下降的实现 只在调试的时候用提督检验，在训练的时候不要用 如果算法梯度检验失败，检查每一个dw，db来找到程序的bug 记得正则化 在没有dropout的时候先进行梯度检验，发现算法没有问题再使用dropout 随机初始化可以先运行一下梯度检验 合适的初始化方法He初始化方法（He et al., 2015），在激活函数是Relu的时候非常有效，具体做法是$W^{[l]}=\rm{np.random.randn}(layer_dimension[l],layer_dimension[l-1])*\rm{np.sqrt}(2./layer_dimension[l-1])$ 第二周优化算法向量化可以高效计算m个example，但是当example非常多的时候，计算起来也是非常的慢的，比如你现在有500w个example，拿计算起来就是非常慢的 为了加快计算的速度，提出了mini-batch gradient descent，也就是批量梯度下降，将数据分成一个个的小batch，然后进行前向传播，反向传播，参数更新等步骤，这样计算速度会快上很多 比如现在有500w条数据，将每1000条数据凑成一个batch，用{}来表示第多少个batch，现在分成了$X^1$到$X^5000$共5000个batch，每个batch的维度是$(n_x,1000)$ Y以同样的方法被分成5000份，每个$Y^$的维度是(1，1000) 到目前为止，我们一共用过三种括号，分别是小括号，中括号，和大括号 小括号：$x^{(i)}$，表示第i个训练实例 中括号：$Z^{[L]}$表示第L层 大括号：$X^$,$Y^$表示第t个batch 分成batch之后的步骤和之前的神经网络的构建步骤一样，只是多了一重循环batch的for 理解mini-batch梯度下降批量梯度下降的损失函数往往一直下降，但是mini-batch梯度下降存在噪声，但是整体趋势是下降的 两种极端情况： 如果mini-batch的size=m，那么这就是梯度下降，梯度下降的好处是每一步迭代都是往最优值的方向去靠近，但是数据量很大的时候，批量梯度下降就会非常的慢，这种情况又被称为批梯度下降 如果mini-batch的size=1，那么这种情况就是每次输入一个example，这样每次迭代的方向可能是乱的，最终的结果可能在最优值附近徘徊，这种情况又被称为随机梯度下降 只有mini-batch值合适的时候，才能既用到向量化的加速运算，又能得到一个最优值 一般认为： 在m&lt;=2000时，认为数据量足够下，可以使用批量梯度下降 在m&gt;2000时，通常使用的mini-batch的size为64, 128, 256, 512，用2的倍数是因为内存读取的方式是通过2的倍数来读取的，这样能够加快运算 指数加权平均如图，是一大堆温度数据，我们为了对温度数据做个平均，用v0=0,$v1=0.9v_0+0.1\theta_1$，一直到$v_t=0.9v{t-1}+0.1\theta_t$进行指数加权平均 这种指数加权平均的效果的$v{t}$就大致等同于对$\frac{1}{1-\beta}$天的数据进行平均，其中$\beta$是$v_t=\beta v{t-1}+(1-\beta)\theta_t$这个公式中的系数 比如，当$\beta=0.9$时，这就相当于对前10天的数据进行平均；当的$\beta=0.98$时，这就相当于对前50天的数据进行平均；当的$\beta=0.5$时，这就相当于对前2天的数据进行平均 更大的$\beta$意味着更平滑的曲线，但是对数据的延迟性也更大 指数加权平均的理解通用的迭代公式：$vt=\beta v{t-1}+(1-\beta)\theta_t $ 我们来举个例子，假如$\beta=0.9$ 那么 $v{100}=0.9 v{99}+0.1\theta_{100}$ $v{99}=0.9 v{98}+0.1\theta_{99}$ $v{98}=0.9 v{97}+0.1\theta_{98}$ 将$v{100}=0.9 v{99}+0.1\theta_{100}$展开可以得到 $v{100}=0.9 v{99}+0.1\theta{100}=0.1\theta{100}+0.9(0.1\theta{99}+0.9 v{98})=0.1\theta{100}+0.9*0.1\theta{99}+0.9^2(0.9 v{97}+0.1\theta{98})…$ 这个过程与我们平时的平均数有类似的地方，因为我们平时求解的平均数是在每个$\theta$前面的系数相等，都是1/n，在指数加权平均的时候，将靠的近的系数放大，靠的远的系数变小，以指数形式衰减 这样下去，要使得v的加和的那一项足够小， 也就是$0.1*0.9^{t}$足够小的情况下，$0.9^{10}=1/e$，就认为是10天的平均 指数加权平均的好处： 我们可以看到指数加权平均的求解过程实际上是一个递推的过程，那么这样就会有一个非常大的好处，每当我要求从0到某一时刻（n）的平均值的时候，我并不需要像普通求解平均值的作为，保留所有的时刻值，类和然后除以n。 而是只需要保留0-(n-1)时刻的平均值和n时刻的温度值即可。也就是每次只需要保留常数值，然后进行运算即可，这对于深度学习中的海量数据来说，是一个很好的减少内存和空间的做法。 偏差修正因为$v_0=0$，而$v_1=0.98v_0+0.02\theta_1$，因为$v_0=0$，所以$v_1=0.02\theta_1$；$v_2=0.98v_1+0.02\theta_2$，$v_2=0.0196\theta_1+0.02\theta_2$ 由于上面两个等式展现的原因，这些v的值在初始阶段都很小，为了使这些初始阶段的值可以作为平均，我们用$v_t=\frac{v_t}{1-\beta^t}$来进行偏差修正，如下图 动量(Momentum)梯度下降动量梯度下降比普通的梯度下降更快，其主要思想是：计算梯度的指数加权平均，使用这个梯度来更新权重 实现的方式如下，$\beta$参数最常用的值就是0.9： 进行动量梯度下降之后，纵轴上的偏差被减小了，得到如下图红线的效果 RMSprop(Root Mean Square prop)算法实现的方法和momentum类似，但是公式变成了 $S{dw}=\beta_2S{dw}+(1-\beta_2)dw^{2}$ $S{db}=\beta_2S{db}+(1-\beta_2)db^{2}$ 而迭代公式变成了 $w:=w-\alpha\frac{dw}{\sqrt{S_{dw}}+\epsilon}$ $b:=b-\alpha\frac{dw}{\sqrt{S_{db}}+\epsilon}$ 加一个$\epsilon$是为了不出现除以0的情况 Adam(Adaptive moment estimation) 优化算法Adam(Adaptive moment estimation)的意思是：适应性矩优化，这里的矩指的是一阶矩，二阶矩那个矩。 Adam就是将momentum和RMSprop结合起来 实现方法如下图，注意这里的参数都需要修正偏差： 里面的超参，一般来说momentum的超参$\beta_1=0.9$，RMSprop的超参$\beta_2=0.999$，$\epsilon=10^{-8}$，学习率$\alpha$ 是需要去调整的参数，Adam的公式如下，将w换成b则得到b的更新公式 \begin{cases} v_{dW^{[l]}} = \beta_1 v_{dW^{[l]}} + (1 - \beta_1) \frac{\partial \mathcal{J} }{ \partial W^{[l]} } \\ v^{corrected}_{dW^{[l]}} = \frac{v_{dW^{[l]}}}{1 - (\beta_1)^t} \\ s_{dW^{[l]}} = \beta_2 s_{dW^{[l]}} + (1 - \beta_2) (\frac{\partial \mathcal{J} }{\partial W^{[l]} })^2 \\ s^{corrected}_{dW^{[l]}} = \frac{s_{dW^{[l]}}}{1 - (\beta_2)^t} \\ W^{[l]} = W^{[l]} - \alpha \frac{v^{corrected}_{dW^{[l]}}}{\sqrt{s^{corrected}_{dW^{[l]}}} + \varepsilon} \end{cases}学习率衰减我们用下面的公式来衰减学习率$\alpha$： $\alpha=\frac{1}{1+decay_rate\times epoch_num}\alpha_0$ decay_rate是这里的下降率，epoch_num是迭代的次数 局部最优解在二维图像中，很容易产生局部最优解，但是在高维的时候，你要找到一个这个点在所有维度上梯度都为0，这是非常困难的，我们称这种有部分维度梯度为0的点为鞍点，因为图形的形状就好像马鞍一样 Week 3Batch Normalization调参过程神经网络有很多的超参，调整超参有利于改进神经网络的性能 参数有很多，包括：学习率$\alpha$，momentum当中的$\beta$，Adam优化中的$\beta_1,\beta_2,\epsilon$，网络层数，隐藏单元，学习率衰减方式，mini-batch的size 一般来说需要调整的重要程度排序为： $\alpha&gt;\rm{momentum当中的}\beta=mini-batch\ size=隐藏单元数量&gt;网络层数&gt;学习率衰减参数&gt;&gt;Adam（Adam一般不调参，用默认参数\beta_1=0.9,\beta_2=0.999,\epsilon=10^{-8}）$ 但这并不是一个死板的规定，可能有其他的规则 早期调参的时候，通常是启发式搜索，然后给定最优的参数；参数很多的时候，建议随机选择点，进行尝试，如下图右边 当你能确定更小的范围的时候，就可以在这个范围内进行更加密集的搜索，直到找到你能接受的最优参数 选择合适尺度去选取超参数很多超参数是不能在某个范围内均匀取样的，比如考虑学习率$\alpha$，让$\alpha$从0.0001到1取值，肯定要求在0.0001到0.001之前取多点，而0.1-1之间要比较少，所以我们此时用到对数的取法，也就是从10e-4取到10e0，那我们就只需要去一个-4到0的随机数，用a = -4 np.random.randn(), alpha=10*a 还有比如momentum当中的$\beta$参数，如果让$\beta$从0.9取到0.999，在靠近0.999的时候，稍微改变一点点都会让平均值的范围变化很大，因此在后面我们要取的密集一些，我们考虑$1-\beta$，$\beta$从0.9到0.999，那么$1-\beta$就从0.1到0.001，取一个从-3到-1的随机数，再用10的指数来代替$1-\beta$，那么$\beta=1-10^t$ 熊猫模型和鱼子酱模型熊猫模型：关注你的模型，就如同熊猫产子一般，一次调整一点 鱼子酱模型：一次同时开始多个模型的训练，如同鱼类产子一般 计算资源足够的时候，就用鱼子酱模型，否则用熊猫模型 这两个名称只是为了好记忆，并没有特别的意思 批量归一化在之前的归一化当中，我们只是对第一步的输入进行了归一化，但是其实每一层神经网络的输入应该都有归一化，在归一化z和a这两种选择中，业界都默认归一化z 对z的归一化过程如下： 红框部分就是归一化的过程，对于每一个z(i)，计算均值$\mu$，方差$\sigma^2$，然后用$z^{(i)}{norm}=\frac{z^{(i)}-\mu}{\sqrt{\sigma^2+\epsilon}}$，这里加一个$\epsilon$的原因是为了避免除以0的情况发生，然后用$\tilde{z}^{(i)}=\gamma z^{(i)}{norm}+\beta$，这个$\gamma$和$\beta$是可以从模型当中学习出来的参数。 为什么要用$\gamma$和$\beta$这两个参数呢，是因为比如你中间某一层的激活函数是sigmoid函数，如果你让你的z均值为0，方差为1，那么z的变化范围就很靠近0，这是sigmoid函数基本就成了线性函数，为了利用好sigmoid的非线性，所以对中间的z的归一化稍有不同 将batch-norm运用到神经网络中假设我们有一个如下图所示的三层神经网络，那么我们将x输入，通过w[1]和b[1]，得到z[1]，对z1进行batch-norm，通过$\gamma^{[1]}$和$\beta^{[1]}$得到$\tilde{z}^{[1]}$，然后将$\tilde{z}^{[1]}$通过g[1]得到a[1]，同理得到z[2]，$\tilde{z}^{[2]}$，a[2] 此时的参数就有了w[1],b[1],w[2],b[2]，$\gamma^{[1]}$,$\beta^{[1]}$,$\gamma^{[2]}$,$\beta^{[2]}$,在TensorFlow中我们可以直接一行语句实现batch-normalization,tf.nn.batch-normalization 那如何将batch-normalization用到mini-batch-normalization中呢 如下图，每次用一个mini-batch，对其进行batch-normalization。 值得注意的是，因为$z^{[l]}=w^{[l]}a^{[l-1]}+b^{[l]}$，而$z_{norm}=\frac{z-\mu}{\sqrt{\sigma^2+\epsilon}}$，每次归一化的时候减去了均值，所以加的$b^{[l]}$会被减掉，因此b这个参数在mini-batch-normalization时可以忽略 实现的具体方法，对于每一次mini-batch t，计算对于$X^{[t]}$的前向传播，对每个隐藏层使用BN（batch-normalization）方法，然后反向传播去更新W,$\beta$,$\gamma$三个参数（b被减掉因此忽略），当然这里更新的方式可以是momentum，RMSprop或者Adam 为什么batch-normalization会有效首先，normalization会使得所有的x的值在同一个量级上面，这样能够加速迭代 协变量转换（covariate shift）是指在数据x变化之后，原来的网络不适用于分类新的数据的情况，如果我们使用了batch-normalization方法，前面层的变化对后面层的影响就降低了，因为被平均了，所以BN会使得系统优化的结果更好 同时，这还起到了一点点正则化的作用，因为每个mini-batch在计算的时候都被平均了，所以整个网络对于数据的适应性就没有那么强了 对测试数据的batch norm在训练阶段，我们每次可以用一次批量的值计算均值和方差，但是在测试阶段，我们每次输入的只有一个值，这时候我们进行batch norm的均值和方差从哪里来呢？ 解决办法就是，记录下训练数据的均值和方差，然后对各个mini-batch norm的均值和方差做指数权重平均，在测试阶段使用 多分类softmax Regression我们之前接触的问题都是二分类，当我们要进行多分类的时候，就要用到一个特殊的激活函数，叫做softmax 假设我们要分类的类别数C=4，标签为0,1,2,3，那么在最后一层，我们要输出一个4*1的输出层，每一个输出点代表分到该类的概率 举个例子，我们得到了最后一层的输入为z[L] = [5,2,-1,3]，我们用指数函数对其变换，$t = [e^5,e^2,e^{-1},e^3]$，计算比例得到$a^{[L]}$，如下图所示 对softmax的理解softmax是一个$\frac{e^{z_j}}{\sum_ke^{z_k}}$形式的激活函数，当分类的类别C=2的时候，softmax就是logistics函数 softmax的loss一般取为：$L(\hat{y},y)=-\sum_{j=1}^Cy_j\log \hat{y}_j$ 真实的y和$\hat y$的形式如下： 真实值只有真的那个地方为1，别的地方为0，$\hat y$是C个概率，代表分到每一类的概率 因为y一般有很多个需要分类的样本，所以真实的y和$\hat y$如下，其中的4是此时分为4类 反向传播中，softmax的导数的求法稍微复杂一点，过程如下： 首先求$\partial J/\partial a$，虽然这里有个累加，但是其实只有真实的那类$y_j=1$，别的都是0，所以求和号可以去掉，变成$J=y_j\log \hat{y}_j$，对$\hat y$求偏导可以得到，$\partial J/\partial a=-1/\hat{y}_j$ 接下来求softmax的导数，也就是$\hat{y}_j$对所有的$z_i$求导数，分为i=j和i!=j的情况来求 这样，$\partial J/\partial z$的值就可以通过链式法则得到 当i=j时，$\partial J/\partial z=a_j-1$ 当i!=j时，$\partial J/\partial z=-a_i$ 在使用深度学习框架的时候，比如TensorFlow和caffe，我们只需要规划好前向传播的过程，反向传播的过程框架会自动帮你完成 深度学习框架的介绍目前主流的深度学习框架和选择标准如下： TensorFlow简介引入TensorFlow，通过import tensorflow as tf w设置为tf当中的变量，用tf.Variable(initial_value=0,dtype=tf.float32)表示 x是输入值，一开始不知道是多少，只表示dtype和shape，用tf.placeholder(dtype=tf.float32,shape=[3,1])表示 表示cost函数，因为tf已经重载了加减乘除的形式，所以可以直接用加减乘除表示，也可以用tf.add之类的表示，矩阵乘法的表示是tf.matmul() 之后表示train的方法和目标：我们这里用梯度下降，最小化costtrain = tf.train.GradientDescentOptimizer(0.01).minimize(cost)，如果要用别的优化方法，只需要将GradientDescentOptimizer替换为别的函数就好了，括号里面的参数是learning-rate 然后初始化变量值，init = tf.global_variables_initializer() 定义一个session，用session来run一下init，再run一下w，看看w的值，最后迭代run(train) 也可以用如下形式定义session 123with tf.Session() as session: session.run(init) session.run(w) placeholder的值可以用feed_dict传入 1234sess = tf.Session()x = tf.placeholder(tf.int64, name = 'x')print(sess.run(2 * x, feed_dict = &#123;x: 3&#125;))sess.close() 写TensorFlow的代码过程大致如下： 建立未执行的tensor变量 写tensor之间的运算 初始化tensor 建立session 运行session，将会运行你简历里的运算 所有的运算都要run之后才能执行，如果你直接print运算的话，只会得到一个tensor，也就是计算图 因此，请注意初始化变量，建立session并run operation 损失计算计算形如： J = - \frac{1}{m} \sum_{i = 1}^m \large ( \small y^{(i)} \log a^{ [2] (i)} + (1-y^{(i)})\log (1-a^{ [2] (i)} )\large )\small这样的损失的时候，可以使用tf内置的tf.nn.sigmoid_cross_entropy_with_logits函数实现 one_hot encodingone_hot：只有一个值为1，别的值都为0的vector，用tf.one_hot实现，参数indices表示需要转换的向量, depth表示一共多少个类， on_value=None表示符合类的值为多少, off_value=None表示不符合类的值是多少, axis为0表示每个indices放一行，-1表示每个indices放一列 实现TensorFlow model的步骤 建立一个计算图 run这个计算图 初始化参数的方法W用Xavier初始化，b用zero初始化 12W1 = tf.get_variable("W1", [25,12288], initializer = tf.contrib.layers.xavier_initializer()）b1 = tf.get_variable("b1", [25,1], initializer = tf.zeros_initializer()) 反向传播的方法1234#For instance, for gradient descent the optimizer would be:optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate).minimize(cost)#To make the optimization you would do:_ , c = sess.run([optimizer, cost], feed_dict=&#123;X: minibatch_X, Y: minibatch_Y&#125;)]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>deeplearning</tag>
        <tag>机器学习</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[c++ primer 基础语法]]></title>
    <url>%2F2018%2F04%2F10%2Fc%2B%2B%20primer-%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[最近看了看c++基础语法，记录如下 感觉windows下面visual studio的代码提示不是很好用，还是用了熟悉的intelligJ的IDE——clion 安装clion之后安装MinGW，就可以开始编程了 基础语法标准输入输出流cin和cout用于输入输出，需要包含iostream头文件，并using namespace std; 可以用多个输入输出符号进行连续输出或者输入 cin连续输入的分隔符号是：空格、tab或换行符 格式是 12345#include &lt;iostream&gt;using namespace std;int main()&#123; cout &lt;&lt; a &lt;&lt; "字符串" &lt;&lt; b;&#125; 循环及条件语句while，for，if与c语言基本相同，没有什么说的 输入不定量的数据：while(cin &gt;&gt; value)，这样实现的原因是cin输入正常的时候，判定为true，没有值的时候判定为false 第二章：内置类型int和unsigned int如果unsigned int表示一个负数的话，应该是取其补码（因为负数在计算机中是以补码的形式存储的），按unsigned int来计算值（无符号位），当然有一个简单的办法，比如你是32位机器，那么-1的表示形式就是$2^{32}-1$，-32的表示形式就是$2^{32}-32$ int 类型的第一位是符号位，0表示正数，1表示负数 stringstring在c++中一个要用双引号：”” 单引号表示char： ‘’ 多个字符串如果紧邻且中间仅用空格、缩进和换行符分隔，那么他们就是一个字符串 12345int main(int argc, char *argv[])&#123; cout&lt;&lt; "my name is" "jeffrey"&lt;&lt; endl; return 0;&#125; 转义字符在反斜杠”\”后面紧跟着1个，2个或3个八进制字符 指定字面值的类型12345L'A' //宽字符型，wchar_tu8'hi!' //utf-8字符3.1315L //long double1E-3F //单精度浮点数，float E-3表示10的-3次方，小写的e效果一样42ULL //Unsigned long long 变量赋值方法c++有四种变量赋值方法： 1234int a = 0;int b = &#123;0&#125;;int c&#123;0&#125;;int d(0); 上面四个方法分别对应把abcd赋值为0，花括号的赋值方法叫做列表初始化，但是这种方法有个问题就是如果存在精度损失的情况下，编译器会报错。 123long double ld=3.1424234;int a&#123;ld&#125;, b&#123;ld&#125;; //报错，因为列表初始化不允许存在精度损失int a(ld), b(ld); //不报错，但存在精度损失 变量赋值不能使用连等号 12int a=b=0; //错误！！！int a=0, b=0; 作用域用两个冒号表示作用域，左边表示作用域，右边表示变量或函数名 比如常见的std::cout 全局作用域就是两个冒号，左边没有值， 1234a = 5int main(int argc, char *argv[])&#123; cout &lt;&lt; ::a;&#125; 引用和指针 引用引用必须要初始化（定义的时候必须赋值），赋值为另一个已经定义好的变量，这样两个变量就相当于是同一个变量，只是名字不同而已 指针空指针是指向某个对象，可以初始化为空指针nullptr或null或0 1int *p1=nullptr 指针必须指向相同类型的元素，void类型的指针可以指向任何元素 const限定符const用于定义一个无法改变的常数，在初始化的时候必须要赋值 声明变量用extern，如果想定义一个大家都能用的const值，那么在定义的时候必须同时用到external和const关键字 123extern const int butSize = 512;//在别的文件中用到这个值只需要声明一下extern const int butSize; const指针常量指针因为值不能变，所以必须初始化 12const int number=0;const int *const num = &amp;number; 顶层const：指针本身是一个常量，如int *const p = a; 底层const：指针所指向的是一个常量，如const int a =1;const int *p=a; 类型别名使用关键字typedef进行别名定义： 1typedef double wages; //定义weges是double的别名 或者别名声明进行定义using： 1using wagees = double; auto类型说明符auto可以自动识别数值类型，但是定义的时候必须初始化： 1auto item = value1 + value2; decl类型指示符decl类型指示符是用于得到某个对象或变量的类型，来定义别的变量 12const int i =0;decltype(ci) x=0; 标准库类型string用string之前要声明，using std::string 初始化方法有直接初始化和拷贝初始化两种，不使用等号的就是直接初始化 12345using std::stringstring s1;string s2 = s1;string s3 = "hiya"; //拷贝初始化string s4(10,'c'); //直接初始化 string的输入是以第一个不为空白的地方开始，到下一个空白符的地方结束 判断string为空：string.empty()，为空返回true，否则返回false 读入一行：getline(string, line)函数，从string读入，读入之后放在line中 返回string长度：string.size() string比较: ==或者是!=，两个字符串如果a是b的子串，那么b&gt;a，如果ab有很多不同，那么他们的大小是按照第一个不相同的字符的比较来的 c++的string也可以直接相加，但是区别是不能把两个都用双引号扩起来的字面值相加，相加的至少有一个是string类型： 1234string s1 = "hello";string s2 = "world";string s3 = s1 + ", " + s2; //正确，因为s1和s2都是string类型string s3 = "hello" + ", " //错误，两个字面值不能直接相加 字符串处理函数包含在cctype头文件中 isalnum():是字母或数字时为真 isalpha()：是字母为真 iscntrl()：是控制字符为真 isdigit()：是数字为真 issupper()：大写字母为真 ispunct():是符号位真 isprint()：可打印时为真 isgraph()：不为空格且可打印时为真 tolower()，toupper()：大小写转换 对字符串进行迭代使用范围for对字符串迭代 12for (auto c : str) cout &lt;&lt; c &lt;&lt;endl; 使用范围for对字符串的值进行改变，每个c都定义为引用，改变c的时候就改变了原来的字符串 12for (auto &amp;c : str) c = topper(c) 使用下标访问字符串与python类似，c++也可以用下标访问string，开头为str[0]，结尾为str[str.size()-1]，要注意，str.size()的返回类型并不是int，而是string::size_type，因此定义index的时候要用到decltype() 12345string word = "hello world";for (decltype(word.size()) index=0; (index != word.size()) &amp;&amp; (!isspace(word[index])); ++index) &#123; word[index] = toupper(word[index]);&#125;cout &lt;&lt; word &lt;&lt; endl; 容器vector要想使用vector就要包含vector头文件#include &lt;vector&gt; vector有点像python里面的list，什么都可以放进去，vector基本可以容纳所有对象，但是引用不是对象，所以vector无法存放引用 初始化vector只需要vector&lt;type&gt; i就可以了，大体来说有以下几种初始化方法 vector&lt;T&gt; V1:空vector，用于存放T vector&lt;t&gt; v2(v1)：将v1赋值给v2 vecto&lt;T&gt; v3(n,val)：v3包含n个val vector&lt;T&gt; v4(n)：包含n个重复执行值初始化的对象 vector&lt;T&gt; v5{a,b,c...}： v5包含初始值个数的元素，每个元素在初始化阶段被赋值 vector&lt;T&gt; v5={a,b,c...} ：等价于v5 注意：用圆括号的时候是用来构建vector的元素个数的，用花括号是用来表示初始值的 12vector&lt;int&gt; v1&#123;10&#125;; //只有一个值为10vector&lt;int&gt; v1(10); //有10个初值为0的值 向vector中添加元素使用push_back方法，类似于python list的append方法，每次放在最后 1234vector&lt;int&gt; a;for (int i = 0; i &lt; 100; ++i) &#123; a.push_back(i);&#125; 访问vector的方法和访问string基本一致，用方括号加索引，vector也有size, empty,等等函数，也可以直接比较 将输入的字符串大写并输出，注意toupper之后返回一个int类型，不能直接用to_string方法，那样会让结果是ascii码的字符串类型，就是一串数字 123456789101112131415int main(int argc, char *argv[])&#123; vector&lt;string&gt; a; string temp; string temp_string=""; while (cin &gt;&gt; temp)&#123; temp_string = ""; for (auto tempc : temp) temp_string += toupper(tempc); a.push_back(temp_string); &#125; for (auto i : a)&#123; cout &lt;&lt; i &lt;&lt;endl; &#125;&#125; 迭代器迭代器有begin和end两种方法，分别指向第一个元素和最后一个元素的下一个元素，特殊地，空容器返回的begin和end是同一个迭代器 迭代器使用==或!=进行比较，用++向前移动一个位置，+n则移动n个位置，减法亦然，大小于符号用来比较同一个vector对象的两个迭代器，注意：两个迭代器可以做减法，但是不能做加法，加法只能加常数 比如迭代器访问一个string： 12345string a = "hello world";for (auto i = a.begin(); i != a.end() ; i++) &#123; *i = toupper(*i); cout &lt;&lt; *i;&#125; c++在for当中的判断都是用的!=，这可以使得在用迭代器和普通的for时候的形式一样，因此用不等于符号 迭代器类型包含普通迭代器和常量迭代器，普通迭代器可以读写，常量迭代器只能读 123vector&lt;int&gt;::iterator it; //it能读写vector&lt;int&gt;元素string::iterator it2; //it2能读写string元素vector&lt;int&gt;::const_iterator it3; //it3只能读vector&lt;int&gt;元素 c++11中引入两个新函数，cbegin和cend，是为了直接获得const_iterator的 迭代器解引用原始的解引用的方法是(*it).function()，c++引入了一种新的解引用的方法，用箭头运算符it-&gt;function() 数组字符串数组初始化的时候，会在后面加一个’\0’结束符，但用{}的形式初始化的时候不会加 123char a1[] = &#123;'a','b','c'&#125;; //没有加'\0'char a2[] = &#123;'a','b','c','\0'&#125;; //手动加'\0'char a3[] = "abc"; //自动加'\0' 有指针的数组，没有引用的数组，但是有数组的引用和数组的指针 123int *p[10]; //含有10个整型指针的数组int (*p)[10] = &amp;arr; //p指向含有10个整数的数组int (&amp;p)[10] = arr;//p引用一个含有10个整数的数组 数组也通过下标访问 指针和数组书组合指针联系紧密，对数组取地址则得到该元素的指针 123string num[] = &#123;"one","two","three"&#125;;string *p = &amp;num[0];string *p2 = num; //等价于前一句 指针也可以像数组一样进行加减整数的运算 注意指针的数组和数组的指针的区别 12int *ip[4]; //整型指针的数组int (*ip)[4]; //指向含有4个整数的数组 c风格的字符串c风格的字符串定义方式是char *str = &quot;abcd&quot;，如果要用string赋值给c类型的字符串，用.c_str()函数 12string s = "abcd";char *str = s.c_str(); 用数组初始化vector定义一个数组，用begin和end函数对vector进行初始化 12int int_arr[] = &#123;0,1,2,3&#125;;vector&lt;int&gt; ivec(begin(int_arr),end(int_arr)); 多维数组严格来说c++当中没有多维数组，所谓的多维数组就是数组的数组 用范围for遍历多维数组第一层循环要用引用，第二层循环直接auto，因为第一层循环如果不用引用的话，第一层就被自动转换成了指针，第二层再遍历就不合法了 12for (auto &amp;row : ia) for (auto &amp;col : row) 运算符大多数运算符和c当中的顺序没有明显差异，只记录一些比较生疏的运算符 ?: 运算符，用于选择运算，条件运算符的优先级非常低，如果在输出语句中包含，就不会执行 1234final_grade = (grade &gt; 90) ? "high grade" : (grade &lt; 60) ? "fail" : "pass";cout &lt;&lt; ( (grade &lt; 60) ? "fail" : "pass"); //输出fail或passcout &lt;&lt; (grade &lt; 60) ? "fail" : "pass"; //输出1或0，即(grade&lt;60)的结果cout &lt;&lt; grade &lt; 60 ? "fail" : "pass"; //错误，因为想当与cout&lt;&lt;grade;cout &lt; 60 位运算符 位运算符 ~：位求反 &lt;&lt;：左移 &gt;&gt; ：右移 &amp;：位与 ^：位异或 \ ：位或 逗号运算符逗号运算符通常放在for循环中，用以同时执行两个内容 1for(vector&lt;int&gt;::size_type ix=0; ix!=ivec.size(); ++ix,--cnt) 显示类型转换static_cast,dynamic_cast, const_cast, reinterpret_cast其中一种 任何明确定义的类型转换，只要不是底层const都可以用static_cast 1double slope = static_cast&lt;double&gt;(j) / i ;强制类型转换以便执行浮点数除法 dynamic_cast用于转换底层cosnt，将常量转换为非常量 12const char *pc;char *p = const_cast&lt;char*&gt;(pc) reinterpret_cast用于对象底层的转换，比如char和int的转换 12int *ip;char *pc = reinterpret_cast&lt;char*&gt;(ip); 语句大多数语句在c语言中已经学过，这里不多赘述，只详细讨论部分不熟悉的语句 if else语句用于条件判断 switch case语句也主要用于条件判断，记住switch语句要有break，不然就按顺序执行（不论条件是否满足都会往下执行），比如： 12345678910switch(ch)&#123; case 'a': ++acnt; case 'e': ++ecnt; case 'i': ++icnt; case 'o': ++ocnt;&#125; 如果输入的ch为e，此时++ecnt之后，没有break，接下来的++icnt和++ocnt都会被执行 没有可以匹配的时候，就匹配default标签 while和for语句用于循环，for比较特殊的就是范围for do while语句是先执行，后判断 跳转语句c++有四种跳转语句：break，continue，goto，return break用于跳出最近的循环 continue用于循环中的当前迭代，并立即开始下一次迭代 go to是直接跳到某一句，尽量不要用go to try语句和异常处理异常处理包括throw抛出异常和try catch处理异常 throw直接throw 后面加上异常的内容 123if (item1.isbn() != item2.isbn())&#123; throw runtime_error("data should refer to same ISBN");&#125; try catch语句用try尝试，多个catch抓住不同类型的错误，错误类型可以搜索c++标准异常 12345678while (cin &gt;&gt; item1 &gt;&gt; item2)&#123; try&#123; // 执行的语句 &#125; catch (runtime_error err)&#123; cout&lt;&lt; err.what() &lt;&lt;endl; &#125;&#125; 函数这里只介绍不熟悉的函数重载 同一个作用域内几个函数，名字相同但形参不同，称为重载，编译器通过参数类型确定你调用的是哪个函数 类定义头文件的时候，用ifdef或者ifndef确保变量没有定义，然后用#define定义头文件变量变量名_H， 形式如下 12345678#ifndef SALE_DATA_H#define SALE_DATA_H#include &lt;string.h&gt;struct Sales_data&#123; std::string bookNo; unsigned units_sold=0; double revenue=0.0;&#125; 定义类当中的函数的时候，有时候会用到常量函数，就是在函数的名字后面添加一个const关键字，常量函数： 如果尝试去改变这个类的成员变量，就会产生一个编译器错误；然而，在这个函数中读取一个类变量是允许的，但是不允许写一个类变量 还有一种理解就是对普通函数加一个this指针，而常量函数的this指针就是const *this， 比如定义一个int Foo::Bar(int random_arg)就等同于定义一个int Foo::Bar(Foo *this, int random_arg)，使用这个函数Foo f;f.Bar(4)就等同于Foo f;f.Bar(&amp;f, 4)，加了const在函数后面的话int Foo::Bar(int random_arg) const， 那么就可以理解为int Foo::Bar(const Foo *this, int random_arg) const ，在这种常量this指针的情况下，是不允许修改类成员变量的 在这一章节中，函数常常返回的是引用，注意：不能返回局部的引用变量，如果要返回引用，那么你的函数参数里面至少有一个引用类型 构造函数构造函数用于类的初始化，在没有定义构造函数的时候，有一个默认的default构造函数，当你定义了新的构造函数的时候，默认的构造函数失效 类名(参数类型1 参数名1,参数类型2, 参数2): 成员1(参数名1), 成员2(参数名2){}， 构造函数的通用形式 12345678struct Sale_data&#123; Sale_data() = default; //默认构造函数 Sale_data(const string &amp;s):bookNo(s)&#123;&#125;; // Sale_data(const string &amp;s, unsigned n, double p):bookNo(s),units_sold(n),revenue(p*n)&#123;&#125; Sale_data(istream &amp;is)&#123; read(is, *this) &#125;&#125; 这里string以引用方式传递，是因为在c++中，string是被视为指针的 class和struct的区别：当你希望所有成员都是public的时候用struct，只要有想要变成private的成员的情况下，都用class 友元允许其他类或函数，访问类的非公有成员 12345678910111213141516171819int main(int argc, char *argv[])&#123; class Sale_data&#123; friend Sale_data add(const int&amp;); public: Sale_data add(const Sale_data &amp;lhs, const Sale_data &amp;rhs)&#123; Sale_data sum = lhs; sum.combine(rhs); return sum; &#125;; private: string bookNo; unsigned unints_sold=0; double revenue=0.0; &#125;;&#125; 类里面分public和private变量，public变量可以在类外访问，private变量不允许显式地访问，除非是想要进行访问的类是该类的友元，friend]]></content>
      <categories>
        <category>编程学习</category>
      </categories>
      <tags>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Coursera deeplearning.ai (一)]]></title>
    <url>%2F2018%2F03%2F15%2FCoursera-deeplearning-ai-%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Coursera上面关于deeplearning.ai的课程一共有五门，在申请助学金之后都可以免费参与，这篇博文主要讲的是关于deeplearning.ai的第一门课程的 在房价预测中，最普通的如右上角转弯的函数，称之为ReLU(rectified linear unit)函数，给定一个大小，通过一个神经元就可以得到房子的价格，这就是一个神经元。 如果你对房价预测还有别的因素，比如卧室的数量，地理位置，学区信息等等来对房价进行预测，你只需要给定大量的x的输入数据，就可以用来预测房价y的值，这样就得到了一个较大的神经元 最左边的一层是输入层，中间一层是隐藏层，最后是输出层 Week 2首先介绍一下logistics二分类：经典的二分类算法 首先来看看图像分类的问题，输入一张图片，我们标记1作为猫，标记0作为不是猫 图片在电脑中保存为红绿蓝三个色彩强度矩阵，如果是一幅$64\times64$的图片，就有3个$64\times64$的色彩矩阵，为了进行分类，将这些矩阵中的像素值展开为一个向量x作为算法的输入 输入x的定义为：红黄蓝三张矩阵的像素值按顺序放进去，x在$64\times64$的图片的情况下就是，$64\times64\times3=(12288,1)$的矩阵，有m个训练数据，则有m个x向量，m个y 如图，每个训练数据占一列，m个训练数据，一共是$mn$行，Y是标签，m个标签为1m logistics 回归给定x，预测y，y只能是0和1，也就是二分类问题 有两个参数，w和b，w也是（n，1）的向量，$\hat{y} = w^Tx+b$，这样的表示并不好，因为y可能是一个小数或者甚至是负数，我们想要结果是0或1，因此我们对结果用sigmoid函数，如下： $\hat{y} = \sigma(w^Tx+b)$ sigmoid函数的定义为：$f(z)=\frac{1}{1+e^{-z}}$ Logistic Regression Cost Function为了优化logistic回归的w和b，我们定义一个损失函数， 损失函数（loss function）：定义一个估计量$\hat{y}$和一个真实值$y$之间的误差，我们在这里用到的是平方损失函数，$L(\hat{y},y)=\frac{1}{2}(\hat{y}-y)^2$ 另一种适用的损失函数定义为：$L(\hat{y},y)=- (y\log\hat{y}+(1-y)\log({1-\hat{y}}))$ 这个函数在y=1的时候，$L(\hat{y},y)=- \log\hat{y}$，要让损失函数尽可能小，那么$\hat{y}$就要尽可能大（因为前面有负号，log是增函数），由于$\hat{y}$是sigmoid函数，最大为1 这个函数在y=0的时候，$L(\hat{y},y)=- \log({1-\hat{y}})$，要让损失函数尽可能小，那么$\hat{y}$就要尽可能小（因为前面有负号，log是增函数），由于$\hat{y}$是sigmoid函数，最小为0 代价函数（cost function）：定义整个训练集的平均损失：$J(\hat{y},y)=\frac{1}{m}\sum_{i=1}^{n}L(\hat{y}^{(i)},y^{(i)})$ 梯度下降已经知道了逻辑回归算法的参数w和b，以及代价函数$J(\hat{y},y)$，我们需要一个方法来训练我们的模型，那就是梯度下降。 目标是使代价函数$J(\hat{y},y)$最小，也就是下面这个公式最小： $J(w,b) = \frac{1}{m}\sum_{i=1}^mL(\hat{y}^{(i)},y^{(i)})=\frac{1}{m}y^{(i)}\log\hat{y}^{(i)}+(1-y^{(i)})\log(1-\hat{y}^{(i)})$ 这是一个凸优化问题，有且仅有一个最优值，在初始化w和b的时候，可以令初始w=1，b=0，也可以随机初始化。 每次迭代找到下一个点的方法是通过找到斜率的方向，因为斜率的方向是下降最快的 直到找到全局最优值，w和b每次迭代更新的公式如下： $w:=w-\alpha\frac{\partial{J(w,b)}}{\partial{w}}$ $b:=b-\alpha\frac{\partial{J(w,b)}}{\partial{b}}$ 计算图 如图是一个计算图，$J(a,b,c)=3(a+bc)$，令bc=u，bc=v，3v=j，这样就是如上图一步一步的计算 在代码中，我们要表示dJ/da的时候，只需要写da就行了 所谓的反向传播，就是通过链式法则求导倒数的过程 logistic回归梯度下降法应用 一直z，$\hat{y}$，以及L(a,y)公式如上，要通过调节w和b得到最大或者最小的L，应该用L对w和b求偏导，然后运用 $w:=w-\alpha dw$ b:=b-\alpha db这两个公式进行迭代，其中dw就是L对w的偏导，db就L对b的偏导 首先L对a求偏导，得到$da=-\frac{y}{a}+\frac{1-y}{1-a}$，接下来a对z求偏导，乘以L对a求偏导，得到$dz=\frac{dL}{dz}=\frac{dL}{da}\frac{da}{dz}$，有 $\frac{da}{dz}=(\frac{1}{1+e^{-z}})’=\frac{e^{-z}}{(1+e^{-z})^2}=\frac{1+e^{-z}-1}{(1+e^{-z})^2}=\frac{1}{1+e^{-z}}(1-\frac{1}{1+e^{-z}})=f(z)(1-f(z))=a(1-a)$ 因此，$dz=a-y$，$dw_1=x_1dz$，$dw_2=x_2dz$，$db=dz$，再用上图右下角的迭代公式，即可实现梯度下降迭代 m个训练数据的梯度下降代价函数$J(w,b)=\frac{1}{m}\sum_{i=1}^{n}L(a^{(i)},y^{(i)})$ 其中$a^{(i)}=\hat{y}^{(i)}=\sigma(w^Tx^{(i)}+b)$ 如图，有两层循环，第一层是循环m个训练数据，第二层是循环n个w 通过向量化减少逻辑回归的循环如下图，我们先减少内层的n个w的循环，通过$dw+=x^{(i)}dz^{(i)}$减少内层循环 我们再来减少外层的循环 通过图片中Z和A的计算，就可以减少外层的循环 Week 3神经网络的定义，我们可以从前两周学的逻辑回归来进入，给定x，w，b，可以算出z，由z可以算出a，由a算出损失函数， 这是一个两层神经网络（包括1个隐藏层和1个输出层，输入层并不算在其中） 神经网络的计算公式我们先看看逻辑回归的计算方法：没有隐藏层，直接通过输入就算出最终的输出a 神经网络与之类似，不过多了一层隐藏层， 通过如下的公式进行计算隐藏层的每一个点的值 整理一下四个点的计算公式如下：右上角的方括号表示所在层，右下角角标表示第几个点 我们将公式矢量化： 得到最终的计算公式如下：其中a[0]表示输入x 多个训练样本的矢量化要将如下图所示的循环进行矢量化：其中方括号表示所在层，圆括号表示第几个隐藏单元 矢量化之后得到如下公式：Z和A的横向表示m个样本 激活函数我们之前用的激活函数都是simoid函数，tanh函数一般来说比sigmoid函数的效果好 $a = tanh(z) = \frac{e^z-e^{-z}}{e^z+e^{-z}}$ tanh函数可以看做一个sigmoid函数的平移，图形如下： 但是tanh函数和sigmoid函数都有缺陷，那就是在a接近1的时候，斜率非常小，导致迭代速度特别慢，因此给出了RELU函数和leaker relu函数，是Restrict Linear Unit的缩写，一个是取0和z的最大值，一个取0.01z和z的最大值，这样能够保证迭代的速度 为什么需要非线性激活函数$z^{[1]} = W^{[1]}X+b^{[1]}$ $a^{[1]}=\sigma(z^{[1]})​$ $z^{[2]} = W^{[2]}X+b^{[2]}$ $a^{[2]}=\sigma(z^{[2]})$ 如果我们不使用非线性激活函数，比如直接让g(z) = z，那么$z^{[2]} = W^{[2]}a^{[1]}+b^{[2]}=W^{[2]}(W^{[1]}X+b^{[1]})+b^{[2]}=W^{[2]}W^{[1]}X+W^{[2]}b^{[1]}+b^{[2]} = W^{‘}X+b^{‘}$ 相当于经过多个隐藏层之后，结果还是输入的线性变化，那么隐藏层就没有意义了 只有一种情况使用线性激活函数，就是在做回归问题的最后一步的时候，输出值不是0和1而是一个实数，那么这个时候就应该使用线性激活函数，但是在中间的隐藏层仍然应该使用非线性激活函数。 激活函数的梯度下降 sigmoid函数： $a=g(z)=\frac{1}{1+e^{-z}}$，导数是$g^{‘}(z)=g(z)(1-g(z))=a(1-a)$，在z=一个很大的正数或者负数的时候，g（z）导数接近于0；z等于0的时候，g(z)的导数是1/4 tanh函数，$a=g(z)=\tanh(z)=\frac{e^z-e^{-z}}{e^z+e^{-z}}$，求导可得$g^{‘}(z)=1-g^{2}(z)$，我们可以通过一个简单的例子来检验有没有错误，当z很大或者很小的时候，$g^{‘}(z)=0$当，z=0的时候，导数=1 Relu函数，$g(z)=max(0,z)$，导数=0（当$z=0$的时候） Leaky ReLU：$g(z)=max(0.01z,z)$，导数=0.01（当$z=0$的时候） 神经网络的梯度下降左边是包含一个隐藏层的神经网络的推导公式，右边是反向传播求导的结果，其中np.sum函数中的keepdims=True这个参数是为了输出结果是(n,1)而不是(n,) 神经网络梯度下降的推导从后往前推导，先求dz2=a2-y，因为L(a2,y)=-yloga-(1-y)log(1-a)，对a求导，然后乘以sigmoid的导数刚好是a2-y，dw2=dz2a1T，这里的转置是通过维度来判断的，dw2一定和w2一样的维度，w2的维度是（n2,n1），那么dw2维度也是(n2,n1)，dz2的维度与z2相同是(n2,1)，那么应该右乘一个(1,n1)得到dw2，也就是a1T 左边是一个输入的时候的梯度下降，右边是向量化之后多个输入的梯度下降，因为代价函数J前面有1/m，所以dw前面也有1/m，keepdims=True是为了保证b2的形状是(n2,1) 随机初始化在逻辑回归中，w可以初始化为0，在神经网络中，我们必须要随机初始化w。这是为什么呢？主要是因为神经网络中存在隐藏层，如果一开始将w设置为全0，那么在反向传播的时候，通过$w = w-\alpha dw$这个公式进行迭代，每次迭代结束之后，两行的结果完全相同，这就是所谓的“对称”。这样多个隐藏点就跟1个隐藏点没有区别了 我们使用np.random.randn((1,2))随机初始化，并乘以一个很小的值，比如0.01，为什么不乘以一个很大的值比如100之类的呢，这是因为我们通常使用的激活函数，比如tanh和sigmoid函数，在值很大的时候斜率很小，迭代速度非常慢。 Week 4L层深度神经网络的符号表示其中L表示神经网络的层数，不包括输入层，仅包含隐藏层和输出层，$n^{[i]}$表示第i层的点的个数 深度神经网络的前向传播深度神经网络前向传播的通用公式： $Z^{[l]}=W^{l}A^{[l-1]}+b^{[l]}$ $A^{[l]}=g^{[l]}(Z^{[l]})$ 通过这个通用公式，我们就可以通过一个for循环，循环完所有的层 使矩阵维度保持正确检查神经网络代码的最好的办法，就是拿出一张纸，看看矩阵维度是否正确 检查两个参数W,b和每层输出a和Z的维度 $W^{[l]}=dW=(n^{[l]},n^{[l-1]})$ $a^{[l]}=z^{[l]}=(n^{[l]},1)$ $b^{[l]}=db=(n^{[l]},1)$ 矢量化之后的 $W^{[l]}=dW=(n^{[l]},n^{[l-1]})$ $A^{[l]}=Z^{[l]}=dA=dZ(n^{[l]},m)$ $b^{[l]}=db=(n^{[l]},1)$通过python的广播功能传播为$(n^{[l]},m)$ 深度神经网络的解释如下图，深度神经网络的第一层，可能能够检测一些图像的边缘，第二层可能由这些边缘组成了一些部件（比如人脸识别中的眼睛、鼻子、耳朵之类的），第三层再将这些眼睛鼻子耳朵之类的组合起来形成不同的脸，这就是神经网络的直观解释。 建立神经网络神经网络主要分为两个部分，前向传播和反向传播 前向传播：输入$a^{[l-1]}$，输出$a^{[l]}$ 反向传播中：输入$da^{[l]}$和$z^{[l]}$，输出$da^{[l-1]}$ 第L层的前向与反向传播示意如下： 整个深度神经网络的传播示意如下： 先正向传播，再反向传播，算出dw和db后用更新公式更新w和b，就完成了一次迭代 正反向传播第L层的正向传播 第L层的反向传播 前反向传播的总结 参数和超参数神经网络中的参数：W，b 超参数：影响到实际的参数W和b的参数，比如学习率$\alpha$，迭代次数，隐藏层的个数，隐藏神经单元数，激活函数的选择（tanh，sigmoid，RELU） 一般都是不断的尝试找到最优的超参值（启发式搜索），比如学习率$\alpha$要找到一个下降较快，且算是函数收敛到较低的值。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>deeplearning</tag>
        <tag>机器学习</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[由kaggle房价模型得到stacking model方法]]></title>
    <url>%2F2018%2F03%2F14%2F%E7%94%B1kaggle%E6%88%BF%E4%BB%B7%E6%A8%A1%E5%9E%8B%E5%BE%97%E5%88%B0stacking-model%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[房价模型在kaggle房价预测问题中已经介绍过，具体不再赘述。 大致内容为：根据给定的数据的80个变量来预测未知数据（同样包含80个变量）来预测房价 首先导入需要的包 123456789101112131415161718192021222324#import some necessary librairiesimport numpy as np # linear algebraimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)%matplotlib inlineimport matplotlib.pyplot as plt # Matlab-style plottingimport seaborn as snscolor = sns.color_palette()sns.set_style('darkgrid')import warningsdef ignore_warn(*args, **kwargs): passwarnings.warn = ignore_warn #ignore annoying warning (from sklearn and seaborn)from scipy import statsfrom scipy.stats import norm, skew #for some statisticspd.set_option('display.float_format', lambda x: '&#123;:.3f&#125;'.format(x)) #Limiting floats output to 3 decimal pointsfrom subprocess import check_outputprint(check_output(["ls", "../input"]).decode("utf8")) #check the files available in the directory 数据直观分析导入数据 1234#Now let's import and put the train and test datasets in pandas dataframetrain = pd.read_csv('../input/train.csv')test = pd.read_csv('../input/test.csv') 看看数据长什么样子： 12##display the first five rows of the train dataset.train.head(5) Id MSSubClass MSZoning LotFrontage LotArea Street Alley LotShape LandContour Utilities … PoolArea PoolQC Fence MiscFeature MiscVal MoSold YrSold SaleType SaleCondition SalePrice 0 1 60 RL 65.000 8450 Pave NaN Reg Lvl AllPub … 0 NaN NaN NaN 0 2 2008 WD Normal 208500 1 2 20 RL 80.000 9600 Pave NaN Reg Lvl AllPub … 0 NaN NaN NaN 0 5 2007 WD Normal 181500 2 3 60 RL 68.000 11250 Pave NaN IR1 Lvl AllPub … 0 NaN NaN NaN 0 9 2008 WD Normal 223500 3 4 70 RL 60.000 9550 Pave NaN IR1 Lvl AllPub … 0 NaN NaN NaN 0 2 2006 WD Abnorml 140000 4 5 60 RL 84.000 14260 Pave NaN IR1 Lvl AllPub … 0 NaN NaN NaN 0 12 2008 WD Normal 250000 一共是81列，最后一列是房价，第一列是id 我们再看看test数据长什么样： 12##display the first five rows of the test dataset.test.head(5) Id MSSubClass MSZoning LotFrontage LotArea Street Alley LotShape LandContour Utilities … ScreenPorch PoolArea PoolQC Fence MiscFeature MiscVal MoSold YrSold SaleType SaleCondition 0 1461 20 RH 80.000 11622 Pave NaN Reg Lvl AllPub … 120 0 NaN MnPrv NaN 0 6 2010 WD Normal 1 1462 20 RL 81.000 14267 Pave NaN IR1 Lvl AllPub … 0 0 NaN NaN Gar2 12500 6 2010 WD Normal 2 1463 60 RL 74.000 13830 Pave NaN IR1 Lvl AllPub … 0 0 NaN MnPrv NaN 0 3 2010 WD Normal 3 1464 60 RL 78.000 9978 Pave NaN IR1 Lvl AllPub … 0 0 NaN NaN NaN 0 6 2010 WD Normal 4 1465 120 RL 43.000 5005 Pave NaN IR1 HLS AllPub … 144 0 NaN NaN NaN 0 1 2010 WD Normal 一共是80列，第一列是id，房价未知 删除id信息 123456789101112131415#check the numbers of samples and featuresprint("The train data size before dropping Id feature is : &#123;&#125; ".format(train.shape))print("The test data size before dropping Id feature is : &#123;&#125; ".format(test.shape))#Save the 'Id' columntrain_ID = train['Id']test_ID = test['Id']#Now drop the 'Id' colum since it's unnecessary for the prediction process.train.drop("Id", axis = 1, inplace = True)test.drop("Id", axis = 1, inplace = True)#check again the data size after dropping the 'Id' variableprint("\nThe train data size after dropping Id feature is : &#123;&#125; ".format(train.shape)) print("The test data size after dropping Id feature is : &#123;&#125; ".format(test.shape)) 12345The train data size before dropping Id feature is : (1460, 81) The test data size before dropping Id feature is : (1459, 80) The train data size after dropping Id feature is : (1460, 80) The test data size after dropping Id feature is : (1459, 79) 数据预处理我们先来看看异常值，首先画一下GrLivArea和SalePrice的关系 123f, ax = plt.subplots()plt.scatter(x=train['GrLivArea'],y=train['SalePrice'])plt.show() 很明显看到另个异常值，我们先把这两个点删除 1train = train.drop(train[(train['GrLivArea'] &gt; 4000) &amp; (train['SalePrice'] &lt; 300000)].index) 目标变量房价是我们需要预测的变量，所以我们先分析一下这个变量 12345678910111213141516sns.distplot(train['SalePrice'] , fit=norm)# Get the fitted parameters used by the function(mu, sigma) = norm.fit(train['SalePrice'])print( '\n mu = &#123;:.2f&#125; and sigma = &#123;:.2f&#125;\n'.format(mu, sigma))#Now plot the distributionplt.legend(['Normal dist. ($\mu=$ &#123;:.2f&#125; and $\sigma=$ &#123;:.2f&#125; )'.format(mu, sigma)], loc='best')plt.ylabel('Frequency')plt.title('SalePrice distribution')#Get also the QQ-plotfig = plt.figure()res = stats.probplot(train['SalePrice'], plot=plt)plt.show() 房价正态对比图以及QQ图 目标变量右偏，线性模型比较喜欢正态分布的数据，因此我们需要转换变量使其正态分布 对数据进行log变换1234567891011train['SalePrice'] = np.log(train['SalePrice'])sns.distplot(train['SalePrice'],fit=norm)(mu,sigma) = norm.fit(train['SalePrice'])print('the $\mu$ = &#123;:.2f&#125; \n the $\sigma$ = &#123;:.2f&#125;'.format(mu,sigma))plt.legend(['Norm distribution( $\mu$ = &#123;:.2f&#125; , $\sigma$ = &#123;:.2f&#125;)'.format(mu,sigma)],loc='best')plt.ylabel('Frequency')plt.xlabel('SalePrice')plt.title('SalePrice distribution')fig = plt.figure()stats.probplot(train['SalePrice'],plot=plt)plt.show() 可以看到，变换之后更加接近正态分布 特征工程先把所有train和test数据连接在一起，并删掉售价这列 123456all_data = pd.concat([train,test],ignore_index=True)ntrain = train.shape[0]ntest = test.shape[0]y_train = train.SalePrice.valuesall_data.drop('SalePrice',1,inplace=True)print(all_data.shape) 缺失数据先把缺失数据找出来 1234all_data_na = (all_data.isnull().sum() / len(all_data)) *100all_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)[:30]missing_data = pd.DataFrame(&#123;'Missing Ratio':all_data_na&#125;)print(missing_data.head(20)) Missing Ratio PoolQC 99.691 MiscFeature 96.400 Alley 93.212 Fence 80.425 FireplaceQu 48.680 LotFrontage 16.661 GarageQual 5.451 GarageCond 5.451 GarageFinish 5.451 GarageYrBlt 5.451 GarageType 5.382 BsmtExposure 2.811 BsmtCond 2.811 BsmtQual 2.777 BsmtFinType2 2.743 BsmtFinType1 2.708 MasVnrType 0.823 MasVnrArea 0.788 MSZoning 0.137 BsmtFullBath 0.069 画一下缺失的比例： 1234sns.barplot(all_data_na.index,all_data_na.values)plt.xticks(rotation=90)plt.title('data missing percent')plt.show() 数据相关性分析123456corrmat = train.corr()plt.subplots(figsize=(12,9))sns.heatmap(corrmat,vmax=0.9,square=True)plt.xticks(rotation=90)plt.yticks(rotation=360)plt.show() 计算缺失值 PoolQC : 数据描述中提到 NA 表示 “No Pool”. MiscFeature : 数据描述中提到 NA 表示 “no misc feature” Alley : 数据描述中提到 NA 表示 “no alley access” Fence : 数据描述中提到 NA 表示”no fence” FireplaceQu : 数据描述中提到 NA 表示 “no fireplace” ‘GarageType’, ‘GarageFinish’, ‘GarageQual’, ‘GarageCond’,’BsmtQual’, ‘BsmtCond’,’BsmtExposure’, ‘BsmtFinType1’, ‘BsmtFinType2’,’MSSubClass’： 用’None’替代缺失值 123var = ['PoolQC','MiscFeature','Alley','Fence','FireplaceQu','GarageType', 'GarageFinish', 'GarageQual', 'GarageCond'，'MSSubClass']all_data[var] = all_data[var].fillna('None')print('为null的值',max(all_data[var].isnull().sum())) LotFrontage: 由于连接到房产的每条街道的面积很可能与其附近的其他房屋具有相似的面积，因此我们可以通过邻里的LotFrontage填充缺失值。 1all_data['LotFrontage'] = all_data.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median())) ‘GarageYrBlt’, ‘GarageArea’, ‘GarageCars’,’BsmtFinSF1’, ‘BsmtFinSF2’, ‘BsmtUnfSF’, ‘TotalBsmtSF’,’BsmtFullBath’, ‘BsmtHalfBath’,’MasVnrArea’, ‘MasVnrType’：用0代替缺失值 12var = ['GarageYrBlt', 'GarageArea', 'GarageCars','BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF','BsmtFullBath', 'BsmtHalfBath','MasVnrArea', 'MasVnrType']all_data[var] = all_data[var].fillna(0) ‘Electrical’,’MSZoning’,’KitchenQual’,’Exterior1st’,’Exterior2nd’,’SaleType’：用它的频繁模式来填充缺失值 123var = ['Electrical','MSZoning','KitchenQual','Exterior1st','Exterior2nd','SaleType']for v in var: all_data[v] = all_data[v].fillna(all_data[v].mode()[0]) Utilities : 这个变量在训练数据中，几乎所有值都是’AllPub’，除了两个NA和1个”NoSeWa”，所以我们可以删除这个变量。 1all_data.drop('Utilities',1,inplace=True) Functional : NA 表示 typical 1all_data["Functional"] = all_data["Functional"].fillna("Typ") 再检查一下有没有缺失值： 1print('缺失值个数:',max(all_data.isnull().sum())) 1缺失值个数:0 更多的特征工程将某些本来应该是类的数值变量变为类型变量 1234567891011#MSSubClass=The building classall_data['MSSubClass'] = all_data['MSSubClass'].apply(str)#Changing OverallCond into a categorical variableall_data['OverallCond'] = all_data['OverallCond'].astype(str)#Year and month sold are transformed into categorical features.all_data['YrSold'] = all_data['YrSold'].astype(str)all_data['MoSold'] = all_data['MoSold'].astype(str) 然后将数值变量变成值： 12345678columns = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', 'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', 'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope', 'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', 'YrSold', 'MoSold')for column in columns: lb_make = LabelEncoder() all_data[column] = lb_make.fit_transform(all_data[column].values) 加入一个额外的特征我们都知道房价和总面积息息相关，那么我们在加一个总面积的变量 12# Adding total sqfootage feature all_data['TotalSF'] = all_data['TotalBsmtSF'] + all_data['1stFlrSF'] + all_data['2ndFlrSF'] 计算数值特征的数据斜度1234567numeric_feats = all_data.dtypes[all_data.dtypes != "object"].index# Check the skew of all numerical featuresskewed_feats = all_data[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)print("\nSkew in numerical features: \n")skewness = pd.DataFrame(&#123;'Skew' :skewed_feats&#125;)skewness.head(10) 1Skew in numerical features: Skew MiscVal 21.940 PoolArea 17.689 LotArea 13.109 LowQualFinSF 12.085 3SsnPorch 11.372 LandSlope 4.973 KitchenAbvGr 4.301 BsmtFinSF2 4.145 EnclosedPorch 4.002 ScreenPorch 3.945 符合正态分布的变量斜度应该基本为0，离0越远表示越不符合正态分布 对高斜度变量进行box-cox变换box-cox变换的公式 12y = ((1+x)**lmbda - 1) / lmbda if lmbda != 0 log(1+x) if lmbda == 0 找出斜度大于0.75的值 12skewness = skewness[abs(skewness) &gt; 0.75]print("There are &#123;&#125; skewed numerical features to Box Cox transform".format(skewness.shape[0])) 进行box-cox变换 12345678# 进行box-cox变换skewness = skewness[abs(skewness)&gt;0.75]print('斜度大于0.75的有&#123;&#125;个'.format(skewness.shape[0]))print(len(skewed_feats))from scipy.special import boxcox1plam = 0.15for feat in skewed_feats.index: all_data[feat] = boxcox1p(all_data[feat],lam) 得到哑变量12all_data = pd.get_dummies(all_data)print(all_data.shape) 建立模型首先导入一系列会用到的包 12345678910from sklearn.linear_model import ElasticNet, Lasso, BayesianRidge, LassoLarsICfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressorfrom sklearn.kernel_ridge import KernelRidgefrom sklearn.pipeline import make_pipelinefrom sklearn.preprocessing import RobustScalerfrom sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clonefrom sklearn.model_selection import KFold, cross_val_score, train_test_splitfrom sklearn.metrics import mean_squared_errorimport xgboost as xgbimport lightgbm as lgb 使用sklearn里面的cross_val_score函数进行交叉验证 ，但是这个函数没有乱序的功能，所以加了一行乱序到这个交叉验证过程中。 123456# 交叉验证n_folds = 5def rmsle_cv(model): kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(train.values) rmse = np.sqrt(-cross_val_score(model, train.values, y_train, scoring='neg_mean_squared_error',cv=kf)) return rmse 交叉验证：用相同的数据进行学习和测试，这是机器学习中常见的一种错误，因为这样会过拟合。这样的测试效果是100%正确，但当模型用于新的数据时，得到的结果往往非常差。因此，常常将数据分为训练集和测试集合。在scikit-learn中，为了将数据随机切分，我们可以依靠train_test_split函数，导入iris数据集进行测试 123456789101112131415161718192021&gt;&gt;&gt; import numpy as np&gt;&gt;&gt; from sklearn.model_selection import train_test_split&gt;&gt;&gt; from sklearn import datasets&gt;&gt;&gt; from sklearn import svm&gt;&gt;&gt; iris = datasets.load_iris()&gt;&gt;&gt; iris.data.shape, iris.target.shape((150, 4), (150,))# 随机分40%的数据为测试集&gt;&gt;&gt; X_train, X_test, y_train, y_test = train_test_split(... iris.data, iris.target, test_size=0.4, random_state=0)&gt;&gt;&gt; X_train.shape, y_train.shape((90, 4), (90,))&gt;&gt;&gt; X_test.shape, y_test.shape((60, 4), (60,))&gt;&gt;&gt; clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)&gt;&gt;&gt; clf.score(X_test, y_test) 0.96... 在调整参数的时候，那些超参需要手动调节，比如SVM中的C，这样仍然存在过拟合的风险，因为你需要不断调整参数使估计量最优。为了解决这个问题，我们再保留一部分数据，称之为验证集。在训练集上训练，在验证集上调参，最终在测试集上进行测试。然而，这种办法将数据集分成了三部分：训练集，验证集和测试集，可以用于训练模型的数据就非常少了，并且结果很大程度上取决于三部分的划分方法。这个问题的解决办法就是交叉验证（CV），在交叉验证中，仍然需要测试集，但是不在需要验证集。交叉验证最基本的方法就是k-fold 交叉验证： 训练集被分为k个小的集合； 用k-1个folds的数据进行训练 余下的一个folds数据被用于验证模型 最终模型的性能就是k折交叉验证循环中的平均值。 计算交叉验证矩阵最简单的方法就是cross_val_score函数 12345&gt;&gt;&gt; from sklearn.model_selection import cross_val_score&gt;&gt;&gt; clf = svm.SVC(kernel='linear', C=1)&gt;&gt;&gt; scores = cross_val_score(clf, iris.data, iris.target, cv=5)&gt;&gt;&gt; scores array([ 0.96..., 1. ..., 0.96..., 0.96..., 1. ]) 平均的模型精度的95%置信区间就是： 12&gt;&gt;&gt; print("Accuracy: %0.2f (+/- %0.2f)" % (scores.mean(), scores.std() * 2))Accuracy: 0.98 (+/- 0.03) 可以通过传入不同的score方法来返回不同的结果 1234&gt;&gt;&gt; from sklearn import metrics&gt;&gt;&gt; scores = cross_val_score(clf, iris.data, iris.target, cv=5, scoring='f1_macro')&gt;&gt;&gt; scores array([ 0.96..., 1. ..., 0.96..., 0.96..., 1. ]) score的类型可以查看The scoring parameter: defining model evaluation rules我们也可以传入打乱的cv 123456&gt;&gt;&gt; from sklearn.model_selection import ShuffleSplit&gt;&gt;&gt; n_samples = iris.data.shape[0]&gt;&gt;&gt; cv = ShuffleSplit(n_splits=3, test_size=0.3, random_state=0)&gt;&gt;&gt; cross_val_score(clf, iris.data, iris.target, cv=cv)... array([ 0.97..., 0.97..., 1. ]) 基本模型的构建这里采用了五个基本模型：LASSO Regression （拉索回归），Elastic Net Regression （弹性网络回归），Kernel Ridge Regression （内核岭回归），XGBoost，LightGBM 12345678910111213141516171819202122232425262728293031323334# 基本模型# LASSO Regression :拉索回归，用RobustScaler做中间键增强模型稳定性lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))#Elastic Net Regression :弹性网络回归，用RobustScaler做中间键增强模型稳定性ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))# Kernel Ridge Regression :内核岭回归，以huber作为损失函数提高稳定性KRR = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05, max_depth=4, max_features='sqrt', min_samples_leaf=15, min_samples_split=10, loss='huber', random_state =5)#Gradient Boosting Regression : :GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05, max_depth=4, max_features='sqrt', min_samples_leaf=15, min_samples_split=10, loss='huber', random_state =5)#XGBoost :model_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, learning_rate=0.05, max_depth=3, min_child_weight=1.7817, n_estimators=2200, reg_alpha=0.4640, reg_lambda=0.8571, subsample=0.5213, silent=1, random_state =7, nthread = -1)#LightGBM :model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5, learning_rate=0.05, n_estimators=720, max_bin = 55, bagging_fraction = 0.8, bagging_freq = 5, feature_fraction = 0.2319, feature_fraction_seed=9, bagging_seed=9, min_data_in_leaf =6, min_sum_hessian_in_leaf = 11) 看看每个模型单独的效果： 123456789101112score = rmsle_cv(lasso)print("\nLasso score: &#123;:.4f&#125; (&#123;:.4f&#125;)\n".format(score.mean(), score.std()))score = rmsle_cv(ENet)print("ElasticNet score: &#123;:.4f&#125; (&#123;:.4f&#125;)\n".format(score.mean(), score.std()))score = rmsle_cv(KRR)print("Kernel Ridge score: &#123;:.4f&#125; (&#123;:.4f&#125;)\n".format(score.mean(), score.std()))score = rmsle_cv(GBoost)print("Gradient Boosting score: &#123;:.4f&#125; (&#123;:.4f&#125;)\n".format(score.mean(), score.std()))score = rmsle_cv(model_xgb)print("Xgboost score: &#123;:.4f&#125; (&#123;:.4f&#125;)\n".format(score.mean(), score.std()))score = rmsle_cv(model_lgb)print("LGBM score: &#123;:.4f&#125; (&#123;:.4f&#125;)\n" .format(score.mean(), score.std())) 结果如下 1234567891011Lasso score: 0.1115 (0.0074)ElasticNet score: 0.1116 (0.0074)Kernel Ridge score: 0.1176 (0.0081)Gradient Boosting score: 0.1176 (0.0081)Xgboost score: 0.1151 (0.0069)LGBM score: 0.1162 (0.0071) 模型堆叠最简单的堆叠方法： 平均基础模型我们写个新的类用于模型堆叠，顺便对代码进行重构 写自己的估计函数的方法： 首先决定你想要建立的方法，可能是四种之一：Classifier, Clusterring, Regressor and Transformer，Classifier是用于分类，Clusterring用于聚类，Regressor 用于回归预测，transform用于数据变换（输入一个数据x，返回数据的变化，比如PCA）； 选好之后，需要去继承BaseEstimator ，并选择合适的类型继承（ ClassifierMixin, RegressorMixin, ClusterMixin, TransformerMixin）； 然后重写，__init__方法，fit方法（返回self，即为模型的训练方法），以及predict和score方法 12345678910111213class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin): def __init__(self, models): self.models = models def fit(self,X,y): self.models_ = [clone(x) for x in self.models] for model in self.models_: model.fit(X,y) return self def predict(self,X): predictions = np.column_stack([model.predict(X) for model in self.models_]) return np.mean(predictions, axis=1) 最后看看得到的结果： 123averaged_models = AveragingModels(models = (ENet, GBoost, KRR, lasso))score = rmsle_cv(averaged_models)print(score.mean(),score.std()) 10.109500230379（0.00763453599777） 复杂的融合方法：加入一个元模型训练过程如下图： 将数据分成两部分，训练和保留部分 用训练数据训练多个基础模型 用保留部分的数据，测试基础模型 用第三步中得到的对保留部分数据的预测作为输入，加上正确的目标变量作为输出，去训练一个更高水平的模型，称为元模型 在上图中，A,B就是训练数据集，被分成了训练A和保留B，两部分。基础模型是算法0,1,2，元模型是算法3，B1是新的特征用于训练元模型3，C1是最终需要预测的元特征。 Stacking averaged Models Class123456789101112131415161718192021222324252627282930313233343536class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin): def __init__(self, base_models, meta_model, n_folds=5): self.base_models = base_models self.meta_model = meta_model self.n_folds = n_folds # We again fit the data on clones of the original models def fit(self, X, y): self.base_models_ = [[]] * len(self.base_models) self.meta_model_ = clone(self.meta_model) kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156) out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models))) for i, model in enumerate(self.base_models): for train_index, holdout_index in kfold.split(X, y): #base_models_长度为模型的个数 #五折交叉之后，每种模型得到了五个可用的模型，都保存在base_models_[i]中 instance = clone(model) self.base_models_[i].append(instance) instance.fit(X[train_index], y[train_index]) y_pred = instance.predict(X[holdout_index]) out_of_fold_predictions[holdout_index, i] = y_pred # 用的到的[原始数据行数*模型个数]的特征训练新的回归算法 self.meta_model_.fit(out_of_fold_predictions, y) return self # Do the predictions of all base models on the test data and use the averaged predictions as # meta-features for the final prediction which is done by the meta-model def predict(self, X): # 每个模型预测X的结果作为特征输入，用心的预测算法预测出最终结果 meta_features = np.column_stack([np.column_stack([model.predict(X) for model in base_models]).mean(axis=1) for base_models in self.base_models_]) return self.meta_model_.predict(meta_features)stacked_averaged_models = StackingAveragedModels(base_models = (ENet, GBoost,KRR,GBoost,model_xgb,model_lgb),meta_model = lasso)score = rmsle_cv(stacked_averaged_models)print("Stacking Averaged models score: &#123;:.4f&#125; (&#123;:.4f&#125;)".format(score.mean(), score.std())) 最终成绩]]></content>
      <categories>
        <category>数据分析</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>kaggle</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python数据分析过程--kaggle房价预测]]></title>
    <url>%2F2018%2F03%2F11%2Fpython%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E8%BF%87%E7%A8%8B-kaggle%E6%88%BF%E4%BB%B7%E9%A2%84%E6%B5%8B%2F</url>
    <content type="text"><![CDATA[具体来说可以分为五个部分: 问题理解 单变量分析 多变量分析 基本的数据清理 假设测验 首先导入过程中需要用到的python库12345678910import pandas as pdimport matplotlib.pyplot as pltimport seaborn as snsimport numpy as npfrom scipy.stats import normfrom sklearn.preprocessing import StandardScalerfrom scipy import statsimport warningswarnings.filterwarnings('ignore')%matplotlib inline 接下来读入数据:1df_train = pd.read_csv('../input/train.csv') 看一下每列都是些什么值1df_train.columns 得到如下的结果123456789101112131415161718Index(['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual', 'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual', 'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC', 'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType', 'SaleCondition', 'SalePrice'], dtype='object') 接下来我们需要做些什么为了理解数据，我推荐用excel做一个如下的表格，每一列数据变成一类，包含6部分内容： 变量名； 变量类型：有两种可能的值在这个域中，“数值型”或者是“分类型”，数值型意味着数据都是数值，而“分类型”意味着变量值是类别； 变量分割：根据大类对变量分段。比如在房价问题中，可以大致分为3大类：“建筑本身”，“空间大小”，“位置”，当我们说建筑本身的时候，我们意味着建筑的物理特征；说空间大小的时候，指的是空间特征，比如有几个卫生间之类的；说位置的时候，指的是地理位置相关的特征，比如街区之类的； 期望：我们自认为的哪些因素对最终分析目标的影响，可以分为高中低三类。 结论：我们认为这个变量重要性的结论，可以跟期望一样分为几类 补充评论：任何我们能想到的一般性评论 最后，我们结合自身实际，看看哪些因素是真的重要的，比如买房子的时候，房子外观重要吗？再看看哪些因素可能重复了，地势等高线之后就不需要地势斜度了 在房价预测这个问题中，我们总结了四个最重要的影响因素： OverallQual ：整体质量，虽然不知道怎么算出来的，但是很有可能是通过其余所有变量综合计算得到的； YearBuilt：建筑年份 TotalBsmtSF：总地下室面积 GrLivArea：总的非地下室面积 在这个问题中，我们最终是以2个“建筑本身”变量（整体质量和建筑年份），和2个“空间大小”变量（地下室面积和非地下室面积）结束。 先说最重要的：分析房价房价是我们这个问题探索的目标，首先看看数据描述12#获得数据的整体性描述df_train['SalePrice'].describe() 123456789count 1460.000000mean 180921.195890std 79442.502883min 34900.00000025% 129975.00000050% 163000.00000075% 214000.000000max 755000.000000Name: SalePrice, dtype: float64 非常好，至少最低的房价是大于0的12#画个直方图来看看数据分布sns.distplot(df_train['SalePrice']); 看上去似乎是一个变形的正态分布图片，我们来计算机下他的偏度和峰度： 123#skewness and kurtosisprint("Skewness: %f" % df_train['SalePrice'].skew())print("Kurtosis: %f" % df_train['SalePrice'].kurt()) 得到结果如下 12Skewness: 1.882876Kurtosis: 6.536282 其中峰度和偏度的解释如下： 峰度（skewness）：峰度衡量数据分布的平坦度（flatness）。尾部大的数据分布，其峰度值较大。正态分布的峰度值为3如图，黑线的峰度值大于3，红线峰度值等于3 偏态（Skewness）：偏态量度对称性。0说明是最完美的对称性，正态分布的偏态就是0。如图所示，右偏态为正，表明平均值大于中位数。反之为左偏态，为负。 数值类型因素之间的关系先来画一画grlivarea/saleprice两者之间的散点图 1234#scatter plot grlivarea/salepricevar = 'GrLivArea'data = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)data.plot.scatter(x=var, y='SalePrice', ylim=(0,800000)); 可以看到两者几乎呈现正相关，也就是非地下室面积和售价呈现正相关 我们再来画一下totalbsmtsf和售价的关系 1234#scatter plot totalbsmtsf/salepricevar = &apos;TotalBsmtSF&apos;data = pd.concat([df_train[&apos;SalePrice&apos;], df_train[var]], axis=1)data.plot.scatter(x=var, y=&apos;SalePrice&apos;, ylim=(0,800000)); 可以看到两者同样几乎呈现正相关，关系似乎是指数关系 分类类型变量的关系画一个box图（箱形图），看看整体质量和售价之间的关系 1234var = 'OverallQual'data = pd.concat([train['SalePrice'], train[var]], axis=1)sns.boxplot(x=var,y='SalePrice',data=data)plt.show() 箱形图的解释：又称为盒须图、盒式图、盒状图或箱线图，是一种用作显示一组数据分散情况资料的统计图。因型状如箱子而得名。在各种领域也经常被使用，常见于品质管理。不过作法相对较繁琐。它能显示出一组数据的最大值、最小值、中位数、及上下四分位数。 上四分位数Q3-下四分位数Q1 = 四分位间距$\Delta{Q}$ 在区间$Q3+1.5\Delta{Q}$和区间$Q1-1.5\Delta{Q}$之外的值应该被忽视，被称为异常值，异常值被画在图上 再看看建造年份和售价的关系 123456var = 'YearBuilt'data = pd.concat([train['SalePrice'], train[var]], axis=1)fig = sns.boxplot(x=var,y='SalePrice',data=data)# 将x轴坐标旋转90度plt.xticks(rotation=90)plt.show() 看上去似乎并没有什么强烈的关系 关系总结 地上面积和总的地下面积看上去和房价线性相关，两者的关系都是正向的；并且在总地下面积的关系中可以看到，其与售价面积相关性的斜度非常大 总体质量和建筑年代似乎与售价也有一定关系，其中总体质量关系比较大，箱形图显示出房价随着整体质量的上升而上涨 试验性分析为了更加理性的对房价数据进行分析，我们先用一下几个办法来进行分析： 相关矩阵（热力图heatmap） 房价的相关矩阵（缩放热力图） 大多数相关变量之间的散点图 相关矩阵画个热力图看看相关系数 123456cormat = train.corr()f, ax = plt.subplots(figsize=(12, 9))sns.heatmap(cormat,vmax=.8,square=True)plt.xticks(rotation=90)plt.yticks(rotation=360)plt.show() 在我看来，热力图的确是一个最好的看一个大致影响程度的方法。 可以看到，总地下室面积和一楼面积很大程度上影响了房价，还有关于车库的好几个因素都很大程度上影响了房价。这让我们感觉到heatmap非常适合做特征选择。 售价相关矩阵看完了上面的heatmap的最后一行，我们只是从颜色上看出了各个因素与售价的关系，接下来我们画一个缩放的heatmap来具体看看每个因素的影响有多大 12345678910cormat = train.corr()k = 10cols = cormat.nlargest(10, 'SalePrice')['SalePrice'].indexcm = train[cols].corr()#np.corrcoef(train[cols].values.T)print(train[cols].values)sns.set(font_scale=1.25)hm = sns.heatmap(cm, cbar=True, annot= True, fmt='.2f', annot_kws=&#123;'size':10&#125;, yticklabels=cols.values, xticklabels=cols.values)plt.xticks(rotation=90)plt.yticks(rotation=360)plt.show() 可以看到这些变量是影响房价最大的10个因素，从图中的数值可以看出来，OverallQual和GrLiveArea以及GarageCars和GarageArea是影响房价最大的几个因素。 然而我们可以看到，GarageArea和GarageCars是有因果关系的，车库面积决定了可以停多少车，所以我们最终选择影响更大的GarageCars这个因素 总地下室面积（TotalBsmtSF）和一楼面积1stFlrSF似乎也有强烈相关性，我们选择地下室面积作为因素 地上房间数目（TotRmsAbvGrd）和地上居住面积（GrLivArea）也有相当大关系，所以选其中一个 售价和相关变量之间的散点图12345#画出所有与售价相关的10个因素之间的关系图pairplotk = 10cols = train.corr().nlargest(10, 'SalePrice').index.valuessns.pairplot(train[cols],size=2.5)plt.show() 大量的散点图给了我们一个变量之间关系的合理解释 缺失数据的处理在处理缺失数据之前不妨问一下以下两个问题： 缺失数据的比例有多大 缺失数据是随机的吗还是说缺失数据有一定的模式 这两个问题非常重要，因为缺失数据可能就意味着训练数据的减少，对我们的分析不利。 先来找到缺失的数据： 12345#isnumll()函数将返回与原dataframe同样形状的dataframe，不过原来为空的地方标为1，原来不为空的地方标0total = train.isnull().sum().sort_values(ascending=False)miss_percent = (train.isnull().sum()/train.isnull().count()).sort_values(ascending=False)miss_data = pd.concat([total,miss_percent],axis=1,keys=['total','percent'])print(miss_data.head()) 得到如下的结果| | total | percent || —————— | ——- | ———— || PoolQC | 1453 | 0.995205 || MiscFeature | 1406 | 0.963014 || Alley | 1369 | 0.937671 || Fence | 1179 | 0.807534 || FireplaceQu | 690 | 0.472603 || LotFrontage | 259 | 0.177397 || GarageCond | 81 | 0.055479 || GarageType | 81 | 0.055479 || GarageYrBlt | 81 | 0.055479 || GarageFinish | 81 | 0.055479 || GarageQual | 81 | 0.055479 || BsmtExposure | 38 | 0.026027 || BsmtFinType2 | 38 | 0.026027 || BsmtFinType1 | 37 | 0.025342 || BsmtCond | 37 | 0.025342 || BsmtQual | 37 | 0.025342 || MasVnrArea | 8 | 0.005479 || MasVnrType | 8 | 0.005479 || Electrical | 1 | 0.000685 || Utilities | 0 | 0 | 看一看到缺失最多的达到了99.5%，我们现在制定一个原则，当数据缺失超过15%的时候，我们就把这个变量删掉 同样，虽然Garage相关的数据只缺失5%，但是“GarageCars”已经可以表示车库相关的问题，我们把garage相关的信息删掉，同样BsmtX相关的变量也删掉 最后，我们的删除方案是，除了只有一个缺失值的Electrical列删除缺失值所在行，别的都删除所在列 123train = train.drop((miss_data[miss_data['total'] &gt; 1]).index,1)train = train.drop(train.loc[train['Electrical'].isnull()].index,0)print(train.isnull().sum().max()) 异常值处理异常值会对模型产生很大的影响，因此需要格外注意 单变量分析这里最主要的问题就是建立一个阈值去筛选出异常值，因此我们需要对数据进行标准化。意味着将数据值变化到均值为0，标准差为1的数据 123# 标准化数据from sklearn.preprocessing import StandardScalersaleprice_scaled = StandardScaler().fit_transform(train['SalePrice'].values) 找到标准化之后数据的最大最小的10个值1234lowrange = np.sort(saleprice_scaled)[:10]highrange = np.sort(saleprice_scaled)[-10:]print('lowrange 10 values',lowrange)print('highrange 10 values',highrange) 得到结果 1234[-1.83820775 -1.83303414 -1.80044422 -1.78282123 -1.77400974 -1.62295562 -1.6166617 -1.58519209 -1.58519209 -1.57269236][ 3.82758058 4.0395221 4.49473628 4.70872962 4.728631 5.06034585 5.42191907 5.58987866 7.10041987 7.22629831] 可以看到，最小值都比较相近且接近0，最大值相差比较大，且远离0，特别是有几个7点几的几乎可以肯定是异常值 二元变量分析我们画出地面居住面积和房价的散点图 1234# 二元分析房价与地上居住面积var = 'GrLivArea'data = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)data.plot.scatter(x=var, y='SalePrice', ylim=(0,800000)); 有两个面积很大但是价格很低的点，我们可以推断他们对我们的分析意义不大，可能是偏远农村的房子。我们认为这两个点是异常值并删除他们。 最高处的两个点，应该就是我们在标准化数据的时候得到的7点几的两个点，然而他们两个点好像符合这个线性关系，我们暂时决定保留他们。 我们先删除两个异常值 1234# 删除异常值print('删除之前的矩阵：',train.shape)train = train.drop(train[(train['SalePrice']&lt;300000) &amp; (train['GrLivArea']&gt;4000)].index)print('删除之后的矩阵：',train.shape) 得到： 12删除之前的矩阵：(1459, 63)删除之后的矩阵：(1457, 63) 接下来进行售价和总地下室面积的二元分析 1234var = 'TotalBsmtSF'data = pd.concat([train['SalePrice'],train[var]],1)data.plot.scatter(x=var,y='SalePrice')plt.show() 我们可能很想要删除那几个居住面积大于3000的值，但是在这里我们先保留他们 得到模型我们已经完成了数据清理，现在需要对售价的模型提出假设： 根据论文Hair et al. (2013)中提到，我们需要对数据进行四类假设： 正态性：说到正态性就是说数据长得比较像正态分布，这非常重要，因为好几种统计测试方法都依赖于这个（比如t-statistics)。在这个问题中我们只是检查售价这个单变量的正态性，记住：单变量的正态性并不意味着多变量的正态性，还有，在样本超过200的时候，正态性并不是个问题。如果我们解决了正态性，那么就避免了很多别的问题，比如heteroscedacity（异方差），这个就是我们为什么要做这个分析的原因， 同方差性：所有自变量的方差相同 线性：最好的检查现行的方法就是画散点图，看看上面有没有直线。 相关误差的缺乏：相关误差是在一个误差发生的时候，与其相关联的值也会发生误差。 寻找正态性我们之前已经看了房屋售价的histgram的图，找到了峰度和偏态。 那么我们再画一个正态概率图，用来找到我们的histgram和正态分布的区别 1234sns.distplot(train.loc[:,'SalePrice'], fit=norm)fig = plt.figure()res = stats.probplot(train['SalePrice'], plot=plt)plt.show() 得到下面两张图 显然，售价并不是正态分布，他有一个尖峰，并且正的偏度。然而我们可以通过一个简单的变换把这些数据变成正态的，在统计学中可以知道，当数据分布是有正的偏度的时候，log变换非常有效。 进行log变换 1train['SalePrice'] = np.log(train['SalePrice']) 变换之后的数据 同样，我们对GrLivArea进行一个log变换 123456train['GrLivArea'] = np.log(train['GrLivArea'])#正态概率图sns.distplot(train.loc[:,'GrLivArea'], fit=norm)fig = plt.figure()res = stats.probplot(train['GrLivArea'], plot=plt)plt.show() 得到变换之后的图形如下： 我们再来看看TotalBsmtSF本来的数据长什么样子： 1234sns.distplot(train['TotalBsmtSF'], fit=norm)fig = plt.figure()res = stats.probplot(train['TotalBsmtSF'], plot=plt)plt.show() 我们可以看到好多值都是0，这样我们就不能用log变换了 我们在做log变换之前需要把所有为0的值变为1，这样变换之后，值还是0 123456789print('等于0平的地下室',train[train['TotalBsmtSF'] == 0]['TotalBsmtSF'].shape)print(train.loc[train['TotalBsmtSF']&gt;0,'TotalBsmtSF'].shape)train.loc[train['TotalBsmtSF']&gt;0,'TotalBsmtSF'] = np.log(train.loc[train['TotalBsmtSF']&gt;0,'TotalBsmtSF'])print(train['TotalBsmtSF'].head())#正态概率图sns.distplot(train[train['TotalBsmtSF']&gt;0]['TotalBsmtSF'], fit=norm)fig = plt.figure()res = stats.probplot(train[train['TotalBsmtSF']&gt;0]['TotalBsmtSF'], plot=plt)plt.show() 我们只画出为正的那部分的地下室的变化之后的分布，也服从正态分布 验证同方差性最好的验证同方差性的办法就是图形。 先看看‘SalePrice’ and ‘GrLivArea’的分布 1plt.scatter(df_train['GrLivArea'], df_train['SalePrice']) 对比log变化之前的图形，可以看到这个图没有之前那种锥形的样子了，这就是正态性的效果，确保了正态性往往就确保了同方差性 再看看’SalePrice’ with ‘TotalBsmtSF’. 1plt.scatter(train[train['TotalBsmtSF']&gt;0]['TotalBsmtSF'], train[train['TotalBsmtSF']&gt;0]['SalePrice']); 哑变量1df_train = pd.get_dummies(df_train) 一句话就可以推出哑变量]]></content>
      <categories>
        <category>python</category>
        <category>编程练习</category>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>kaggle</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[WinEdt中英文字体调节]]></title>
    <url>%2F2017%2F12%2F18%2FWinEdt%E4%B8%AD%E8%8B%B1%E6%96%87%E5%AD%97%E4%BD%93%E8%B0%83%E8%8A%82%2F</url>
    <content type="text"><![CDATA[WinEdt10之后的版本，在编译器中设置字体只能设置一种，当我们编辑器中又有中文，又有英文的时候会变得很难看，所以我们需要更改设置脚本以对中英文字体分别设置 设置英文字体及大小点击Options-Options Interface 看到左边的font schemes - Font，双击之后设置英文字体和大小 设置中文字体点击左侧的language ，unicode，sorting，Translations 点击unicode（utf-8） support，把喜欢的中文字体移到最前面 完成！]]></content>
      <categories>
        <category>科研</category>
      </categories>
      <tags>
        <tag>latex</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django项目学习]]></title>
    <url>%2F2017%2F12%2F13%2FDjango%E9%A1%B9%E7%9B%AE%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[本文主要来自于mooc公开课Django课程 首先创建一个Django的虚拟环境：pip install virtualenv，然后使用virtualenv 虚拟环境名建立一个虚拟环境，在windows下面的激活方法是 123cd django_virtualcd Scriptactivate 在linux下只需要将最后一步换位source activate 建立Django项目在PyCharm建立程序时，直接选择Django程序，选择解释器为virtualenv建立的django环境，即可建立django项目 项目建立之后，我们得到了如下的目录结构，紫色的被标记为了templet目录，这样就能智能提示，如果你想要在import的时候不需要加入绝对路径，那么就可以mark as source root 接下来我们先尝试运行该项目，点击run，运行这个Django项目，可以看到运行在了本机的8000端口，点击该地址即可访问： 如果要配置监听所有ip，那么我们需要通过run-Edit configurations，将监听端口改为0.0.0.0 Navicat使用安装好Navicat之后，打开软件，建立连接，之后建立表，设计表的字段，设计完之后按ctrl+s保存，之后就可以插入数据条目，这就是简单的使用方法，具体使用会在之后用到的时候详细介绍。下载地址请点击 Django目录结构首先看看之前提到的建立django之后的目录结构，windows使用tree \F .得到如下结构，linux中使用apt-get install tree，然后tree .即可得到： 12345678├mooc_web │ manage.py ├─mooc_web │ │ settings.py │ │ urls.py │ │ wsgi.py │ │ __init__.py └─templates templetes文件夹主要放html文件 主文件夹下面有settings.py，以及manage.py 我们需要建立static文件夹，用于存放css和js文件，以及主要的图片文件 建立log文件夹，用于存放日志 建立media文件夹，用于存放用户上传的文件 建立apps文件夹，用于存放各个app 建立app通过pycharm当中的tools-run manage.py task，此时可以在shell中执行Django命令： 1startapp message 此时就有了一个名为message的文件夹，将其拖入apps文件夹，自动生成了一个__init__.py文件，这样就让apps变成一个可以导入的包，为了方便导入，那么我们需要将apps文件夹remark成source root，这样每次引用的时候就不需要import apps.message.view 而是可以直接 import message.view 这样在pycharm中引用变得方便了，但是在使用命令行运行的时候就会出错，此时我们需要在settings.py中将apps加入到根搜索路径（BASE_DIR）中 12345678910111213141516171819202122├── apps│ ├── __init__.py│ └── message│ ├── admin.py│ ├── apps.py│ ├── __init__.py│ ├── migrations│ │ └── __init__.py│ ├── models.py│ ├── tests.py│ └── views.py├── db.sqlite3├── log├── manage.py├── media├── mooc_web│ ├── __init__.py│ ├── settings.py│ ├── urls.py│ └── wsgi.py├── static└── templates 建立log文件夹用于存放日志，media用于存放用户的上传文件，建立static存放静态css和js文件 当app比较多的时候，就建立一个apps文件夹，将新建立的app拖进去 使用模板将html模板放入template文件夹，在static文件夹中建立css文件夹，并放入style.css文件 settings配置更改数据库配置因为Django默认用的是sqlite数据库，我们要改成mysql数据库，打开项目的settings.py，找到DATABASES，将其中的： ENGINE改为django.db.backends.mysql NAME改为Navicat中看到的testDjango USER改为数据库的user名，我这里是root PASSWORD改为数据库的password，我这里也是root HOST改为localhost，也就是127.0.0.1 123456789DATABASES = &#123; &apos;default&apos;: &#123; &apos;ENGINE&apos;: &apos;django.db.backends.mysql&apos;, &apos;NAME&apos;: &apos;testDjango&apos;, &apos;USER&apos;: &apos;root&apos;, &apos;PASSWORD&apos;: &apos;root&apos;, &apos;HOST&apos;: &apos;127.0.0.1&apos; &#125;&#125; ####migration生成数据表 通过tools-Run manage.py Task来连接数据库，首先需要安装mysqlclient，用pip install mysqlclient安装： 12&gt; makemigrations # 用于生成一个基于你对模型改变的迁移，在这里就是数据库类型从sqlite迁移到mysql&gt; migrate # 用于应用改变 此时Django自动生成了一大堆数据库表，在Navicat中可以看到表的名称： 此时可以点击run运行整个系统，可以在127.0.0.1:8000上访问该网址 配置static文件夹地址但是此时的style.css无法被找到，我们要在settings.py中配置一下static文件夹的地址，因为STATICFILES_DIRS 可能不止一个，所以用list的形式进行赋值，其中BASE_DIR是项目文件的根目录： 123STATICFILES_DIRS = [ os.path.join(BASE_DIR,&apos;static&apos;)] urls.py配置和views.py函数在urls.py中添加新的页面，页面的处理函数要在apps-message-views.py 中新增，首先我们在view.py 中构造如下函数，直接return render的模板，其中request参数是Django的请求，每个views函数都得有： 12def getform(request): return render(request, template_name=&apos;course-comment.html&apos;) 项目配置流程 整体来说，先设置数据库和STATICFILES_DIRS，之后这一块不再动，主要就是views.py写后端逻辑，urls.py写页面地址url配置 Django orm 模型设计普通的数据库调用方法，连接（connect），生成cursor，excute sql语句，cursor.fetchall( ) orm就是把一个表映射成一个类，比如要找出name只需要调用book.name 下面我们开始使用orm进行设计数据库： 找到message下面的models.py文件，在其中定义一个UserMessage类，用于存放我们需要的数据，所有model都要继承models.Model类： 1234567891011class UserMessage(models.Model): name = models.CharField(max_length=20, verbose_name=&apos;用户名&apos;) email = models.EmailField(verbose_name=&apos;邮箱&apos;) address = models.CharField(max_length=100, verbose_name=&apos;地址&apos;) message = models.CharField(max_length=500, verbose_name=&apos;留言信箱&apos;) class Meta: verbose_name = &apos;用户留言信息&apos; verbose_name_plural = verbose_name ordering = &apos;-id&apos; # 排序方式为反向的id db_table = &apos;my_table&apos; #设置table的名字 其中每一个字段都定义一个类型，常用的有CharField，EmailField，DateTimeField, IntergerField, ForeignKey, IPAddressField, FileField, ImageField 其中max_length表示最大长度，verbose_name表示别名. 自己定义的model还有一个内部类Meta，用于存放所有不是Field的字段，比如排序的顺序，数据表的名称等等 应用模型的改变点击Tools-Run manage.py，执行命令，发现找不到message这个model，所有我们要去settings.py中INSTALLED_APPS加入’app.message’ 再次执行 12&gt; makemigrations message&gt; migragate message 对数据表进行增删改查查找数据先引入model对象，from apps.message.models import UserMessage ，，利用model对象的objects方法，对数据进行操作 1234567all_message = UserMessage.objects.all() #这个是可以循环的for message in all_messages: print(message.name)filterd_data = UserMessage.objects.filter(name=&apos;jeffrey&apos;,address=&apos;beijing&apos;) #filter方法可以对数据进行过滤，中间的逗号表示多个条件，这里是取出的name为jeffrey，address为北京的值for message in filterd_data: print(message.name) 这里的all就是取出所有值，filter就是取出特定条件的值 增加数据定义一个新的对象，并对其各个field赋值 12345user_message = UserMessage()user_message.name = &apos;a&apos;user_message.message = &apos;a@a.com&apos;user_message.message = &apos;aaaaa&apos;user_message.save() 这样每次访问form页面的时候都可以存入一条记录 在html文件中需要进行如下更改： 12&lt;form action=&quot;/form/&quot; method=&quot;post&quot; class=&quot;smart-green&quot;&gt;在action中填入网页地址 需要加入CSRF安全机制， 还可以通过页面的表单提交增加新的数据，request的POST属性中，以字典的形式存储了表单中提交的值，可以用python的get方法获取这些值，get的第二个参数为获取不到时候的默认值： 12345678910if request.method == &apos;POST&apos;: name = request.POST.get(&apos;name&apos;,&apos;&apos;) email = request.POST.get(&apos;email&apos;, &apos;&apos;) message = request.POST.get(&apos;message&apos;, &apos;&apos;) user_message = UserMessage() user_message.name = &apos;a&apos; user_message.email = &apos;a@a.com&apos; user_message.message = &apos;aaaaa&apos; user_message.save() 删除数据直接先查找到对象，然后用delete方法就可以删除对象 12all_message = UserMessage.objects.fileter(name=&apos;bob&apos;)all_message.delete() 显示数据库中的数据到页面在view.py中，我们可以先取出数据，然后在render的时候，把需要传入的参数以一个dict的形式，传递给context，这样我们就可以在html文件中进行调用 123456def getform(request): message = None all_message = UserMessage.objects.filter(name=&apos;boobytest&apos;) if all_message: message = all_message[0] return render(request, template_name=&apos;course-comment.html&apos;,context=&#123;&apos;message&apos;:message,&#125;) 在HTML文件中调用参数的方法是两个大括号，input就输入在value里面，textarea就输入在两个标签之间： 12&lt;input id=&quot;email&quot; type=&quot;email&quot; value=&#123; &#123; message.email &#125; &#125; name=&quot;email&quot; placeholder=&quot;请输入邮箱地址&quot;/&gt;&lt;textarea id=&quot;message&quot; name=&quot;message&quot; placeholder=&quot;请输入你的建议&quot;&gt;&#123; &#123; message.message &#125; &#125;&lt;/textarea&gt; 在HTML文件中使用python逻辑在HTML文件中，使用python逻辑的方法是大括号加百分号，{ % python expression % } if和end if成对出现 123&lt;input id=&quot;name&quot; type=&quot;text&quot; value=&quot;&#123; % if not message.name == &apos;boobytest&apos; % &#125;boobyhastest&#123; % else % &#125;booby no test&#123; % endif % &#125;&quot; name=&quot;name&quot; class=&quot;error&quot; placeholder=&quot;请输入您的姓名&quot;/&gt; 比如在HTML中使用if和else的方法如上，当然if a==b 也可以使用 ifequal a b代替，取前五位也可以使用message.name|split:&#39;5&#39; 1&#123; % ifequal a b% &#125; &#123; % endif % &#125;#用于表示等于 Django提供了很多内置的方法，具体可以查看Django template built-in tags 使用别名关联url和HTMLurl在配置过程中可能会改变，因此我们需要为url设置一个不变的名字供HTML调用 在url.py中： 1url(r&apos;^form/$&apos;, getform,name=&apos;form&apos;) 在comment.html中： 1&lt;form action=&quot;&#123; % url &apos;form&apos; % &#125;&quot; method=&quot;post&quot; class=&quot;smart-green&quot;&gt; 注意，在url配置中一定要加上/$ 表示以/结尾，不然再进行正则匹配的时候可能会匹配到别的网页 url匹配必须在url前面加上^，后面加上/$，这样不会匹配出错 mooc开发实战app设计 新建虚拟环境1234mkvirtualenv mooccd mooc/Scriptactivatepip install Django mysqlclient 新建Django项目通过pycharm建立Django项目，名字为MxOnline，首先在settings.py中更改数据库引擎 123456789DATABASES = &#123; &apos;default&apos;: &#123; &apos;ENGINE&apos;: &apos;django.db.backends.mysql&apos;, &apos;NAME&apos;: &apos;mxonline&apos;, &apos;USER&apos;: &apos;root&apos;, &apos;PASSWORD&apos;: &apos;root&apos;, &apos;HOST&apos;: &apos;127.0.0.1&apos;, &#125;&#125; 通过Tools-run manage.py task来生成数据库的表 12makemigrationsmigragate 扩展user表首先startapp users，在models当中，新建一个UserProfile，继承django.contrib.auth.models.AbstractUser，加入你需要的自定义字段，并定义好meta信息中的verbose_name 12345678910111213141516from django.db import modelsfrom django.contrib.auth.models import AbstractUser# Create your models here.class UserProfile(AbstractUser): nick_name = models.CharField(max_length=50,verbose_name=&apos;昵称&apos;,default=&apos;&apos;) birthday = models.DateField(verbose_name=&apos;生日&apos;,null=True,blank=True) gender = models.CharField(max_length=5,choices=((&apos;male&apos;,&apos;男&apos;),(&apos;female&apos;,&apos;女&apos;)),default=&apos;&apos;) address = models.CharField(max_length=100,default=&apos;&apos;) mobile = models.CharField(max_length=11, null=True, blank=True) image = models.ImageField(upload_to=&apos;image/%Y/%m&apos;,default=&apos;image/default.png&apos;) class Meta: verbose_name = &apos;用户信息&apos; verbose_name_plural = verbose_name 然后run manage.py，通过makemigrations users和migragate users生成新的user表，可能会报错，报错时只需要将之前生成的所有表删除后重新生成即可 循环引用 避免交叉引用，不然会出错，使用上层app引用下层app 加入邮件验证码和轮播图123456789101112131415161718class EmailVerifyRecord(models.Model): code = models.CharField(max_length=20, verbose_name=&apos;验证码&apos;) email = models.EmailField(max_length=50, verbose_name= &apos;邮箱&apos;) send_type = models.CharField(choices=((&apos;register&apos;,&apos;注册&apos;),(&apos;forget&apos;,&apos;找回密码&apos;)),max_length=10) send_time = models.DateTimeField(default=datetime.now) #记得去掉datetime.now的括号，不然只会记录class生成的时间 class Meta: verbose_name = &apos;邮箱验证码&apos; verbose_name_plural = verbose_nameclass Banner(models.Model): title = models.CharField(max_length=100, verbose_name=&apos;标题&apos;) image = models.ImageField(upload_to=&apos;banner/%Y/%m&apos;, verbose_name=&apos;轮播图&apos;) url = models.URLField(max_length=500, verbose_name=&apos;访问地址&apos;) index = models.IntegerField(default=100, verbose_name=&apos;顺序&apos;) add_time = models.DateTimeField(default=datetime.now, verbose_name=&apos;添加时间&apos;) class Meta: verbose_name = &apos;轮播图&apos; verbose_name_plural = verbose_name 课程model设计1234Course -- 课程基本信息Lesson -- 章节信息Video -- 视频CourseResource -- 课程资源 一共有上述四张表 12345678910111213141516171819202122232425262728293031323334353637383940414243from django.db import modelsfrom datetime import datetime# Create your models here.class Course(models.Model): name = models.CharField(max_length=50, verbose_name=&apos;课程名称&apos;) desc = models.CharField(max_length=300, verbose_name=&apos;课程描述&apos;) detail = models.TextField(verbose_name=&apos;课程详情&apos;) degree = models.CharField(choices=((&apos;cj&apos;,&apos;初级&apos;),(&apos;zj&apos;,&apos;中级&apos;),(&apos;gj&apos;,&apos;高级&apos;)),verbose_name=&apos;课程难度&apos;,max_length=2) learn_time = models.IntegerField(default=0, verbose_name=&apos;学习时长(分钟数)&apos;) students = models.IntegerField(default=0, verbose_name=&apos;学习人数&apos;) fav = models.IntegerField(default=0, verbose_name=&apos;收藏人数&apos;) image = models.ImageField(upload_to=&apos;courses/%Y/%m&apos;, verbose_name=&apos;封面图&apos;, max_length=100) click_num = models.IntegerField(default=0, verbose_name=&apos;点击数&apos;) add_time = models.DateTimeField(default=datetime.now, verbose_name=&apos;添加时间&apos;) class Meta: verbose_name=&apos;课程&apos; verbose_name_plural = verbose_nameclass Lesson(models.Model): course = models.ForeignKey(Course, verbose_name=&apos;课程&apos;) name = models.CharField(max_length=100, verbose_name=&apos;章节名&apos;) add_time = models.DateTimeField(default=datetime.now, verbose_name=&apos;添加时间&apos;) class Meta: verbose_name = &apos;章节&apos; verbose_name_plural = verbose_nameclass Video(models.Model): lesson = models.ForeignKey(Lesson, verbose_name=&apos;章节&apos;) name = models.CharField(max_length=100, verbose_name=&apos;视频名&apos;) add_time = models.DateTimeField(default=datetime.now, verbose_name=&apos;添加时间&apos;) class Meta: verbose_name = &apos;视频&apos; verbose_name_plural = verbose_nameclass CourseResource(models.Model): course = models.ForeignKey(Course, verbose_name=&apos;课程&apos;) download = models.FileField(upload_to=&apos;courses/resource/%Y/%m&apos;,max_length=100) name = models.CharField(max_length=100, verbose_name=&apos;资源名称&apos;) add_time = models.DateTimeField(default=datetime.now, verbose_name=&apos;添加时间&apos;) class Meta: verbose_name = &apos;课程资源&apos; verbose_name_plural = verbose_name 添加organization的model123CourseOrg -- 课程机构基本信息Teacher -- 教师基本信息CityDict -- 城市信息 添加如下 123456789101112131415161718192021222324252627282930313233343536373839from django.db import modelsfrom datetime import datetime# Create your models here.class CourseOrg(models.Model): city = models.ForeignKey(CityDict,verbose_name=&apos;所在城市&apos;) name = models.CharField(max_length=50,verbose_name=&apos;机构名称&apos;) desc = models.TextField(verbose_name=&apos;机构描述&apos;) click_nums = models.IntegerField(default=0, verbose_name=&apos;点击数&apos;) fav_nums = models.IntegerField(default=0, verbose_name=&apos;收藏数&apos;) image = models.ImageField(upload_to=&apos;org/%Y/%m&apos;,verbose_name=&apos;封面图&apos;) address = models.CharField(max_length=150,verbose_name=&apos;地址&apos;) add_time = models.DateTimeField(datetime.now, verbose_name=&apos;添加时间&apos;) class Meta: verbose_name = &apos;课程机构&apos; verbose_name_plural = verbose_nameclass CityDict(models.Model): name = models.CharField(max_length=20,verbose_name=&apos;城市&apos;) desc = models.CharField(max_length=200, verbose_name=&apos;描述&apos;) add_time = models.DateTimeField(datetime.now, verbose_name=&apos;添加时间&apos;) class Meta: verbose_name = &apos;城市&apos; verbose_name_plural = verbose_nameclass Teacher(models.Model): org = models.ForeignKey(CourseOrg, verbose_name=&apos;所属机构&apos;) name = models.CharField(max_length=20,verbose_name=&apos;教师名&apos;) work_years = models.IntegerField(default=0, verbose_name=&apos;工作年限&apos;) work_company = models.CharField(max_length=50,verbose_name=&apos;就职公司&apos;) work_position = models.CharField(max_length=50,verbose_name=&apos;公司职位&apos;) points = models.CharField(max_length=50, verbose_name=&apos;教学特点&apos;) click_nums = models.IntegerField(default=0, verbose_name=&apos;点击数&apos;) fav_nums = models.IntegerField(default=0, verbose_name=&apos;收藏数&apos;) add_time = models.DateTimeField(datetime.now, verbose_name=&apos;添加时间&apos;) class Meta: verbose_name = &apos;教师&apos; verbose_name_plural = verbose_name 添加operation的model12345UserAsk -- 用户咨询CourseComments -- 用户评论UserFavorite -- 用户收藏UserMessage -- 用户消息UserCourse -- 用户学习的课程 添加如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051from django.db import modelsfrom datetime import datetimefrom users.models import UserProfilefrom courses.models import Coursefrom organization.models import CourseOrg# Create your models here.class UserAsk(models.Model): name = models.CharField(max_length=20,verbose_name=&apos;姓名&apos;) mobile = models.CharField(max_length=11, verbose_name=&apos;手机&apos;) course_name = models.CharField(max_length=50,verbose_name=&apos;课程名称&apos;) add_time = models.DateTimeField(datetime.now, verbose_name=&apos;添加时间&apos;) class Meta: verbose_name = &apos;用户咨询&apos; verbose_name_plural = verbose_nameclass CourseComments(models.Model): user = models.ForeignKey(UserProfile, verbose_name=&apos;用户&apos;) course = models.ForeignKey(Course, verbose_name=&apos;课程&apos;) comments = models.CharField(max_length=500,verbose_name=&apos;评论&apos;) add_time = models.DateTimeField(datetime.now, verbose_name=&apos;添加时间&apos;) class Meta: verbose_name = &apos;课程评论&apos; verbose_name_plural = verbose_nameclass UserFavorite(models.Model): user = models.ForeignKey(UserProfile, verbose_name=&apos;用户&apos;) fav_id = models.IntegerField(default=0, verbose_name=&apos;数据id&apos;) fav_type = models.IntegerField(choices=((1,&apos;课程&apos;),(2,&apos;课程机构&apos;),(3,&apos;讲师&apos;)),default=1,verbose_name=&apos;收藏类型&apos;) add_time = models.DateTimeField(datetime.now, verbose_name=&apos;添加时间&apos;) class Meta: verbose_name = &apos;用户收藏&apos; verbose_name_plural = verbose_nameclass UserMessage(models.Model): user = models.IntegerField(default=0,verbose_name=&apos;接收用户&apos;)# 不用外键，因为有可能是发给所有人的消息，用0表示发送给所有人的消息,用int表示用户的id message = models.CharField(max_length=500, verbose_name=&apos;消息内容&apos;) add_time = models.DateTimeField(datetime.now, verbose_name=&apos;添加时间&apos;) has_read = models.BooleanField(default=False,verbose_name=&apos;是否已读&apos;) class Meta: verbose_name = &apos;用户消息&apos; verbose_name_plural = verbose_nameclass UserCourse(models.Model): user = models.ForeignKey(UserProfile, verbose_name=&apos;用户&apos;) course = models.ForeignKey(Course, verbose_name=&apos;课程&apos;) add_time = models.DateTimeField(datetime.now, verbose_name=&apos;添加时间&apos;) class Meta: verbose_name = &apos;用户课程&apos; verbose_name_plural = verbose_name 将所有app放到同一个文件夹下面建立new python package， 把所有的app放到apps这个包下面，注意选择不改相对引用，并mark apps为source root 将apps这个文件夹加入到settings当中 12BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))sys.path.insert(0, os.path.join(BASE_DIR,&apos;apps&apos;)) 建立后台管理系统直接在run manage.py task中输入createsuperuser，输入用户名，邮箱和密码就可以登录 更改语言和时区： 123LANGUAGE_CODE = &apos;zh-hans&apos; #将语言改为中文TIME_ZONE = &apos;Asia/Shanghai&apos; #将时区改为上海USE_TZ = False # 系统使用本地时间而不是utc时间 因为我们更改了admin的auth.user的model，因此需要注册user的model，在users库中的admin.py文件中注册： 1234567from users.models import UserProfile# Register your models here.class UserProfileAdmin(admin.ModelAdmin): #userprofile的管理器 passadmin.site.register(UserProfile,UserProfileAdmin) #admin和model的关联注册 登录http://127.0.0.1:8000/admin就可以对用户进行修改 pycharm全局搜索的快捷键是ctrl+shift+f 使用xadmin使用xadmin，因为我安装的Django 2.0.1版本，所以需要安装专门的xadmin for Django2.0 1pip install git+git://github.com/sshwsfc/xadmin.git@django2 在url.py中引入xadmin 12import xadminurlpatterns = [url(r&apos;^xadmin/&apos;, xadmin.site.urls),] 在settings.py中注册xadmin和crispy_forms: 123456INSTALLED_APPS = [ &apos;django.contrib.admin&apos;,....... &apos;xadmin&apos;, &apos;crispy_forms&apos;,] 接下来同步xadmin的表： 12&gt; makemigrations&gt; migragate 再打开http://127.0.0.1:8000/xadmin就可以访问xadmin的后台管理了 在管理用户信息的时候，会出现错误，这是由于我们用的Django是2.0.1版本，而教程中用到的是1.0+，根据pycharm报错的最后一条，打开widget.py文件，在74行修改如下 1234input_html = [ht for ht in super(AdminSplitDateTime, self).render(name, value, attrs).split(&apos;/&gt;&lt;&apos;) if ht != &apos;&apos;]if (len(input_html) &gt; 1): input_html[0] = input_html[0] + &quot;/&gt;&quot; input_html[1] = &quot;&lt;&quot; + input_html[1] 通过源码安装xadmin在mxonline下建立一个python package文件夹extra_apps，下载xadmin并解压，拷贝其中的xadmin文件夹到其中，并把extra_apps mark as source root，这样引入xadmin的时候就会从相对文件引入 同时在settings.py中把xadmin文件夹加入根搜索路径 注册邮箱验证码model注册方法类似于admin的注册方式，只不过不是在admin.py中注册，而是要新建adminx.py，并且admin继承的是object 12345678import xadminfrom users.models import EmailVerifyRecordclass EmailVerifyRecordAdmin(object): passxadmin.site.register(EmailVerifyRecord, EmailVerifyRecordAdmin) # 注册方法 修改显示的邮件验证码存储记录的str名称： 123456class EmailVerifyRecord(models.Model): code = models.CharField(max_length=20, verbose_name=&apos;验证码&apos;) email = models.EmailField(max_length=50, verbose_name= &apos;邮箱&apos;)....... def __str__(self): return &apos;&#123;0&#125;(&#123;1&#125;)&apos;.format(self.code,self.email) 注意：所有注册的Model名字都应该为class Model名+Admin 添加搜索和显示列在其中加入list_display（显示列）, search_fields（搜索域）, list_filter（过滤器） 1234class LessonAdmin(object): list_display = [&apos;course&apos;,&apos;name&apos;,&apos;add_time&apos;] search_fields = [&apos;course&apos;,&apos;name&apos;,&apos;add_time&apos;] list_filter = [&apos;course&apos;,&apos;name&apos;,&apos;add_time&apos;] 如果要使用外键进行搜索，可以用两个下划线表示 12class LessonAdmin(object): list_filter = [&apos;course__name&apos;,&apos;name&apos;,&apos;add_time&apos;] xadmin全局配置将全站的配置放在user app的admix.py中，新建一个class BaseSetting，用于配置主题 123456from xadmin import viewsclass BaseSettings: enable_themes = True #允许使用主题 use_bootswatch = True #允许多主题xadmin.site.register(views.BaseAdminView,BaseSettings) 建立一个class GlobalSettings配置标题名称和footer名称 12345class GlobalSettings: site_title = &apos;慕学后台管理系统&apos; site_footer = &apos;慕学在线网&apos; menu_style = &apos;accordion&apos; #折叠modelxadmin.site.register(views.CommAdminView,GlobalSettings) 更改model名称在每个model文件夹中的apps.py文件中加入verbose_name 123456from django.apps import AppConfigclass CoursesConfig(AppConfig): name = &apos;courses&apos; verbose_name = &apos;课程&apos; 然后在__init__.py 中加入default_app_config 1default_app_config = &apos;courses.apps.CoursesConfig&apos; 完成用户的登录功能首先将前端给的Index.html（首页）文件和login.html（登录页）文件放入templates文件夹中 在根目录下建立static文件夹，存放css，images，js，media文件，并在settings.py中声明STATICFILES_DIRS=[os.path.join(BASE_DIR,&#39;static&#39;)]，注意：这里的STATICFILES_DIRS必须设置为list或者tuple形式，否则会报错 此时，将html文件中的所有css，js的文件路径修改为/static/css和/static/js 接下来配置url，在url.py中引入TemplateView 1234567from django.views.generic import TemplateViewurlpatterns = [ url(r&apos;^xadmin/&apos;, xadmin.site.urls), url(r&apos;^$&apos;,TemplateView.as_view(template_name=&apos;index.html&apos;),name=&apos;index&apos;), url(r&apos;^login/&apos;, TemplateView.as_view(template_name=&apos;login.html&apos;), name=&apos;login&apos;)] 这样就完成了页面配置，重启项目后就可以访问首页和登录页面 实现使用用户名或者邮箱都可以登录现在users模块中新建CustomBackend类，继承ModelBackend，重写其中的authenticate函数，用Q函数实现或操作 12345678910from django.contrib.auth.backends import ModelBackendfrom django.db.models import Qclass CustomBackend(ModelBackend): def authenticate(self, request, username=None, password=None, **kwargs): try: user = UserProfile.objects.get(Q(username=username)|Q(email=username)) if user.check_password(password): return user except Exception as e: return None 写自己的login函数login，并将其写到urls.py中 views.py 123456789101112def my_login(request): if request.method == &apos;POST&apos;: user_name = request.POST.get(&apos;username&apos;,&apos;&apos;) pass_word = request.POST.get(&apos;password&apos;,&apos;&apos;) user = authenticate(username=user_name,password=pass_word) if user: login(request, user) return render(request, &apos;index.html&apos;,&#123;&apos;userprofile&apos;:user&#125;) else: return render(request,&apos;login.html&apos;,&#123;&apos;msg&apos;:&apos;用户名或密码错误&apos;&#125;) elif request.method == &apos;GET&apos;: return render(request, &apos;login.html&apos;, &#123;&#125;) urls.py 1url(r&apos;^login/&apos;, my_login, name=&apos;login&apos;) 在settings.py中加入AUTHENTICATION_BACKENDS=（&#39;users.views.CustomBackend&#39;,），将认证后台改为自己写的后台 在点击登陆后，我们需要跳转回首页或者是报告密码错误，此时request被传递到网页中，可以在跳转后显示自己的用户名 1&lt;dd&gt;&#123; &#123; request.POST.username &#125; &#125;&lt;img class=&quot;down fr&quot; src=&quot;/static/images/top_down.png&quot;/&gt;&lt;/dd&gt; 将用户登录改成类的方法views.py中加入自己的类： 12345678910111213from django.views.generic import Viewclass LoginView(View): def get(self, request): return render(request, &apos;login.html&apos;, &#123;&#125;) def post(self, request): user_name = request.POST.get(&apos;username&apos;,&apos;&apos;) pass_word = request.POST.get(&apos;password&apos;,&apos;&apos;) user = authenticate(username=user_name,password=pass_word) if user: login(request, user) return render(request, &apos;index.html&apos;,&#123;&apos;userprofile&apos;:user&#125;) else: return render(request,&apos;login.html&apos;,&#123;&apos;msg&apos;:&apos;用户名或密码错误&apos;&#125;) 在urls.py中将loginview注册： 1url(r&apos;^login/&apos;, LoginView.as_view(), name=&apos;login&apos;) 实现用户名和密码的长度和空检验在users模块汇总建立forms.py用于检验表单 forms.py 12345from django import formsclass LoginForm(forms.Form): username = forms.CharField(required=True) password = forms.CharField(required=True, min_length=5) 在views.py中加入loginform的验证，逻辑是如果有效，则提取表单中的username和password，验证成功后，用login函数登录，返回index页面；如果验证失败，返回登录页显示用户或密码错误；如果检测到form有错误，返回登录页，显示错误类型 12345678910111213141516class LoginView(View): def get(self, request): return render(request, &apos;login.html&apos;, &#123;&#125;) def post(self, request): login_form = LoginForm(request.POST) #实例化一个login_form，传入参数为request.POST,自动验证其中的username和password，注意这里名字必须和login.html的form当中的name相同 if login_form.is_valid(): #这一步之后可以看到login_form的error类型，存为一个dict类型 user_name = request.POST.get(&apos;username&apos;,&apos;&apos;) pass_word = request.POST.get(&apos;password&apos;,&apos;&apos;) user = authenticate(username=user_name,password=pass_word) if user: login(request, user) return render(request, &apos;index.html&apos;,&#123;&apos;userprofile&apos;:user&#125;) else: return render(request,&apos;login.html&apos;,&#123;&apos;msg&apos;:&apos;用户名或密码错误&apos;&#125;) else: return render(request,&apos;login.html&apos;,&#123;&apos;login_form&apos;:login_form&#125;) 在login.html中显示错误类型： 12&lt;div class=&quot;error btns login-form-tips&quot; id=&quot;jsLoginTips&quot;&gt;&#123; % for key, error in login_form.errors.items % &#125;&#123; &#123; error &#125; &#125;&#123; % endfor % &#125;&#123; &#123; msg &#125; &#125;&lt;/div&gt; 使用cookies进行登录http本身是一种无状态协议，每次发送请求，服务器返回请求的数据，如果要记住登录状态就需要cookies django的cookie由session_key和session_data以及expire_data组成，实现是通过setings.py中的’django.contrib.sessions’, 每个域名之下的cookies是不能互相访问的 实现user的注册功能先拷贝register.html到template中，配置url， 1url(r&apos;^register/&apos;,RegisterView.as_view,name=&apos;register&apos;), 然后在views.py中加入RegisterView类 123class RegisterView(View): def get(self, request): return render(request, &apos;register.html&apos;) 在HTML代码中修改指向 12&lt;a style=&quot;color:white&quot; class=&quot;fr registerbtn&quot; href=&quot;&#123; % url &apos;register&apos; % &#125;&quot;&gt;注册&lt;/a&gt;&lt;a style=&quot;color:white&quot; class=&quot;fr loginbtn&quot; href=&quot;&#123; % url &apos;login&apos; % &#125;&quot;&gt;登录&lt;/a&gt; 修改其css和js文件的地址，这里介绍第二种修改的方法 首先在html文件中输入{ %load staticfiles% } 然后在需要修改地址的地方输入{ %static &#39;/css/reset.css&#39;% } 加入验证码功能 先安装django-simple-captcha模块 1pip install django-simple-captcha 根据官方文档的提示添加captcha到settings.py当中的INSTALLED_APPS 运行makemigrations,migrate 添加实例到urls.py中 123urlpatterns += [ url(r&apos;^captcha/&apos;, include(&apos;captcha.urls&apos;)),] 然后在forms.py中加入一个新的register_form，在其中加入captchafiled 1234567from django import formsfrom captcha.fields import CaptchaFieldclass RegisterForm(forms.Form): email = forms.EmailField(required=True,error_messages=&#123;&apos;invalid&apos;:&apos;请输入一个有效的邮箱地址&apos;&#125;) password = forms.CharField(required=True,min_length=5,error_messages=&#123;&apos;invalid&apos;:&apos;密码至少6个字符&apos;,&apos;required&apos;:&apos;请输入密码&apos;&#125;) captcha = CaptchaField(error_messages=&#123;&apos;required&apos;: &apos;验证码错误&apos;&#125;) 在view.py中加入registerview 123456789101112131415161718192021222324class RegisterView(View):#get方法，先实例化一个RegisterForm，将register_form返回到html中用于获取验证码 def get(self, request): register_form = RegisterForm() return render(request, &apos;register.html&apos;,&#123;&apos;register_form&apos;:register_form&#125;) def post(self, request): register_form = RegisterForm(request.POST) if register_form.is_valid(): user_name = request.POST.get(&apos;email&apos;, &apos;&apos;) pass_word = request.POST.get(&apos;password&apos;, &apos;&apos;) is_used = UserProfile.objects.filter(username=user_name) if not is_used: user = UserProfile() user.username = user_name user.email = user_name user.password = make_password(pass_word) user.save() send_register_email(user_name) return render(request, &apos;login.html&apos;,&#123;&#125;) else: return render(request, &apos;register.html&apos;, &#123;&apos;msg&apos;:&apos;该用户名已经被占用&apos;,&apos;register_form&apos;:register_form&#125;) else: return render(request, &apos;register.html&apos;,&#123;&apos;register_form&apos;:register_form&#125;) 修改register.html 1234567891011121314151617181920212223242526272829303132333435&lt;div class=&quot;tab-form&quot;&gt;&lt;!--其中的action用于指定提交到哪个页面--&gt; &lt;form id=&quot;email_register_form&quot; method=&quot;post&quot; action=&quot;&#123; % url &apos;register&apos; % &#125;&quot; autocomplete=&quot;off&quot;&gt; &lt;input type=&apos;hidden&apos; name=&apos;csrfmiddlewaretoken&apos; value=&apos;gTZljXgnpvxn0fKZ1XkWrM1PrCGSjiCZ&apos;/&gt;&lt;!--在class里面加入&#123; %if register_form.email.errors % &#125;errorput用于出错时高亮--&gt; &lt;div class=&quot;form-group marb20 &#123; % if register_form.email.errors % &#125;errorput&#123; % endif % &#125;&quot;&gt; &lt;label&gt;邮&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;箱&lt;/label&gt;&lt;!--将value填为上次填写的value，这样出错时不用用户每次手动填写value--&gt; &lt;input type=&quot;text&quot; id=&quot;id_email&quot; name=&quot;email&quot; value=&quot;&#123; &#123; register_form.email.value &#125; &#125;&quot; placeholder=&quot;请输入您的邮箱地址&quot;/&gt; &lt;/div&gt; &lt;div class=&quot;form-group marb8 &#123; % if register_form.errors.password % &#125;errorput&#123; % endif % &#125;&quot;&gt; &lt;label&gt;密&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;码&lt;/label&gt; &lt;input type=&quot;password&quot; id=&quot;id_password&quot; name=&quot;password&quot; value=&quot;&#123; &#123; register_form.password.value &#125; &#125;&quot; placeholder=&quot;请输入6-20位非中文字符密码&quot;/&gt; &lt;/div&gt; &lt;div class=&quot;form-group marb8 captcha1 &#123; % if register_form.errors.password % &#125;errorput&#123; % endif % &#125;&quot;&gt; &lt;label&gt;验&amp;nbsp;证&amp;nbsp;码&lt;/label&gt; &#123; &#123; register_form.captcha &#125; &#125; &lt;/div&gt; &lt;div class=&quot;error btns&quot; id=&quot;jsEmailTips&quot;&gt; &lt;!--用循环的方式将错误显示出来--&gt; &#123; % for key,value in register_form.errors.items % &#125; &#123; &#123; value &#125; &#125; &#123; % endfor % &#125; &#123; &#123; msg &#125; &#125; &lt;/div&gt; &lt;div class=&quot;auto-box marb8&quot;&gt; &lt;/div&gt; &lt;input class=&quot;btn btn-green&quot; id=&quot;jsEmailRegBtn&quot; type=&quot;submit&quot; value=&quot;注册并登录&quot;/&gt; &#123;# &lt;input type=&apos;hidden&apos; name=&apos;csrfmiddlewaretoken&apos; value=&apos;5I2SlleZJOMUX9QbwYLUIAOshdrdpRcy&apos;/&gt;#&#125; &#123; % csrf_token % &#125; &lt;/form&gt;&lt;/div&gt; 处理用户激活在urls.py中插入需要激活的页面，用(?P&lt;active_code&gt;.*?)/$，?P是表示parameter的意思，active_code表示你需要提取的变量，后面的.*?表示正则表达式 1url(r&apos;^active/(?P&lt;active_code&gt;.*?)/$&apos;,ActiveUserView.as_view()), 在view中加入新的ActiveUserView,在get中可以拿到刚才在urls.py中定义的active_code参数，先判断这个值在我的数据库中是否存在 123456789101112class ActiveUserView(View): def get(self, request, active_code): #判断这个值在我的数据库中是否存在 all_records = EmailVerifyRecord.objects.filter(code=active_code) #如果存在，通过active_code对应的email找到用户，并将其is_active改为True if all_records: for record in all_records: email = record.email user = UserProfile.objects.get(email=email) user.is_active = True user.save() return render(request, &apos;login.html&apos;) 在LoginView中加入是否激活的判断 1234567891011121314151617def post(self, request): login_form = LoginForm(request.POST) if login_form.is_valid(): user_name = request.POST.get(&apos;username&apos;,&apos;&apos;) pass_word = request.POST.get(&apos;password&apos;,&apos;&apos;) user = authenticate(username=user_name,password=pass_word) if user: # if user.is_active: login(request, user) return render(request, &apos;index.html&apos;,&#123;&apos;userprofile&apos;:user&#125;) else: return render(request, &apos;login.html&apos;, &#123;&apos;msg&apos;: &apos;用户未激活&apos;&#125;) else: return render(request,&apos;login.html&apos;,&#123;&apos;msg&apos;:&apos;用户名或密码错误&apos;&#125;) else: return render(request,&apos;login.html&apos;,&#123;&apos;login_form&apos;:login_form&#125;) 处理忘记密码在urls.py中加入新的页面 12url(r&apos;^reset/(?P&lt;reset_code&gt;.*?)/$&apos;, ResetView.as_view(), name=&apos;reset_pwd&apos;),url(r&apos;^modify_pwd/&apos;, ModifyPwdView.as_view(), name=&apos;modifypwd&apos;), 在views.py中加入新的view 123456789101112131415161718192021222324252627class ResetView(View): def get(self, request, reset_code): all_records = EmailVerifyRecord.objects.filter(code=reset_code) if all_records: for record in all_records: email = record.email user = UserProfile.objects.get(email=email) return render(request, &apos;password_reset.html&apos;,&#123;&apos;email&apos;:email&#125;) else: return render(request, &apos;active_fail.html&apos;)class ModifyPwdView(View): def post(self, request): reset_form = ResetPwdForm(request.POST) if reset_form.is_valid(): pw1 = request.POST.get(&apos;password1&apos;,&apos;&apos;) pw2 = request.POST.get(&apos;password2&apos;,&apos;&apos;) email = request.POST.get(&apos;email&apos;, &apos;&apos;) if pw1 != pw2: return render(request,&apos;password_reset.html&apos;,&#123;&apos;msg&apos;:&quot;两次密码不一致&quot;&#125;) else: user = UserProfile.objects.get(email=request.POST.email) user.password = make_password(pw1) user.save() return render(request, &apos;login.html&apos;) else: return render(request, &apos;password_reset.html&apos;, &#123;&apos;reset_form&apos;:reset_form,&apos;email&apos;:request.POST.email&#125;) 在forms.py中加入ResetPwdForm 123class ResetPwdForm(forms.Form): password1 = forms.CharField(required=True) password2 = forms.CharField(required=True) 在template中加入password_reset.html 12345678910111213141516171819202122&lt;!--修改action为modifypwd--&gt;&lt;form id=&quot;reset_password_form&quot; action=&quot;&#123; % url &apos;modifypwd&apos; % &#125;&quot; method=&quot;post&quot;&gt; &lt;ul&gt; &lt;li&gt;&lt;!--两次密码的name分别为password1和password2--&gt; &lt;span class=&quot;&quot;&gt;新 密 码 ：&lt;/span&gt; &lt;input type=&quot;password&quot; name=&quot;password1&quot; id=&quot;pwd&quot; placeholder=&quot;6-20位非中文字符&quot;&gt; &lt;i&gt;&lt;/i&gt; &lt;/li&gt;&lt;!--加入一个隐藏层用于传输email--&gt; &lt;input type=&quot;hidden&quot; value=&quot;&#123; &#123; email &#125; &#125;&quot; name=&quot;&apos;email&quot;&gt; &lt;li&gt; &lt;span class=&quot;&quot;&gt;确定密码：&lt;/span&gt; &lt;input type=&quot;password&quot; name=&quot;password2&quot; id=&quot;repwd&quot; placeholder=&quot;6-20位非中文字符&quot;&gt; &lt;i&gt;&lt;/i&gt; &lt;/li&gt; &lt;li class=&quot;button&quot;&gt; &lt;input type=&quot;button&quot; value=&quot;提交&quot; onclick=&quot;reset_password_form_submit()&quot;&gt; &lt;/li&gt; &lt;/ul&gt; &#123; % csrf_token % &#125;&lt;/form&gt;]]></content>
      <categories>
        <category>编程学习</category>
        <category>网页制作</category>
      </categories>
      <tags>
        <tag>Django</tag>
        <tag>网页</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ubuntu防火墙设置通过某端口]]></title>
    <url>%2F2017%2F12%2F05%2Fubuntu%E9%98%B2%E7%81%AB%E5%A2%99%E8%AE%BE%E7%BD%AE%E9%80%9A%E8%BF%87%E6%9F%90%E7%AB%AF%E5%8F%A3%2F</url>
    <content type="text"><![CDATA[在启动项里加入以下命令行，修改 /etc/rc.local iptables -I INPUT -p tcp --dport 8888 -j ACCEPT]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux防火墙</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hands on matchine learning]]></title>
    <url>%2F2017%2F12%2F05%2Fhands-on-matchine-learning%2F</url>
    <content type="text"><![CDATA[机器学习分类 unsupervised learning Clustering —k-Means —Hierarchical Cluster Analysis (HCA)-层次聚类分析 ​—Expectation Maximization Visualization and dimensionality reduction 降维方法 —Principal Component Analysis (PCA)主成成分分析 —Kernel PCA —Locally-Linear Embedding (LLE) 局部线性嵌入 —t-distributed Stochastic Neighbor Embedding (t-SNE) t分布随机近邻嵌入 Association rule learning 关联规则挖掘 —Apriori 算法 —Eclat（大成功） Semisupervised learning（半监督学习） 大量无标签数据和少量标记数据 照片标记的时候 强化学习 奖励和惩罚机制 批学习和在线学习（batch learning and online learning） 从是否用新到来的数据进行学习来区分 批学习每次把所有数据都放进去学习，如果数据集过大则不适用 在线学习：每次学习之后可以删除数据，占用计算资源也少 学习率：接收新数据，以及遗忘旧数据的频率 基于实例的学习和基于模型的学习 基于实例的学习：在邮件标记系统中，比较新邮件与已标记为垃圾邮件的相似度，由此来决定是否为垃圾邮件 基于模型的学习：先训练出模型（比如线性模型或者是多项式模型之类的），然后将新的数据输入模型得到结果机器学习问题解决思路 frame the problem搞清楚真正的目标是什么。如何用结果去帮公司盈利之类的。 A sequence of data processing components is called a data pipeline. data pipeline：一系列的数据处理组件被称为数据管道 随机排列数：np.random.permutation() 如果要固定随机的方式，可以在一开始使用np.random.seed(42) train_test_split：把数据集按比例分成训练集和测试集 绘制带有colorbar的图，用圈的大小表示人口数量，用颜色表示放假的高低，红色最高，蓝色最低 12345housing.plot(kind="scatter", x="longitude", y="latitude", alpha=0.4,s=housing["population"]/100, label="population",c="median_house_value", cmap=plt.get_cmap("jet"), colorbar=True,)plt.legend()]]></content>
      <categories>
        <category>机器学习</category>
        <category>技术书籍</category>
      </categories>
      <tags>
        <tag>machine learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pyplot入门]]></title>
    <url>%2F2017%2F11%2F28%2Fpyplot%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[plt画图总体思想，先使用fig = plt.figure(),ax=fig.add_subplot()创建图片，画好图之后，用ax.set_xxx来设置各项参数 设置子图之间的间距plt.subplots_adjust(wspace, hspace)：参数分别代表水平间距和竖直间距 设置x轴坐标及范围set_xticks：刻度值的显示值 set_xticklabels：将任意标签转换为x轴标签 set_xlim：只显示某一部分的时候使用 12ax.set_xticks(range(0,1001,250))ax.set_xticklabels([&apos;one&apos;,&apos;two&apos;,&apos;three&apos;,&apos;four&apos;,&apos;five&apos;],rotation=30,fontsize=&apos;small&apos;) 同样y轴同理 设置title,labelset_title：设置图片title set_xlabel：设置x轴的名称 1234567fig = plt.figure()ax = fig.add_subplot(1,1,1)ax.plot(randn(1000).cumsum(),&apos;k-&apos;)ax.set_xticks(range(0,1001,250))ax.set_xticklabels([&apos;one&apos;,&apos;two&apos;,&apos;three&apos;,&apos;four&apos;,&apos;five&apos;],rotation=30,fontsize=&apos;small&apos;)ax.set_xlabel(&apos;stage&apos;)plt.show() 添加图例在画图的时候传入label，在添加图例的时候用legend就好了 1234ax.plot(randn(1000).cumsum(),&apos;k-&apos;,label=&apos;one&apos;)ax.plot(randn(1000).cumsum(),&apos;g--&apos;,label=&apos;two&apos;)ax.plot(randn(1000).cumsum(),&apos;r-&apos;,label=&apos;three&apos;)ax.legend(loc=&apos;best&apos;) 添加注释注释可以通过text，arrow，annotate等函数添加 保存图片到文件plt.savefig(&#39;a.svg&#39;) pandas当中的plotSeries.plot绘图参数label：用于图例的标签 ax：绘制的画布 style：风格，包括颜色和线型 alpha：不透明度，0-1 kind：’line’,’bar’,’barh’,’kde’ logy：对y轴做对数 use_index：将对象的索引用作刻度标签 rot：旋转刻度标签（0-360） xticks：用作x轴刻度的值 yticks：用作y刻度的值 xlim，ylim：x，y轴界限 grid：显示网格线 DataFrame.plot参数subplots：将各个dataframe列绘制到单独的subplot中 sharex，sharey：如果subplots为true，共用一个x轴，或y轴 figsize：图像大小 title：名称 legend：添加图例，默认为true sort_columns：以字母表顺序绘制各列]]></content>
      <categories>
        <category>编程学习</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>plt</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[*args,**kwargs的使用方法]]></title>
    <url>%2F2017%2F11%2F25%2Fargs-kwargs%E7%9A%84%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[*args和**kargs是一种约定俗称的用法，目的是用于传入不定数量的参数，前者把传入的参数变成一个tuple，后者把传入的参数编程一个字典 1234567891011121314In [1]: def foo(*args): ...: for a in args: ...: print a ...: ...: In [2]: foo(1)1In [4]: foo(1,2,3)123 The **kwargs will give you all keyword arguments except for those corresponding to a formal parameter as a dictionary. 123456789In [5]: def bar(**kwargs): ...: for a in kwargs: ...: print a, kwargs[a] ...: ...: In [6]: bar(name=&apos;one&apos;, age=27)age 27name one Both idioms can be mixed with normal arguments to allow a set of fixed and some variable arguments: 12def foo(kind, *args, **kwargs): pass Another usage of the *l idiom is to unpack argument lists when calling a function. *的另外一个用途就是unpack(打开包裹)，比如调用zip的时候，zip的用法是传入n个对象进行zip，但是每一个都是单独的，比如你可以zip(*[1,2,3]) 123456789In [9]: def foo(bar, lee): ...: print bar, lee ...: ...: In [10]: l = [1,2]In [11]: foo(*l)1 2]]></content>
  </entry>
  <entry>
    <title><![CDATA[numpy教程]]></title>
    <url>%2F2017%2F10%2F22%2Fnumpy%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[使用jupyter notebook 分析数据之前导入的包12345678910111213import numpy as np # linear algebraimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)%matplotlib inlineimport matplotlib.pyplot as plt # Matlab-style plottingimport seaborn as snscolor = sns.color_palette()sns.set_style(&apos;darkgrid&apos;)import warningsdef ignore_warn(*args, **kwargs): passwarnings.warn = ignore_warn #ignore annoying warning (from sklearn and seaborn) 在numpy的使用过程中，最重要的概念就是ndarray，实质上就是数组，在numpy中的所有对象都是ndarray 每一个ndarray对象都有一个shape和dtype属性，用于存储数组的形状和数据类型 函数 说明 array 将输入的数据转换为ndarray asarray 将输入转换为ndarray arange range的数组版本 ones、ones_like 根据指定的形状创建一个全1的数组，ones_like以另一个数组为参数，创建一个与该数组大小相同的全为1的数组 zero、zeros_like 与ones和ones_like类似 empty、empty_like 创建一个没有赋予初始值的数组，用法与ones和ones_like类似 eye，identity 创建一个单位矩阵 可以通过ndarray的astype方法将数组的数据类型转换为其他类型 乘法：直接用乘号或者除号，表示数组*元素之间直接相乘，这个操作称之为广播（不同大小数组之间的运算） np.dot(x,y)或x.dot(y)：用于矩阵乘积 索引和复制12345678910In [1]: arr = np.arange(10)In [2]: arrOut[2]: array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])In [3]: arr[5:8] = 12In [4]: arrOut[4]: array([ 0, 1, 2, 3, 4, 12, 12, 12, 8, 9])In [5]: arr_slice = arr[5:8]In [6]: arr_slice[1] = 12345In [7]: arrOut[7]: array([ 0, 1, 2, 3, 4, 12, 12345, 12, 8, 9]) numpy当中所有数据切片赋值时都是没有进行复制的，视图上的任何修改都会直接反映到原数组上，因为numpy一般处理非常大的数据集，如果numpy每次进行操作的话就是复制非常多的数据。 花式索引（fancy indexing） 1234567891011121314151617181920In [1]: arr = np.arange(32).reshape((8,4))In [2]: arrOut[2]:array([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]])In [3]: arr[[-1,1,3]]Out[3]:array([[28, 29, 30, 31], [ 4, 5, 6, 7], [12, 13, 14, 15]])In [4]: arr[[1,2,3,-1],[3,2,1,0]]Out[4]: array([ 7, 10, 13, 28]) 同时传入多个索引，一次索引出多个值 转置arr.T表示arr的转置，或者transpose方法表示转置 tanspose有一个换维度的操作 12345678910111213141516171819In [4]: arr = np.arange(16).reshape((2,2,4))In [5]: arrOut[5]:array([[[ 0, 1, 2, 3], [ 4, 5, 6, 7]], [[ 8, 9, 10, 11], [12, 13, 14, 15]]])In [6]: arr.transpose((1,0,2))Out[6]:array([[[ 0, 1, 2, 3], [ 8, 9, 10, 11]], [[ 4, 5, 6, 7], [12, 13, 14, 15]]])简而言之就是将原来的0，1，2轴变成现在的1，0，2，转换后的0轴是原来的1轴，转换后的1轴是原来的0轴，2轴未变。换种解释：比如说8元素的索引是[1,0,0]，0，1轴变换后是[0,1,0]。 通用函数（ufunc）：快速的元素级数组函数 函数 说明 abs,fabs 计算绝对值，对于非复数，可以使用更快的fabs sqrt 计算元素的平方根，相当于arr**0.5 square 计算各元素平，相当于arr**2 log，log10，log2，log1p 计算自然对数，以10位底的对数，底数为2的对数，以及log（1+x） sign 取元素的符号，1正，0零，-1负 ceil 向上取整 向下取整 四舍五入取整 将数组的小数和整数部分分别用两个数组返回 isfinite,isinf 返回哪些元素是有穷的，哪些元素是无穷的布尔型数组 cos,cosh,sin,sinh,tan,tanh 三角函数 logical_not 计算各元素not x的真值，相当于-arr 二元ufunc 函数 说明 add 将数组对应元素相加 subtract 对应元素相减 multiply 对应元素相乘 divide，floor_divide 除法或丢掉余数的整除法 pow 计算$A^B$ maximum, fmax 元素级的最大值计算，fmax忽略nana minimum,fmin 最小值计算 mod 求模运算 copysign 将B数组的符号复制给第一个数组 greater，greater_equal，less，less_equal,equal, not_equal 元素比较 logical_and, logical_or，logical_xor 元素级别真值逻辑运算 meshgrid函数X,Y = np.meshgrid(a,b) 得到X为a作为行向量，扩展b.shape那么多行，Y是以b为列向量，扩展a.shape那么多列 12345678910111213141516171819In [67]: xnumsOut[67]: array([0,1, 2, 3]) In [68]: ynumsOut[68]: array([0,1, 2, 3, 4]) In [69]: data_list= np.meshgrid(xnums,ynums) In [70]: data_listOut[70]:[array([[0, 1, 2,3], [0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]]), array([[0, 0, 0, 0], [1, 1, 1, 1], [2, 2, 2, 2], [3, 3, 3, 3], [4, 4, 4, 4]])] np.where（）np.where可以进行x if condition else y的快捷形式 比如我们在下面的例子中，将所有正数替换为2，负数替换为1 123456789101112131415In [7]: arr = np.random.randn(4,4)In [8]: arrOut[8]:array([[ 0.67616266, -0.05338506, 1.24429511, -0.01608611], [ 1.19887484, -0.26227917, -1.06689128, 1.6256341 ], [ 1.33528028, -0.56730727, 0.00761954, 0.15508178], [-1.4552253 , 0.12884633, 0.63242436, -0.62763473]])In [9]: np.where(arr&gt;0, 2, 1)Out[9]:array([[2, 1, 2, 1], [2, 1, 1, 2], [2, 1, 2, 2], [1, 2, 2, 1]]) 基本统计方法sum求和，mean均值，std标准差，var方差，min，max最小最大值 argmin，argmax最小最大值的索引 cumsum：所有元素的累积和，和search_sorted方法配合可以算出分位数所在的位置 123456In [10]: arr = np.random.randn(1000)In [11]: arr.sort()In [12]: arr.searchsorted(int(0.05*(max(arr)-min(arr))))Out[12]: 458 cumprod：所有元素的累积积 唯一化及逻辑运算np.unique效果与python中的set对于list的效果一样，只保留不相同的值 np.in1d用于测试参数是否在数组中 1234567In [13]: arr = np.arange(6)In [14]: arrOut[14]: array([0, 1, 2, 3, 4, 5])In [15]: np.in1d(arr,[0,3,4])Out[15]: array([ True, False, False, True, True, False], dtype=bool) 集合运算的函数 函数 说明 unique 返回唯一元素的有序结果 intersect1d(x,y) 交集（计算xy的公共元素并返回有序结果） union 并集 in1d（x,y） y是否存在于x中的布尔数组 setdiff1d 差集 setxor1d 对称差，存在于一个数组中但不同时存在于两个书注重的元素 元素保存np.save(&#39;filename&#39;, arr):如果没有加后缀会自动加上.npy，然后可以使用np.load读取这个array np.savez(&#39;filename&#39;, a=arr1, b=arr2):存储到压缩文件，后缀为.npz，读取时用load，然后通过字典key，value的索引方式分别取出a和b np.loadtxt(&#39;array.txt&#39;,delimiter=&#39;,&#39;)：读取txt文件，指定分隔符号为delimiter np.savetxt(&#39;filename&#39;, arr)：保存为txt文件 线性代数运算 函数 说明 diag 返回方阵的对角线元素，或者把一维数组转化为方阵 dot 矩阵乘法 trace 对角线元素和 det 矩阵行列式 eig 计算方阵的特征值和特征向量 inv 求方阵的逆 pinv 伪逆 计算QR分解值 svd 奇异值分解 解线性方程Ax=b，其中A是一个矩阵 计算Ax=b的最小二乘解 随机数生成 函数 说明 seed 确定随机数生成器的种子 permutation 返回一个序列的随机排列或者一个随机排列的范围 shuffle 随机打乱一个序列 rand 产生均匀随机分布的样本值 randint 从给定的上下范围内随机选取整数 randn 产生正态分布（平均值为0，标准差为1）的样本值 产生二项分布的样本值 产生正态分布的样本值 产生beta分布的样本值]]></content>
      <categories>
        <category>编程学习</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TensorFlow入门]]></title>
    <url>%2F2017%2F10%2F13%2FTensorFlow%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[MNIST是一个深度学习入门的经典例子，是通过对55000张手写数字的识别以及10000张手写数字数据的测试以及5000个验证数据的验证，来了解TensorFlow的基本用法 每个MNIST数据有两部分，一部分是原始数据，每个图片是28*28的矩阵，在MNIST中已经转换为784的行向量，一行代表一个数据，在python中引用MNIST数据的方式如下： 12from tensorflow.examples.tutorials.mnist import input_datamnist = input_data.read_data_sets("MNIST_data/", one_hot=True) mnist.train.images表示数据，mnist.train.labels表示标签，这个标签被分成了10列，其中只有1列为1其他列为0，每行数据称为一个tensor（张量），其值均为0到1之间的像素值，标签是0-9之间的 one-hot vector是一个稀疏向量，也就是大多数维度上都为0，仅有一个为1 Softmax Regressionssoftmax回归是logistic回归的推广，logistics回归主要解决的是二分类的问题，而softmax回归主要解决的是多分类的问题。 我们对输入的原始数据赋予一个权重和偏差，得到： $evidencei={\sum_j}{W{i,j}}{x_i}+{b_i}$ 其中$W_{i,j}$是权重，$b_i$是偏差，$x_i$是输入变量，$i$表示的是第$i$个类别 然后通过softmax回归，得到： $y=\text{softmax}(evidece)$ 这里的softmax函数可以视作一个激活函数或者是连接函数，把线性函数变换成我们想要的形式，那么我们就得到了10中情况下的概率分布，你可以通过以下的公式得到真正的概率： $\text{softmax}(x)=\text{normalize}(\text{exp}(x))$ 扩展等式后得到： $\text{softmax}(x)=\frac{\text{exp}(x_i)}{\sum_j\text{exp}(x_j)}$ 利用TensorFlow实现softmax方法12import TensorFlow as tfx = tf.placeholder(tf.float32, [None, 784]) x表示tf的一个占位符placeholder，其类型是tf.float32，其shape是[None,784]，其中None可以表示任意的值，在矩阵大小不确定的时候用这种表示方式 再定义权重W和偏量b 12W = tf.Variable(tf.zeros([784,10]))b = tf.Variable(tf.zeros([10])) 把W和b都定义为变量，括号内是其初始值，tf.zeros([10])在这里表示的是一个一行10列的行向量，与np.zeros([10])表示的是一样的 现在我们使用TensorFlow的矩阵乘法来实现softmax： 1y = tf.nn.softmax(tf.matmul(x,W)+b) 计算机器学习模型的性能利用交叉熵来评判算法的性能，作为softmax的损失函数， $H_{y^\prime}(y)=-\sum_i{y_i}{^\prime}\log(y_i) $ 其中y是预测的概率分布，$y^\prime$是真实分布，交叉熵是用于测量预测值描述真实值的无效程度的 为了计算交叉熵，需要增加一个占位符 1y_=tf.placeholder(tf.float32,[None,10]) 然后用下式表示交叉熵： 1cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1])) 开始训练和实施模型通过TensorFlow的train开始训练： 1train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy) 其中的梯度下降是一个简单的下降方法，训练目标是要求最小化交叉熵 利用InteractiveSession来运行模型 1sess = tf.InteractiveSession() 首先要初始化我们设置的变量 1tf.global_variables_initializer().run() 下面开始训练， 123for _ in range(1000): batch_xs, batch_ys = mnist.train.next_batch(100) sess.run(train_step, feed_dict=&#123;x: batch_xs, y_: batch_ys&#125;) 然后计算预测的准确率 1correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1)) tf.argmax(y,1)用于计算每一列最大值，通过tf.equal得到一个全为bool值的向量，通过tf.reduce_mean求出精度： 1accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) 最终，对测试数据进行实验 1print(sess.run(accuracy, feed_dict=&#123;x: mnist.test.images, y_: mnist.test.labels&#125;))]]></content>
      <categories>
        <category>编程学习</category>
        <category>TensorFlow</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>TensorFlow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Cross Validation 交叉验证]]></title>
    <url>%2F2017%2F10%2F10%2FCross-Validation-%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81%2F</url>
    <content type="text"><![CDATA[传统的$F-measure$或平衡的$F-score$ (F1 score)是精度和召回的调和平均值： $F_1 = 2 \frac{precision*recall}{precision + recall}$ 交叉验证cross validation大概的意思是：对于原始数据我们要将其一部分分为train_data，一部分分为test_data。train_data用于训练，test_data用于测试准确率。在test_data上测试的结果叫做validation_error。将一个算法作用于一个原始数据，我们不可能只做出随机的划分一次train和test_data，然后得到一个validation_error，就作为衡量这个算法好坏的标准。因为这样存在偶然性。我们必须好多次的随机的划分train_data和test_data，分别在其上面算出各自的validation_error。这样就有一组validation_error，根据这一组validation_error，就可以较好的准确的衡量算法的好坏。 cross validation是在数据量有限的情况下的非常好的一个evaluate performance的方法。而对原始数据划分出train data和test data的方法有很多种，这也就造成了cross validation的方法有很多种。 带乱序的使用下面的公式可以进行5折交叉验证，cross_val_score函数是进行交叉验证并计算出Validation_score的，但是其中的cross validation并没有打乱原始数据的顺序，所以使用Kfold函数构建cv变量，传递给cross_val_score的cv参数，其中scoring参数可以指定计算准确率的方式 1234567#Validation functionn_folds = 5def rmsle_cv(model): kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(train.values) rmse= np.sqrt(-cross_val_score(model, train.values, y_train, scoring="neg_mean_squared_error", cv = kf)) return(rmse)]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>交叉验证</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python进行数据挖掘中的常见问题及经验]]></title>
    <url>%2F2017%2F10%2F09%2Fpython%E8%BF%9B%E8%A1%8C%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E4%B8%AD%E7%9A%84%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E5%8F%8A%E7%BB%8F%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[在数据分析程序中需要引入的包及设置用python进行数据分析的时候，需要在文件开头导入一下包 123456789101112131415161718import numpy as np # linear algebra 引入线性代数包numpyimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)#%matplotlib inlineimport matplotlib.pyplot as plt # Matlab-style plotting 画图工具包import seaborn as sns # 画图美化工具包color = sns.color_palette()sns.set_style('darkgrid')import warningsdef ignore_warn(*args, **kwargs): passwarnings.warn = ignore_warn #ignore annoying warning (from sklearn and seaborn)from scipy import statsfrom scipy.stats import norm, skew #for some statisticspd.set_option('display.float_format', lambda x: '&#123;:.3f&#125;'.format(x)) #Limiting floats output to 3 decimal points 设置在pd中只显示3位小数 画数据分布图使用seaborn包进行画图，其中数据分布图为distplot，fit参数表示需要拟合的分布类型，norm表示拟合正态分布，正态分布的参数可以由norm.fit来获得 123sns.distplot(data_train[&apos;SalePrice&apos;],fit=norm)(mu, sigma) = norm.fit(data_train[&apos;SalePrice&apos;])plt.legend([&apos;norm distribution with $\mu$=&#123;:.2f&#125;,$\sigma$=&#123;:.2f&#125;&apos;.format(mu,sigma)]) 将分类描述变量转换为数值类型有两种方式可以进行转换： pd.get_dummies(train)：直接传入一个DataFrame，就可以得到改变之后的结果 1234from sklean.preprocessing import LabelEncoderfor label in train.index: encoder = LabelEncoder() train[label] = labencoder.fit_transform(train[encoder]) 矩阵相乘对应元素相乘:np.multiply(A,B)或者是直接用* 矩阵乘法:np.dot(A,B) 参数axis 当axis=0时表示按照行来求值，比如在max函数中，原始数据是一个$40000\times785$的矩阵，那么data.max(axis=0)得到一个$1\times785$的行向量结果，按行就是在行的维度上求最大值 当axis=1时，同理可以得到结果是$785\times1$的列向量数据，按列求值就是在列的维度上进行求值]]></content>
      <categories>
        <category>编程学习</category>
        <category>数据挖掘</category>
      </categories>
      <tags>
        <tag>数据挖掘</tag>
        <tag>pandas</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kaggle-titanic实战--数据挖掘实例]]></title>
    <url>%2F2017%2F09%2F25%2Fkaggle-titanic%E5%AE%9E%E6%88%98-%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E5%AE%9E%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[kaggle是一个国外的数据挖掘竞赛平台，大家做完竞赛之后会写一些指导，因此可以通过其他人写的指导文件进行学习，kaggle传送门。 其中有一个入门类的分析问题是分析Titanic号的救援问题，分析哪些因素会影响到是否被救援，首先打开Titanic这个问题的具体页面，Titanic: Machine Learning from Disaster, ![](http://ooi9t4tvk.bkt.clouddn.com/17-9-25/69961399.jpg) 先看一看overview里面的description和evaluation，看看问题背景和最终需要预测的内容，然后点击数据，下载三个csv格式的数据集，第一个train.csv是训练集，第二个test.csv是测试集，第三个gender_submission.csv是验证集， 下载好之后打开pycharm，新建名为Titanic的工程，新建Titanic.py开始进行分析 首先，导入需要用到的包 1234import numpy as npimport pandas as pdimport matplot.pyplot as pltfrom pandas import DataFrame,Series 接下来导入数据 1train_data = pd.read_csv('train.csv') 查看数据的信息 1train_data.info() 得到的数据信息如下 1234567891011121314151617&lt;class 'pandas.core.frame.DataFrame'&gt;RangeIndex: 891 entries, 0 to 890Data columns (total 12 columns):PassengerId 891 non-null int64Survived 891 non-null int64Pclass 891 non-null int64Name 891 non-null objectSex 891 non-null objectAge 714 non-null float64SibSp 891 non-null int64Parch 891 non-null int64Ticket 891 non-null objectFare 891 non-null float64Cabin 204 non-null objectEmbarked 889 non-null objectdtypes: float64(2), int64(5), object(5)memory usage: 83.6+ KB 一共是891行，12列，其中Age列和Cabin列还有Embarked列数据不完整，每一列的含义如下： PassengerId =&gt; 乘客ID Pclass =&gt; 乘客等级(1/2/3等舱位) Name =&gt; 乘客姓名 Sex =&gt; 性别 Age =&gt; 年龄 SibSp =&gt; 堂兄弟/妹个数 Parch =&gt; 父母与小孩个数 Ticket =&gt; 船票信息 Fare =&gt; 票价 Cabin =&gt; 客舱 Embarked =&gt; 登船港口 然后我们可以看看各个数据的统计值 1train_data.describe() PassengerId Survived Pclass Age SibSp Parch Fare count 891 891 891 714 891 891 891 mean 446 0.383838 2.308642 29.69912 0.523008 0.381594 32.20421 std 257.3538 0.486592 0.836071 14.5265 1.102743 0.806057 49.69343 min 1 0 1 0.42 0 0 0 25% 223.5 0 2 20.125 0 0 7.9104 50% 446 0 3 28 0 0 14.4542 75% 668.5 1 3 38 1 0 31 max 891 1 3 80 8 6 512.3292 得到一个如图的描述，可以看到被救援的人数只有38%，且二，三等舱位人数居多，平均年龄29岁 这样得到的数据有一定的参考性，但是这么多个属性，究竟哪些和最终被救援有关系呢，我们可以画出图像来进行更加形象的描述 所有DataFrame类型的数据都可以在其后面直接调用plot函数，然后在其中输入kind来选择图的类型，绘制代码如下， 12345678910111213141516171819202122232425262728293031323334353637383940414243## 绘制被救情况plt.subplot2grid((2,3),(0,0))## 画子图的第一个fig1 = train_data.Survived.value_counts().plot(kind='bar')plt.title('救援情况(1为被救)')plt.ylabel('人数')for patch in fig1.patches: fig1.annotate(str(int(patch.get_height())),(patch.get_x(),patch.get_height()))## 绘制被救援和舱位之间的关系ax2 = plt.subplot2grid((2,3),(0,1))Survived_0 = train_data.Pclass[train_data.Survived == 0].value_counts()Survived_1 = train_data.Pclass[train_data.Survived == 1].value_counts()df=pd.DataFrame(&#123; u'未获救':Survived_0, u'获救':Survived_1&#125;)fig2 = df.plot(kind='bar', stacked=False , ax=ax2)plt.title(u"各乘客等级的获救情况")plt.xlabel(u"乘客等级")plt.ylabel(u"人数")## 用于标注直方图for patch in fig2.patches: fig2.annotate(str(int(patch.get_height())),(patch.get_x(),patch.get_height()))## 年龄与获救的关系ax3 = plt.subplot2grid((2,3),(0,2))plt.scatter(train_data.Survived, train_data.Age)plt.title('获救与年龄的关系')plt.ylabel('年龄')# plt.xlim([0,1])plt.xticks([0,1])## 各等级舱位年龄分布plt.subplot2grid((2,3),(1,0),colspan=2)train_data.Age[train_data.Pclass == 1].plot(kind='kde')train_data.Age[train_data.Pclass == 2].plot(kind='kde')train_data.Age[train_data.Pclass == 3].plot(kind='kde')plt.title('各等级舱位年龄分布')plt.legend(['头等舱','二等舱','三等舱'])## 各个口岸登船人数plt.subplot2grid((2,3),(1,2))train_data.Embarked.value_counts().plot(kind='bar')plt.title('各个口岸登船人数')plt.show() 绘制得到的图片如下： 其中标注直方图的代码为： 1234def Annotate(fig,plus_times=1.005): for patch in fig.patches: fig.text(patch.get_x()+patch.get_width()/2,patch.get_height()*plus_times, str(int(patch.get_height())),ha='center',va='bottom') 接下来具体看看每个属性和是否被救援的关系 首先画出被救援和性别之间的关系 12345678910survived_m = train_data.Survived[train_data.Sex == 'male'].value_counts()survived_f = train_data.Survived[train_data.Sex == 'female'].value_counts()df_sex = DataFrame(data=&#123;'男性':survived_m,'女性':survived_f&#125;)df_sex.plot(kind='bar')plt.title('被救援和性别的关系',fontsize=20)plt.ylabel('人数',fontsize=15)## 将横坐标的值改成中文plt.xticks(range(2),['未获救','获救'],fontsize=15,rotation=360)plt.legend(['男性','女性'],fontsize=15)plt.show() 其中的字体大小设置可以用ctrl+B跳到原始代码中去看，大多数情况都是直接设置fontsize 舱位级别和性别对获救的影响 123456789101112131415161718192021222324252627282930313233343536373839fig = plt.figure()plt.suptitle('舱位级别和性别对获救的影响',fontsize=20)#用于标注和设置横坐标的xticklablesdef Annotate(fig,plus_times=1.005): for patch in fig.patches: fig.text(patch.get_x()+patch.get_width()/2,patch.get_height()*plus_times, str(int(patch.get_height())),ha='center',va='bottom') fig.set_xticklabels(['未获救','获救'],rotation=0) # 第一幅图ax1 = fig.add_subplot(1,4,1)a = train_data.Survived[train_data.Sex == 'female'][train_data.Pclass == 1].sort_values()# train_data.Survived[train_data.Sex == 'female'][train_data.Pclass == 1].value_counts().plot(kind='bar',color='pink')unsurvived = len(train_data.Survived[train_data.Survived==0][train_data.Sex == 'female'][train_data.Pclass == 1])survived = len(train_data.Survived[train_data.Sex == 'female'][train_data.Pclass == 1][train_data.Survived==1])ax1.bar(range(0,2),[unsurvived,survived],width=0.3,color='pink')ax1.set_title('高级舱女性获救情况')plt.xticks([0,1])Annotate(ax1)# 第二幅图ax2 = fig.add_subplot(1,4,2)train_data.Survived[train_data.Sex == 'female'][train_data.Pclass == 3].value_counts().plot(kind='bar',color='green')Annotate(ax2)ax2.set_title('低级舱女性获救情况')# 第三幅图ax1 = fig.add_subplot(1,4,3)train_data.Survived[train_data.Sex == 'male'][train_data.Pclass == 1].value_counts().plot(kind='bar',color=['blue','yellow'])ax1.set_title('高级舱男性性获救情况')Annotate(ax1)# 第四幅图ax1 = fig.add_subplot(1,4,4)train_data.Survived[train_data.Sex == 'male'][train_data.Pclass == 3].value_counts().plot(kind='bar',color='grey')ax1.set_title('低级舱男性性获救情况')Annotate(ax1)plt.show() 接下来画出登船港口与是否获救的关系： 12345678910111213def Annotate(fig,plus_times=1.005): for patch in fig.patches: fig.text(patch.get_x() + patch.get_width() / 2, patch.get_height() * plus_times, str(int(patch.get_height())),ha='center',va='bottom')unsurvived_Embarked = train_data.Embarked[train_data.Survived == 0].value_counts()survived_Embarked = train_data.Embarked[train_data.Survived == 1].value_counts()ax = pd.DataFrame(data=&#123;'获救':survived_Embarked,'未获救':unsurvived_Embarked&#125;).plot(kind='bar')plt.legend(['获救','未获救'],fontsize=15)plt.title('登船港口与是否获救的关系',fontsize=20)plt.ylabel('人数',fontsize=15)ax.set_xticklabels(['s','c','q'],rotation=0,fontsize=15)Annotate(ax)plt.show() 接下来画出堂兄弟姐妹对是否获救的影响： 123456789101112# 堂兄弟/妹对是否获救的影响g = train_data.groupby(['SibSp','Survived'])a=g.count()['PassengerId']colors = ['blue','green']fig = plt.figure()x = [2*i for i in range(int(len(a)/2))]plt.bar(x,a.iloc[x].values,color='blue',label='未获救',width=0.3)plt.bar(x,a.iloc[::2].values,color='blue',label='未获救',width=0.3)plt.bar([i+0.4 for i in x],a.iloc[1::2].values,color='green',label='未获救',width=0.3)plt.legend()plt.show()pass pandas选取偶数行和奇数行分别为：df.iloc[::2], df.iloc[1::2] 要获得Mutiindex的值只需要:df.index.values 下面看看cabin这个参数，这个参数的缺失很多，并且值的种类实在是太多了，基本是每个值都不同，我们要把这个参数作为一个特征的话，也许可以试试cabin是否缺失作为特征 1234567survived_cabin = train_data.Survived[pd.notnull(train_data.Cabin)].value_counts()survived_nocabin = train_data.Survived[pd.isnull(train_data.Cabin)].value_counts()df = DataFrame(data=&#123;'有':survived_cabin, '没有':survived_nocabin&#125;).Tax = df.plot(kind='bar')print(df)# plt.xticks([0,1],['未获救','获救'])plt.show() 看来有cabin这个参数更容易获救 因此我们需要将Cabin的有无转化为bool型变量： 12345# 将cabin的有无转化为bool型变量def bool_Cabin(df): df.loc[pd.notnull(df.Cabin), 'Cabin']= 'Yes' df.loc[pd.isnull(df.Cabin), 'Cabin']= 'No' return df 使用RandomForest Regression 对年龄数据进行拟合因为年龄数据差的比较多，所以我们想到要将年龄数据进行补全，所以想到了拟合年龄的曲线，在这里我们使用的方法是RandomForestRegressor 1234567891011121314151617181920212223242526from sklearn.ensemble import RandomForestRegressordef matchAge(df): # 通过已知的数值型变量来拟合Age这个参数 age_df = df[['Age','Pclass','SibSp','Parch','Fare']] #通过pd.notnull和pd.isnull来判断是否有年龄这个值，并转化为as_matrix() knowAge = age_df[pd.notnull(age_df.Age)].as_matrix() unknowAge = age_df[pd.isnull(age_df.Age)].as_matrix() # 建立label，即为需要预测的标签的已知值，即训练时用到的标签 lable = knowAge[:,0] # 建立x，即输入的训练样本 x = knowAge[:,1:] # 初始化随机森林回归的参数，n_estimators=2000表示迭代2000次，n_jobs=-1表示用cpu的所有核进行并行计算 rfc = RandomForestRegressor(random_state=0, n_estimators=2000, n_jobs=-1) # 开始训练 rfc.fit(x,lable) # 开始利用训练好的模型进行预测 predictedAges = rfc.predict(unknowAge[:, 1:]) # 将原始数据的空值部分赋值为预测的数据 df.Age[pd.isnull(df.Age)] = predictedAges # 返回数据集 return df,rfc 将非数字的值转化为数字pandas提供了一个get_dummies函数，可以直接把可以分类的数据转换为多个成标量值，比如下面的将Cabin转化为了Cabin_yes 和Cabin_no: 1234dummies_Cabin = pd.get_dummies(train_data['Cabin'], prefix='Cabin')dummies_Embarked = pd.get_dummies(train_data['Embarked'], prefix='Embarked')dummies_Sex = pd.get_dummies(train_data['Sex'], prefix='Sex')dummies_Pclass = pd.get_dummies(train_data['Pclass'], prefix='Pclass') 连接两个DataFrame只要用pd.concat([df1,df2], axis=1)，就可以按列连接 1train_data = pd.concat([train_data,dummies_Cabin,dummies_Embarked,dummies_Sex,dummies_Pclass],axis=1) 删除某些列直接df.drop([&#39;column1&#39;,&#39;column2&#39;], axis=1, inplace=True)，就是按列删除，并且inplace=True表示将原来的df直接替换成删除掉某些列之后的数据 1train_data.drop(['Name','Sex','Ticket','Cabin','Embarked'],axis=1, inplace=True) 数据归一化使用sklearn.preprocessing包的preprocessing函数，先定义一个scaler实例，用preprocessing的StandardScaler，用scaler先fit出你想要归一化的那一列的参数，然后用fit_transform进行归一化，传入的参数是需要归一化的值和归一化参数 12345678#数据预处理import sklearn.preprocessing as preprocessingscaler = preprocessing.StandardScaler()age_scale_param = scaler.fit(train_data[[&apos;Age&apos;]])train_data[&apos;Age_scaled&apos;] = scaler.fit_transform(train_data[[&apos;Age&apos;]],age_scale_param)Fare_scale_param = scaler.fit(train_data[[&apos;Fare&apos;]])train_data[&apos;Fare_scaled&apos;] = scaler.fit_transform(train_data[[&apos;Fare&apos;]],Fare_scale_param) 逻辑回归预测计算完这些部分，将测试数据导入并进行与训练数据相同的预处理，然后进行逻辑回归预测，先用train_data进行fit，然后用训练数据的x进行预测 123456789101112131415161718from sklearn import linear_modeltrain_data = pd.read_csv('prepross_train.csv',index_col=0)train_data.info()train_df = train_data.iloc[:,1:].as_matrix()y = train_df[:,0]x = train_df[:,1:]# test_data = prepross('test.csv','prepross_test.csv')test_data = pd.read_csv('prepross_test.csv',index_col=0)clf = linear_model.LogisticRegression(penalty='l1',C=1.0,tol=1e-6)clf.fit(x, y)test_x = test_data.iloc[:,1:]prediction = clf.predict(test_x)result = DataFrame(data=&#123;'PassengerId':test_data['PassengerId'].as_matrix(),'Survived':[int(i) for i in prediction]&#125;)result.to_csv('result.csv') 检验预测精度因为我们一开始在进行测试数据预处理的时候，删除了一行，所以在比较的时候应该把这一行补上，在补充完毕之后index是乱的，所以我们直接reset_index，并且sort_values，按照PassengerId排序 1234567891011121314151617181920auth_df = pd.read_csv('gender_submission.csv')result_df = pd.read_csv('result.csv',index_col=0)s = 0a = result_df['PassengerId'].valuesb = auth_df['PassengerId'].valuesc = [c for c in b if c not in a][0]result_df = pd.concat([result_df,auth_df[auth_df.PassengerId == c]],axis=0)result_df.reset_index(drop=True,inplace=True)result_df.sort_values(by='PassengerId',inplace=True)result_df.reset_index(drop=True,inplace=True)result_df.loc[auth_df.PassengerId == c,'Survived'] = 1for i,j in zip(result_df['Survived'].values, auth_df['Survived'].values): if i == j: s += 1print(s)precession = float(s/len(auth_df['Survived']))print(precession) 精度得到为0.9330143540669856]]></content>
      <categories>
        <category>编程学习</category>
      </categories>
      <tags>
        <tag>kaggle</tag>
        <tag>数据挖掘</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pandas入门]]></title>
    <url>%2F2017%2F09%2F24%2Fpandas%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[pandas当中最重要的部分就是pandas提供的dataframe和series类型，可以用来保存任何形式的数据，保存之后的结果类似于二维表的形式 Seriesseries有两个重要的参数是values和index 123456789101112131415In [76]: obj = pd.Series([4,5,6,7])In [77]: objOut[77]:0 41 52 63 7dtype: int64In [78]: obj.indexOut[78]: RangeIndex(start=0, stop=4, step=1)In [79]: obj.valuesOut[79]: array([4, 5, 6, 7], dtype=int64) Series本身和索引都有一个index属性，pandas有一个重要特征就是其iloc选择时是后包含的，比如df[:4,1]是指的0,1,2,3,4行的第1列 123456789101112In [81]: obj.name = &apos;population&apos;In [82]: obj.index.name = &apos;state&apos;In [83]: objOut[83]:state0 41 52 63 7Name: population, dtype: int64 DataFrameDataFrame是一个表格型数据结构，同时有行索引和列索引，列的索引被称为columns，行索引被称为index DataFrame的值仍然存储在values属性里面 更换列的顺序只需要在创建dataframe的时候指定columns的值 其columns和index也可以分别指定名字 indexindex对象是不可更改的 reindex方法可以改变原先index的顺序，不过值也会跟着变，相当于换行的顺序，其中的columns参数可以重新索引列，其中的method可以指定对于不存在的index的插值方法，ffill或pad表示向前填充，bfill和backfill表示向后填充 dropdrop用于删除某些行或某些列，删除index行的时候只需要传入index，删除列的时候要传入columns的名字和axis=1 applymap和applyapply可以应用函数到dataframe上，applymap可以应用函数到元素集级别上 12345678910111213In [8]: df = pd.DataFrame(np.arange(0,1,0.1).reshape(2,5))In [9]: dfOut[9]: 0 1 2 3 40 0.0 0.1 0.2 0.3 0.41 0.5 0.6 0.7 0.8 0.9In [12]: df.applymap(format)Out[12]: 0 1 2 3 40 0.000000 0.100000 0.200000 0.300000 0.4000001 0.500000 0.600000 0.700000 0.800000 0.900000 排序 sort_index：按照索引排序，传入axis=1则按columns进行排序，传入by参数则按照某列的值进行排序 order：对Series进行排序 描述和汇总统计 方法 说明 count 非NA的值的数量 decribe 统计性描述，包括max，min，mena等 max，min 最大最小值 argmax, argmin 获取到最大最小值的索引位置（整数） quantile 计算样本的分位数 sum 总和 median 中位数 mad 平均绝对离差 var、std 方差、标准差 skew 三阶矩（样本的偏度） kurt 四阶矩（样本的峰度） cumsum 累积和 cummin,cummax 样本的累计最大值和累积最小值 cumprod（cum表示cumulative累积的，prod表示product乘积） 样本的累计积 diff 一阶差分 pct_change 计算百分数变化（比如股票涨跌计算） 初始化一个dataFrame，可以read_csv从csv文件获取，也可以通过如下代码： 12import pandas as pddf = pd.DataFrame(data, index, columns) 其中data是numpy中提供的数组或者是字典，index表示每行最左边用于索引的列，columns表示每一列的名称 要取出DataFrame的值，只需要df.column_name，用.加上列的名字就可以了 查看数据通过 df.head：查看前五行数据， df.columns：查看列名 df.values：查看矩阵的值 df.describe()：查看矩阵的统计描述，包括值的个数，平均值，标准差，最大最小值等等 df.T：转置矩阵 df.sort_index(axis=1, ascending=False)：通过列的大小值比较进行排序，axis=0时按照行的大小值进行排序 df.sort_values(by=&#39;B&#39;) df.A或者df[&#39;A&#39;]：选取某一列的值 df[0:3]：通过行号选取某几行的值 df[&#39;20101010&#39;:&#39;20101030&#39;]：通过索引选取某些行的值 df.loc[data[0]]：通过索引进行选取，表示的是loc df.iloc[1:3,1:4]：通过位置进行选取 df.iloc[[1,3,4],[0,2]]：通过位置跳跃式选取，表示的是int loc，通过正数进行索引 df[df.A &gt; 0]：条件选择 处理丢失数据首先复制并修改一下df的索引和columns df1 = df.reindex(index=dates[0:4], columns=list(df.columns) + [&#39;E&#39;]) 这样因为第E列是没有赋值的所以全部为NAN 对于nan数据的处理有两种方法，分别是dropna和fillna df1.dropnan(how=&#39;any&#39;)：删除所有值为nan的行 df1.fillnan(value=5)：将所有nan的值填充为5，可以用字典的形式指定每一列的填充值 查找所有的nan，pd.isnull(df1)或者是pd.notnull(df) 对数据进行统计操作 df.mean()：默认求取的是每列的值，得到一个行向量 df.mean(1)：按行求平均值，得到一个列向量 df.apply(lambda:x:x.max()-x.min())：apply应用一个函数到 DataFrame拼接增加行：append，增加列：assign，df.assign(age=[1,2,3]) 将list连接成DataFrame或者增加列，concat，参数为axes，指定按行合并还是按列合并；参数key，按行合并时可以建立层次化索引，按列合并时作为列的名称。ignore_index=true，可以让合并之后的index是行号而没有重复。 123df = pd.DataFrame(np.random.randn(10, 4))pieces = [df[:3], df[3:7], df[7:]]pd.concat(pieces) 将两个DataFrame按值连接在一起（数据库风格的合并），merge，参数为on，表示按那一列进行合并，默认的how参数为Inner，即内连接，如果要保留所有的值，可以将how设置为outer（外连接时等同于join） 12345678910111213141516171819left = pd.DataFrame(&#123;'key': ['foo', 'foo'], 'lval': [1, 2]&#125;)right = pd.DataFrame(&#123;'key': ['foo', 'foo'], 'rval': [4, 5]&#125;)In [79]: leftOut[79]: key lval0 foo 11 foo 2In [80]: rightOut[80]: key rval0 foo 41 foo 5In [81]: pd.merge(left, right, on='key')Out[81]: key lval rval0 foo 1 41 foo 1 52 foo 2 43 foo 2 5 将两个DataFrame按行连接在一起，Append 123df = pd.DataFrame(np.random.randn(8, 4), columns=['A','B','C','D'])s = df.iloc[3]df.append(s, ignore_index=True) 按条件分组，groupby 1df.groupby(&apos;A&apos;).sum() 对数据进行分类12df = pd.DataFrame(&#123;&quot;id&quot;:[1,2,3,4,5,6], &quot;raw_grade&quot;:[&apos;a&apos;, &apos;b&apos;, &apos;b&apos;, &apos;a&apos;, &apos;a&apos;, &apos;e&apos;]&#125;)df[&quot;grade&quot;] = df[&quot;raw_grade&quot;].astype(&quot;category&quot;) 对分类重命名：Series.cat.categories 1df[&quot;grade&quot;].cat.categories = [&quot;very good&quot;, &quot;good&quot;, &quot;very bad&quot;] 正则表达式条件判定1operating_system = np.where(cframe['a'].str.contains('Windows'),'Windows','Not Windows') 这里用np.where和DataFrame.str.contains(&#39;&#39;)来进行判定一个字符串是否包含windows，如果包含则将其改为windows，否则将其改为’not windows’ 数据规整stack和unstackstack：将行旋转为列 unstack：将列旋转为行，默认进行的是最内层的一列 12345678910111213141516171819202122&gt;&gt;&gt; data=DataFrame(np.arange(6).reshape((2,3)),index=['ohio','colorado'],columns=['one','two','three'])&gt;&gt;&gt; data one two threeohio 0 1 2colorado 3 4 5&gt;&gt;&gt; data.index.name='state'&gt;&gt;&gt; data.columns.name='number'&gt;&gt;&gt; datanumber one two threestate ohio 0 1 2colorado 3 4 5&gt;&gt;&gt; data.stack()state numberohio one 0 two 1 three 2colorado one 3 two 4 three 5#将列转化为行，得到一个Series#对于一个层次化索引的Series，可以用unstack将其重排为一个DataFrame 123456789101112result.unstack(0)state ohio coloradonumber one 0 3two 1 4three 2 5&gt;&gt;&gt; result.unstack('state')state ohio coloradonumber one 0 3two 1 4three 2 5 pivot_table：数据透视表比如在电影打分里面，想得到男女对不同电影的打分，可以使用以下的函数 1mean_ratings = data.pivot_table(&apos;rating&apos;, index=&apos;title&apos;, columns=&apos;gender&apos;, aggfunc=&apos;mean&apos;) 数据类型转换df.astype(int)：将所有数据转换为int类型 数据排序argsort：直接将值改为排序后的标号 123456Africa/Cairo 20Africa/Casablanca 21Africa/Ceuta 92Africa/Johannesburg 87Africa/Lusaka 53# 右边得出的是他们经过排序之后的序号 通过take函数可以取出以argsort为index的数据 将多个文件里面的数据连接在一起用一个循环，每次用read_csv或者是read_table函数读出一个dataframe，然后append到一个空list里面，最后通过pd.concat(frame,ignore_index=True)连接成一个大的dataframe 12345678years = range(1880,2011)frame = []for year in years: filename = &apos;yob&#123;&#125;.txt&apos;.format(year) df = pd.read_csv(filename,names=[&apos;name&apos;,&apos;sex&apos;,&apos;births&apos;]) frame.append(df)data = pd.concat(frame,ignore_index=True)data.to_csv(&apos;birth_data.csv&apos;) 多列索引重新排序swaplevel：交换索引sortlevel：索引排序 set_index：和stack很像，将列值变成索引 reset_index：和unstack很像，将多级索引编程列值 数据读入读入方法 read_csv：用于读取csv，默认分隔符为逗号，需要修改默认分隔符用seperator参数，指定列名用header，无列名时用header=None，无index用index=None read_table：读取txt文件，默认分隔符’\t’，如果分隔符不止一个\t的空格，那么用seperator=’\s+’ read_fwf：fixed-width file，读取定宽文件，也就是没有分隔符 read_clipboard：读取剪贴板中的数据，在将网页转换为表格时很有用 如果只想读入前n行，可以使用nrows参数，指定读入的行数 读入json的方法： 12345import json#将json读入为python对象-字典result = json.loads(obj)#将python对象转化为jsonasjson = json.dumps(result) 将长格式转换为宽格式pivot函数：第一个参数表示行索引的列，第二个参数表示列索引的列 移除重复数据duplicated()：返回一个布尔型变量 drop_duplicates：移除重复行的DataFrame，默认保留第一个出现的值，如果要保存最后一个应该传入take_last=True 对某列传入一个函数map 重命名轴索引rename：得到原始的轴索引的转换版（比如首字母大写或者是全大写） 1data.rename(index=str.title，columns=str.upper) 值分区pd.cut(data, [0, 5, 15, 20], right=False)：将数据按照[0,5),[5,15),[15,20)进行划分 pd.qcut（data，4）将数据按分位数等分为4份 随机重排np.random.permutation(x)：若x是一个整数，那么返回打乱的np.arange(x)，然后通过df.take随机选出这若干行；若x是一个数组，那么返回一个打乱的数组的copy 12r = np.random.permutation(len(df))[:5]df_r = df.take(r) 计算哑变量get_dummies Series字符串处理series.str.xxx 其中包含了一大堆字符串处理函数，比如：contains，findall 也可以使用map和正则表达式来完成]]></content>
      <categories>
        <category>编程学习</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>pandas</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[scrapy爬取知乎问题实战]]></title>
    <url>%2F2017%2F09%2F18%2Fscrapy%E7%88%AC%E5%8F%96%E7%9F%A5%E4%B9%8E%E9%97%AE%E9%A2%98%E5%AE%9E%E6%88%98%2F</url>
    <content type="text"><![CDATA[首先,需要理解cookies的含义，是存储在浏览器中的内容，在本地存储任意键值对，第一次访问时服务器返回一个id存储到本地cookie中，第二次访问将cookies一起发送到服务器中 常见http状态码 code 说明 200 请求成功 301/302 永久重定向/临时重定向 403 没有权限访问 404 没有对应的资源 500 服务器错误 503 服务器停机或正在维护 要爬取知乎内容首先需要进行登录，在本文中我们主要介绍2种登录方式，第一种是通过requests的session保存cookies进行登录，第二种是通过scrapy修改start_requests函数进行登录 requests进行登录在utils中新建zhihu_login.py，实例化一个session对象，设置其cookies对象为cookiesjar库中的LWPCookieJar对象，设置requests库需要用到的headrs（从浏览器中进行拷贝）， 123456789session = requests.session()session.cookies = cookiejar.LWPCookieJar(filename='zhihu_cookies.txt')headers = &#123; 'User-Agent':'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36', 'Origin':'https://www.zhihu.com', 'Accept-Language':'zh-CN,zh;q=0.8,en;q=0.6', 'Host':'www.zhihu.com', 'Referer':'https://www.zhihu.com/'&#125; 接下来，我们要寻找登录发送数据的页面，首先打开zhihu.com退出之前的登录，来到一个登录页面，在登陆页面中使用手机号码登录，此时需要发送一个错误的信息给页面，以找到post数据的网页（如果输入正确的账号密码就直接登录成功了，一大堆网页请求就找不到我们需要的网页了） 找到了需要post的网页，发现post的数据有_xsrf,passoword,phone_num，另外一个captcha_type没有用，加了之后反而无法访问（不知道为什么） 1234567891011121314151617181920212223def zhihu_login(account, password): if re.match('1\d&#123;10&#125;', account): phone_post_url = 'https://www.zhihu.com/login/phone_num' post_data=&#123; '_xsrf':get_xsrf(), 'phone_num':account, 'password':password, # 'captcha_type':'cn' &#125; # session_response = session.post(phone_post_url, data=post_data, headers=header) # print(session_response.text) # result_list = re.findall('"msg": "(.*?)"',session_response.text)[0] # print(result_list.encode('utf8').decode('unicode-escape')) # try: # login_page = session.post(phone_post_url, data=post_data, headers=headers) # print('不要验证码,login_code:&#123;&#125;'.format(login_page.status_code)) # except: post_data['captcha'] = get_captcha() login_page = session.post(phone_post_url, data=post_data, headers=headers) result_list = re.findall('"msg": "(.*?)"', login_page.text)[0] print(result_list.encode('utf8').decode('unicode-escape')) session.cookies.save() print('保存成功') 在这里我们一开始没有使用验证码，发现只要是爬虫登录都会被识别到，所以我们编写了一个用于生成验证码的代码： 1234567891011121314def get_captcha(): t = str(int(time.time()*1000)) captcha_url = 'https://www.zhihu.com/captcha.gif?r=' + t + "&amp;type=login" r = session.get(captcha_url, headers=headers) with open('captcha.jpg','wb') as f: f.write(r.content) try: im = Image.open('captcha.jpg') im.show() im.close() except: print('wrong') captcha = input('请输入验证码:') return captcha 保存完cookies，我们尝试使用这个cookies再次登录 1234567891011def get_again(): try: session.cookies.load(ignore_discard=True) print('cookies加载成功\n') except: print('cookies加载失败') response = session.get('https://www.zhihu.com',headers=headers) # response.encoding = response.apparent_encoding with open('my_zhihu_login.html','wb') as f: f.write(response.text.encode('utf8')) print('保存页面成功') 查看这个页面发现不停地刷新，暂时还没有找到办法 scrapy模拟登陆知乎首先生成一个新的spider，名字为zhihu 在class zhihu中定义headers等信息，重写start_requests函数 12def start_requests(self): return [scrapy.Request('https://www.zhihu.com/#signin',headers=self.headers, callback=self.login)] 在start_requests里面返回一个新的Request，其回调函数设置为一个新的login函数如下： 123456789101112131415161718192021def login(self,response): # print(response.text) # a = '&lt;input type="hidden" name="_xsrf" value="36424865b408db8c3f976a1a676cad60"/&gt;' match_obj = re.match('.*name="_xsrf" value="(.*?)"', response.text, re.DOTALL) if match_obj: _xsrf = match_obj.group(1) post_data = &#123; '_xsrf': _xsrf, 'phone_num': 'xxxxxxxxxxx', 'password': 'xxxxxxx', 'captcha':'' &#125; t = str(int(time.time() * 1000)) captcha_url = 'https://www.zhihu.com/captcha.gif?r=' + t + "&amp;type=login" return [scrapy.Request(url=captcha_url, meta=&#123;'post_data':post_data&#125;, headers=self.headers, callback=self.get_captcha_login)] else: raise EOFError]]></content>
      <categories>
        <category>编程练习</category>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>爬虫</tag>
        <tag>scrapy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[scrapy实战伯乐网文章爬虫]]></title>
    <url>%2F2017%2F09%2F18%2Fscrapy%E5%AE%9E%E6%88%98%E4%BC%AF%E4%B9%90%E7%BD%91%E6%96%87%E7%AB%A0%E7%88%AC%E8%99%AB%2F</url>
    <content type="text"><![CDATA[scrapy实战伯乐网爬虫因为我们要对scrapy进行调试，所以我们建立一个main函数来达到调试的目的，以后每次调试只要debug这个main文件就行了 123456from scrapy.cmdline import executeimport sysimport ossys.path.append(os.path.dirname(os.path.abspath(__file__)))execute(["scrapy", 'crawl', 'jobbole']) 在spider文件夹中初始化爬虫之后，可以看到一个parse函数，这个是用来处理具体的网页内容的，可以用Xpath对网页源码进行解析，其中的response参数表示scrapy返回的网页 我们要爬取所有的文章，就要先找到所有文章的存放地点，我们将class JobboleSpider里面的start_urls改为http://blog.jobbole.com/all-posts/，这个页面存放了所有的posts内容 从第一页开始，每次爬取该页所有posts的链接，进入每一个链接进行处理，要处理一个链接，就是将这个链接yield出来，首先我们先编写在每一页中提取出所有posts的方法，在parse函数中，先找到所有存放posts文件的地方：通过chrome的元素选择快捷键（如下图所示），找到所有的存放posts文件的链接 1response_nodes = response.css('#archive .floated-thumb .post-thumb a') 然后我们在找到的response_nodes中进行循环，并找到其中的首页图片地址和post地址，并将posts地址yield出去，交给scrapy.http.Request处理： 12345for response_node in response_nodes: post_url = response_node.css('::attr(href)').extract_first(default="") image_url = response_node.css('img::attr(src)').extract_first(default="") yield Request(url=post_url, meta=&#123;'front_image_url':image_url&#125;, callback=self.parse_detail) 其中的回调函数是用于具体处理网页内容的函数，meta用于传送首页的图片地址，传送的形式是字典的形式 接下来编写解析下一页的方法： 通过找到下一页这个标签的地址，来进行下一页的访问，首先我们通过css选择器选择出下一页的标签，如果存在下一页，那么我们就将下一页yield到Request来处理，回调函数就是这个函数本身： 1234#jobbole.py parsenext_page_url = response.css('a[class="next page numbers"]::attr(href)').extract_first(default="") if next_page_url: yield Request(url=next_page_url, callback=self.parse) 接下来完成具体的parse_detail函数，用于具体解析每一页的posts内容的函数： 首先拿出来meta里面的内容，为了防止意外报错，我们使用字典的get函数，并将默认值设置为空 1front_image_url = response.meta.get('front_image_url','') 然后通过css或者是xpath解析器依次解析自己需要的内容 接下来需要通过items.py建立自己的item，这个item就是你最后想要保存下来的数据： 默认系统会自动帮你建立一个跟工程名字一样的类，继承的是scrapy.Item，如果你自己需要一个新的item的话，只需要按照相同的方法，在item.py中新建一个类，继承scrapy.Item，然后把你需要的字段一个个定义出来，定义的方法是字段名 = scrapy.Field()，具体代码如下： 12345678910111213#items.pyclass JobBoleArticleItem(scrapy.Item): head = scrapy.Field() post_time = scrapy.Field() url = scrapy.Field() url_id = scrapy.Field() front_image_url = scrapy.Field() front_image_path = scrapy.Field() vote_num = scrapy.Field() comment_num = scrapy.Field() collection_num = scrapy.Field() tags = scrapy.Field() content = scrapy.Field() 然后我们需要在爬虫文件中引入定义的item，在parse_detail中实例化item类，并将每一个字段都赋上从网页上解析出来的值，赋值方法是类似于字典的赋值方法： 1234567#jobbole.pyfrom ..items import JobBoleArticleItemdef parse_detail(): article_item = JobBoleArticleItem() article_item['url'] = response.url article_item['head'] = head yield article_item 剩余字段的赋值方法跟上面这两个是一样的，最后把item实例yield出来，交给pipelines处理，我们定义了一个专门用于处理图片的pipeline，继承的是scrapy.pipelines.images.ImagesPipeline，重构其中的item_completed函数，参数results中的value表示的是在settings.py中设置的跟image相关的参数，取出其中的path，赋值给item[&#39;front_image_path&#39;]，最后return item即可： 1234567#pipelines.pyclass articleImagePipeline(ImagesPipeline): def item_completed(self, results, item, info): for ok,value in results: image_file_path = value['path'] item['front_image_path'] = os.path.abspath(image_file_path) return item 在settings.py中取消掉ITEM_PIPELINES的注释，并增加新的自己定义的articleImagePipeline，后面的数字表示进入pipelines的顺序，数字越小，越早进入。 此时设置好IMAGES_URLS_FIELD，IMAGES_STORE，这样就可以开始下载图片 12345678#settings.pyITEM_PIPELINES = &#123; 'bole.pipelines.BolePipeline': 300, # 'scrapy.pipelines.images.ImagesPipeline': 1, 'bole.pipelines.articleImagePipeline': 1&#125;IMAGES_URLS_FIELD = 'front_image_url'IMAGES_STORE = '../IMAGES' 最后还有把url进行hash成固定长度的过程，建立一个python包叫做utils，里面建立一个common.py，在其中建立get_md5函数，其中的url要以utf8传入，所以一开始要检测其是不是unicode，python3里面的str就是unicode： 1234567#common.pydef get_md5(url): if isinstance(url, str): url = url.encode('utf8') m = hashlib.md5() m.update(url) return m.hexdigest() 接下来解决数据保存的问题，在这里我们使用两种方式，分别是：json文件和mysql数据库保存 I. json的保存 json保存有两种方式，一种是自己写json，一种是利用scrapy.exporter提供的JsonItemExporter类 ①自定义json文件，先用codecs打开json文件（这样打开不会有编码错误问题），然后重写process_item方法，将item先dumps为json，其中设置ensure_ascii=False以支持中文，最后写一个close_spider方法，关闭文件 1234567891011121314151617import codecs, jsonclass MyjsonPipelines(object): #自定义的json导出 def __init__(self): #打开文件 self.file = codecs.open('myarticle.json', mode='w', encoding='utf8') def process_item(self, item, spider): #写入数据 line = json.dumps(dict(item),ensure_ascii=False) self.file.write(line) return item def spider_close(self,spider): #关闭文件 self.file.close() ②利用scrapy提供的JsonItemExporter，先定义打开的文件以及exporter，重写处理数据的方法process_item，最后关闭spider 123456789101112131415from scrapy.exporters import JsonItemExporterclass jsonPipelines(JsonItemExporter): #调用scrapy提供的json exporter来导出json文件 def __init__(self): self.file = open('article.json', 'wb') self.exporter = JsonItemExporter(self.file, encoding='utf8', ensure_ascii=False) self.exporter.start_exporting() def close_spider(self): self.exporter.finish_exporting() self.file.close() def process_item(self, item, spider): self.exporter.export_item(item) return item II. 写入mysql 写入MySQL同样有两种方法，第一种是自己写函数同步写入，第二种是利用twisted.enterprise框架提供的adbapi异步写入，第二种写入的方法更快，但也更复杂 ①利用MySQLdb，建立连接，数据库部分可以参考之前写的数据库基础教程 12345678910111213141516import MySQLdbclass MysqlPipeline(object): def __init__(self): #建立连接和cursor self.conn = MySQLdb.connect(host='127.0.0.1', user='root', password='123456', database='scrapy', port=3306,charset='utf8',use_unicode=True) self.cursor = self.conn.cursor() def process_item(self, item, spider): #数据插入的sql语句并执行和提交(excecute &amp; commit) insert_sql = """ INSERT INTO article (head, post_time, url, url_id) VALUES (%s,%s,%s,%s) """ self.cursor.execute(insert_sql,(item['head'],item['post_time'],item['url'],item['url_id'])) self.conn.commit() ②利用twisted.enterprise提供的adbapi插入数据到mysql，这里用到了一个@classmethod的方法，主要是用于初始化类之前，先进行一个操作的函数，比如在这里我们在初始化twisted_mysql_pipelines之前，先连接了数据库，我们将连接数据库的参数都放在了settings.py里面，要将其取出来要用到def from_settings(cls, settings)，第二个参数是一个字典类型，取值可以通过字典的方法来取。 1234567891011121314151617181920212223242526272829303132from twisted.enterprise import adbapiclass twisted_mysql_pipelines(object): def __init__(self, dbpool): self.dbpool = dbpool @classmethod def from_settings(cls, settings): #连接数据库，返回dbpool dbparm = dict(host=settings['MYSQL_HOST'], user=settings['MYSQL_USER'], password=settings['MYSQL_PASSWORD'], database=settings['MYSQL_DBNAME'], cursorclass = MySQLdb.cursors.DictCursor, charset='utf8', use_unicode=True) dbpool = adbapi.ConnectionPool('MySQLdb', **dbparm)#建立连接池 return cls(dbpool) def process_item(self, item, spider): query = self.dbpool.runInteraction(self.do_insert, item)#开始异步插入数据 query.addErrback(self.error_handler)#处理异常 def error_handler(self, error): #异常处理函数 print(error) def do_insert(self, cursor, item): #插入数据的sql语句 insert_sql = """ INSERT INTO article (head, post_time, url, url_id) VALUES (%s,%s,%s,%s) """ cursor.execute(insert_sql, (item['head'], item['post_time'], item['url'], item['url_id'])) itemloader之前的item是直接用字典的形式进行赋值的，如果使用itemloader会使得整个css查询过程看起来更加简洁清晰，具体使用方法如下： ①先在item.py中新建一个myItemLoader类，继承scrapy.loader.ItemLoader，修改其默认的输出处理函数为TakeFirst()(因为默认输出时一个列表，所以我们需要从里面取第一个) 12345item.pyfrom scrapy.loader import ItemLoaderfrom scrapy.loader.processors import TakeFirstclass myItemLoader(ItemLoader): default_output_processor = TakeFirst() ②在jobbole.py中的parse_detail函数中实例化item_loader，并使用add_css和add_value方法，分别直接添加值或者是通过css寻找值， 12345678910111213141516jobbole.pyfrom ..items import myItemLoaderfrom ..items import JobBoleArticleItemdef parse_detail(self,response): item_loader = myItemLoader(item=JobBoleArticleItem(),response=response) item_loader.add_css(&apos;head&apos;, &apos;.entry-header h1::text&apos;) item_loader.add_value(&apos;url&apos;, response.url) item_loader.add_value(&apos;url_id&apos;, get_md5(response.url)) item_loader.add_css(&apos;post_time&apos;,&apos;.entry-meta-hide-on-mobile::text&apos;) item_loader.add_css(&apos;comment_num&apos;,&apos;a[href=&quot;#article-comment&quot;] span::text&apos;) item_loader.add_css(&apos;vote_num&apos;,&apos;.vote-post-up h10::text&apos;) item_loader.add_css(&apos;collection_num&apos;,&apos;span.bookmark-btn::text&apos;) item_loader.add_css(&apos;tags&apos;,&apos;p.entry-meta-hide-on-mobile a::text&apos;) front_image_url = response.meta.get(&apos;front_image_url&apos;,&apos;&apos;) item_loader.add_value(&apos;front_image_url&apos;,front_image_url) article_item = item_loader.load_item() ③此时通过css找出来的是原始的数据，需要在item.py中写处理方法 12345678910111213141516171819202122232425item.pyfrom scrapy.loader.processors import MapCompose,TakeFirst,Joinimport redef post_time_handle(value): time_pattern = re.compile(r'\d&#123;4&#125;/\d&#123;2&#125;/\d&#123;2&#125;') match = re.findall(time_pattern, value.strip()) if match: print(match) post_time = match[0] return post_timedef get_nums(value): match_re = re.match(".*?(\d+).*", value) if match_re: nums = int(match_re.group(1)) else: nums = 0 return numsdef remove_comment_tags(value): #去掉tag中提取的评论 if "评论" in value: return "" else: return value ④修改item.py中JobBoleArticleItem类的input_processor，使其等于MapCompose(function)，其中tags用到的output_processor是scrapy.loader.processors.Join，将各个值用逗号连接起来 12345678910111213class JobBoleArticleItem(scrapy.Item): head = scrapy.Field(input_processor = MapCompose(lambda x:x+'jobbole')) post_time = scrapy.Field(input_processor=MapCompose(post_time_handle)) url = scrapy.Field() url_id = scrapy.Field() front_image_url = scrapy.Field() front_image_path = scrapy.Field() vote_num = scrapy.Field(input_processor=MapCompose(get_nums)) comment_num = scrapy.Field(input_processor=MapCompose(get_nums)) collection_num = scrapy.Field(input_processor=MapCompose(get_nums)) tags = scrapy.Field(input_processor=MapCompose(remove_comment_tags), output_processor=Join(',')) content = scrapy.Field() Xpath语法 article:选取所有article元素的所有子节点 /article：选取根元素article article/a：选取属于article的子元素（只能是子节点，不能是后辈节点）的a元素 //div：选取所有div子元素（不论出现在文档任何地方） article//div：选取所有属于article元素后代的div元素 //@class：选取所有名为class的属性 /article/div[1]：选取属于article子元素的第一个div元素 /article/div[last()]：属于article的最后一个div /article/div[last()-1]：倒数第二个 //div[@lang]：拥有lang属性的div元素 //div[@lang=&#39;eng&#39;]：选取所有lang属性为eng的div元素 /div/*：div元素的所有子节点 //*：选取所有元素 //div[@*]：所有带有属性的div元素 /div/a | //div/p：所有div元素的a或p元素 //sapn | //ul：所有文档中的span和ul元素 article/div/p | //span：所有属于article元素的div元素的p元素以及文档中所有span元素 用xpath进行提取的方法类似于beautifulsoup，但是xpath的提取速度更快，提取的例子如下： 1、我要提取页面中的title信息，通过F12打开网页控制，点击选择元素，点中需要爬取的部分，可以找到他的源码，右键复制xpath或者是自己写xpath进行爬取(要爬取内容的话在xpath后面要加上/xpath)，之后通过extract()提取为列表，选择第[0]个元素，但是此时有可能列表为空，所以使用extract_first(default=0)，表示提取第一个元素如果为空则返回0，写法如下： 123456head_selector = response.xpath('//*[@class="entry-header"]/h1/text()')head = head_selector.extract()[0]post_time_selector = response.xpath('//p[@class="entry-meta-hide-on-mobile"]/text()')time_pattern = re.compile(r'\d&#123;4&#125;/\d&#123;2&#125;/\d&#123;2&#125;') //*：表示选取所有的任意元素 //p：选取所有的p元素 //p[@class=”dd”]：表示选取所有类为dd的p标签 //p[contains(@class,”dd”)]：选取类名包含dd的p元素 CSS选择器 *：选择所有节点 #container：选择id为container的节点 .container：选取所有class中包含container的节点 li a：选取所有li下面的所有a节点 ul + p：选取ul后面的第一个p元素 div#container &gt; ul：选取id为container的div的第一个ul子元素 ul ~ p：选取与ul相邻的所有p元素 a[title]：选择所有有title属性的a元素 a[href=&quot;http://jobbole.com&quot;]：选取所有href属性为http://jobbole.com的a元素 a[href*=&quot;jobbole&quot;]：选取所有href属性包含jobbole的a元素 a[href^=&quot;http&quot;]：选取所有href以http开头的a元素 a[href$=&quot;.jpg&quot;]：选取所有href以.jpg结尾的a元素 input[type=radio]:checked：选择选中的radio元素 div:not(#container)：选择id不是container的div属性 li:nth-child(3)：选取第三个li元素 tr:nth-child(2n)：选择第偶数个tr pycharm单步调试的快捷键是F8]]></content>
      <categories>
        <category>编程练习</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pip换源]]></title>
    <url>%2F2017%2F09%2F06%2Fpip%E6%8D%A2%E6%BA%90%2F</url>
    <content type="text"><![CDATA[在windows文件管理器中输入%APPDATA%，进入到一个文件夹，新建名为pip的文件夹，然后在其中新建pip.ini文件，输入 1234[global]timeout = 6000index-url = https://pypi.douban.com/simpletrusted-host = pypi.douban.com 转换为豆瓣源 或者输入 12[global]index-url = https://mirrors.xjtu.edu.cn/pypi/web/simple/ 转换为西安交大源]]></content>
      <categories>
        <category>软件配置</category>
      </categories>
      <tags>
        <tag>pip</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[scrapy库详解]]></title>
    <url>%2F2017%2F08%2F13%2Fscrapy%E5%BA%93%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[scrapy是一个完整的爬虫框架，一共有5个部分组成和2个中间部分，最主要的是一下五个部分： ENGINE SCHEDULER ITEM PIPELINES SPIDERS DOWNLOADER 用户主要编写spider和item pipelines，其余三个模块是事先写好的，不需要修改 可以通过修改downloader middleware中间键来对engine，scheduler和Downloader进行配置 scrapy通过命令行运行 1scrapy command [options] [args] scrapy有6个常用命令 startproject：创建一个新的工程 genspider：创建一个爬虫 settings：获得爬虫配置信息 crawl：运行一个爬虫 list：列出工程中所有爬虫 shell：启动url调试命令行 建立一个scrapy工程的方法 1scrapy startproject python123demo 建立完成之后可以看到的文件夹下产生了一个名为python123的文件，进入该文件可以看到一个scrapy.cfg的文件，这是一个部署scrapy的配置文件 1234567891011│ scrapy.cfg│└─python123demo │ items.py │ middlewares.py │ pipelines.py │ settings.py │ __init__.py │ └─spiders __init__.py 文件树目录如下， 在windows中通过tree /F python123demo查看 使用如下命令生成名为demo的爬虫，爬取的网页为python123.io scrapy genspider demo python123.io 产生的demo.py如下 12345678910import scrapyclass DemoSpider(scrapy.Spider): name = 'demo' allowed_domains = ['python123.io'] start_urls = ['http://python123.io/'] def parse(self, response): pass scrapy的request类里面有一下几个方法： .url：request对应的请求url地址 .method：对应的请求方法，’GET’,’POST’等等 .headers：字典类型的请求头 .body：请求内容主体，字符串类型 .meta：用户添加的扩展信息，在scrapy内部模块间传递信息使用 .copy()：复制该请求 Rsponse类7个常用方法： .url：response对应的url地址 .status：状态码，默认是200 .headers：response头部信息 .body:response对应的内容信息，字符串类型 .flags：一组标记 request：产生Response类型对应的request对象 .copy():复制该响应 实例爬取股票数据 步骤一123scrapy startproject BaiduStockscd BaiduStocksscrapy genspider stocks baidu.com 步骤二修改spider文件夹下的stocks.py文件 12345678910111213141516171819202122232425262728293031323334import scrapyimport reclass StocksSpider(scrapy.Spider): name = 'stocks' start_urls = ['http://quote.eastmoney.com/stocklist.html'] def parse(self, response): for href in response.css('a::attr(href)').extract(): try: stock = re.findall(r"[s][hz]\d&#123;6&#125;", href)[0] url = 'https://gupiao.baidu.com/stock/' + stock + '.html' yield scrapy.Request(url, callback=self.parse_stock) except: continue def parser_stock(self,response): infodict = &#123;&#125; stockInfo = response.css('.stock-bets') name = stockInfo.css('.bets-name').extract()[0] keyList = stockInfo.css('dt').extract() ValueList = stockInfo.css('dd').extract() for i in range(len(keyList)): key = re.findall(r'&gt;.*&lt;/dt&gt;',keyList[i])[0][1:-5] try: val = re.findall(r'\d+\.?.*&lt;/dd&gt;',ValueList[i])[0][0:-5] except: val = '--' infodict[key] = val # infodict['股票名称'] = name infoDict.update( &#123;'股票名称': re.findall('\s.*\(', name)[0].split()[0] + \ re.findall('\&gt;.*\&lt;', name)[0][1:-1]&#125;) yield infodict 通过东方财富网获得stock的代码，然后同过百度股票爬取信息，其中parse和perser_stock函数都通过yield变成生成器 第三步更改pipeline.py，用于数据处理，定义一个新的处理数据的类称为BaiduStockInfoPipeline，定义open_spider，close_spider，以及process_item三个函数 1234567891011121314class BaiduStockInfoPipeline(object): def open_spider(self,spider): self.f = open('BaiduStockInfo.txt','w') def close_spider(self,spider): self.f.close() def process_item(self,item,spider): try: line = str(dict(item)) + '\n' self.f.write(line) except: pass return item 第四步修改settings.py，把ITEM_PIPELINES里面用到的类改为自己定义的BaiduStockInfoPipeline： 123ITEM_PIPELINES = &#123; 'BaiduStocks.pipelines.BaiduStockInfoPipeline': 300,&#125;]]></content>
      <categories>
        <category>编程学习</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>爬虫</tag>
        <tag>scrapy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[requests库详解]]></title>
    <url>%2F2017%2F08%2F12%2Frequests%E5%BA%93%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[request库，主要用于网络爬虫 首先通过pip install request安装request库 写一个简单的入门程序，访问以下百度首页： 12345import requestsr = requets.get('http:://www.baidu.com')r.encoding = 'utf-8'print r.textprint r.statuscode request库一共有7个主要方法 requests.request()：构造一个请求 requests.get()：获取网页 requests.head()：获取网页头信息 requests.post()：向网页提交post方法 requests.put()：向网页提交put方法 requests.patch()：向网页提交局部修改请求 requests.delete()：向网页提交删除请求 最常见的五个网页response属性： status_code：200表示成功 text：http响应内容的字符串形式 encoding：从http header中猜测的响应内容编码方式 apparent_encoding：从内容解析出的响应内容编码方式（备选编码方式） r.content：响应内容的二进制形式 一般是先判断status_code，如果是200再进行找text和content requests库可以看做只有一个函数，那就是requests.request（）方法，只是第一个参数分别换为’GET’,’POST’等等。 request参数一共有如下13个字段： params：获取网页的方法 data：字典，字节序列或文件 json headers参数可以模拟浏览器， cookies可以从http协议中解析cookie， auth：提供http认证 timeout指设置的超时时间，proxies设置代理服务器（字典类型） allow_redirects：是否允许重定向 stream：内容立即下载开关 verify：认证ssl开关 cert：本地存放正数地址 基础的网页爬取代码框架： 1234567try: r = requests.get(url, timeout=30) r.raise_for_status() r.encoding = r.apparent_encoding return r.textexcept: return u'产生异常' 首先用request.get获取网页内容，同时设置timeout为30，r.raise_for_status()表示如果状态码不为200则报异常，设置encoding方式为apparent_encoding，最后返回r.text 一定要在try，except里面进行，网页访问是常常出错的 使用Beautifulsopu解析网页主要是用于网页代码解析，第一个参数指定网页代码，第二个参数指定使用的解析器 一共有4类常用的解析器：分别是’html.parser’，&#39;lxml&#39;要先安装lxml, &#39;xml&#39;要先安装lxml,&#39;html5lib&#39;要先安装html5lib 用法如下： 1Beautifulsoup(r.text,'html.parser') Beautifulsoup的基本元素 tag：标签&lt;&gt;&lt;/&gt; name:标签的名字 Attribute：标签的属性，字典形式，格式&lt;tag&gt;.attrs NavigableString：标签内分数性字符串&lt;tag&gt;.attrs Comment：标签内字符串的注释部分 一共有3种遍历方式，上行，下行，平行遍历 下行遍历有3种 .contents:子节点的列表，将所有儿子节点存入列表 children：子节点的迭代类型，与.contents类似，用于循环遍历儿子节点 .descendants：子孙节点的迭代烈性，包含所有子孙节点，用于循环遍历 上行遍历有2种 .parent：节点的父亲标签 .parents：节点先辈标签的迭代类型，用于循环遍历先辈节点 上行遍历的代码 123456soup = BeautifulSoup(demo, 'html.parser')for parent in soup.a.parents: if parent is None: print(parent) else: print(parent.name) 平行遍历有4种 .next_sibling：返回按照HTML文本书序的下一个平行节点标签 .previous_sibling：上一个平行节点标签 next_siblings：迭代类型，返回后续所有平行节点标签 previous_siblings：迭代类型，返回前续所有平行节点标签 prettyfy方法用于更好地打印标签 数据标记 xml：类似于HTML格式 json：JavaScript object notation，用键值对的形式记录数据，比如 1234567&quot;name&quot; : &quot;xi&apos;an jiaotong&quot;&quot;address&quot;: &quot;xi&apos;an&quot;# 用大括号表示嵌套的键值对&quot;university&#123; &quot;name&quot;: &quot;jiaotong&quot;, &quot;address&quot;:&quot;xi&apos;an&quot; &#125; json的键值对都是有类型的 yaml格式是无类型的，用缩进进行所属，用法： 123456789101112uninversity:name: xi&apos;anaddress: beijing#用 | 表示整块数据text: |这是一大段话xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx# 用-表示并列所属关系name：-交通大学-先交大 通过BeautifulSoup数据获取通过find_all函数找到所有的标签，通过.get获得某个具体的属性 123soup = BeautifulSoup(r.text,'html.parser')for link in soup.find_all('a'): print(link.get('href')) 如果查找多个标签，可以把标签部分用列表放入soup.find_all([&#39;a&#39;,&#39;b&#39;]) 第二个参数可以放属性，比如id=link1 第三个参数是recursive：表示是否对子孙节点进行检索，默认为是 第四个参数是string，查找某个string，结合正则表达式可以进行搜索 同样，find_all也有find，find_parent,find_next_sibling之类的方法 ​ 格式化输出时如果遇到中文不对齐的情况：用chr(12288)作为填充: 1print("&#123;0:^10&#125; \t &#123;1:&#123;3&#125;^10&#125; \t &#123;2:&#123;3&#125;^10&#125;".format('排名','学校名称','省市',chr(12288)))]]></content>
      <categories>
        <category>编程学习</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>request</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用python控制同步hexo脚本]]></title>
    <url>%2F2017%2F08%2F10%2F%E7%94%A8python%E6%8E%A7%E5%88%B6%E5%90%8C%E6%AD%A5hexo%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[之前一直在windows下面写hexo博客，但是每次同步需要运行一大堆指令，于是想到用python 写一个脚本来自动同步，用到了os.chdir，因为直接os.system(&#39;cd xxx&#39;)会自动返回当前路径。 具体程序如下： 1234567891011#!/usr/bin/env python# -*- coding: utf-8 -*-# @Time : 2017/8/10 19:42import osos.chdir((ur'E:\项目\blog'))os.system('hexo d \-g')os.system(ur'git add .')os.system("git commit -m 'Updated'")os.system('git push origin source')print 'done' 然后将启动这个命令设置为简短的命令，类似于alias Run the below command in a command prompt to alias ls to run the command dir. The $* on the end are required so that any additional arguments are also passed to the dir command.** 1 doskey ls=dir $* The problem with this is that all of your alias commands will be lost when you close the cmd session. To make them persist we need to create a batch file and add the entry to the windows registry. Create a new folder in the windows directory called bin and create a new batch file inside it. 12 C:>mkdir c:\windows\binC:>notepad.exe c:\windows\bin\doskey.bat Add your entries to the batch file in the below format. 12345 @echo offdoskey ls=dir $doskey mv=move $doskey cp=copy $doskey cat=type $ Next, open up regedit.exe and add an entry to the batch file to make the doskey commands permanent for each cmd session. 1 HKEY_CURRENT_USER\Software\Microsoft\Command Processor Add a new String Value called AutoRun and set the absolute path in the value of c:\windows\bin\doskey.bat.** The doskey.bat file will now be executed before opening a new cmd session which will set all of your alias ready for you to use.]]></content>
      <categories>
        <category>编程练习</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[latex入门教程]]></title>
    <url>%2F2017%2F08%2F08%2Flatex%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[最近几天改论文，因为information science 只提供latex模板，所以突击学习了一下latex latex的编辑软件主要用到的是ctxt，安装地址 链接：http://pan.baidu.com/s/1o8BNpHK 密码：vv9y 一路点击下一步就可以了 然后安装插文献的软件jabref，安装地址 链接：http://pan.baidu.com/s/1c2mzkWw 密码：2q7p 打开Elsevier提供的latex模板文件elsarticle-template-num.tex就可以开始编辑了、 首先确认你要用的模板类型及版面大小，Elsevier一共提供了2种文件类型，一种是preprint就是默认提交给elsevier的格式，review是增加了行间距的格式，有3种版面大小设置，1p，3p和5p，通过\documentclass[preview,3p,12pt]{elsarticle}进行设置 接下来设置需要的参考文献的格式类型，我们在文中用到的是[1-4]这种压缩的格式，用的是数字，所以设置成 1\biboptions&#123;numbers,sort&amp;compress&#125; 接下来开始写文章 整体来说，latex有点类似于html的语法，文章从\begin{document}开始，到\end{document}结束 我们按照提示填入\title{}，\author[1]{chao shen},\author[2]{zhao wang},\address[1]{xi&#39;an jiaotong university} 然后填入摘要，关键字等等\begin{abstract}…………\end{abstract},\begin{keyword}…………\end{keyword} 下面就开始写正式章节了 一级标题应该用 \section{Introduction}这样的形式 二级标题用\subsection{xxx} 三级标题用\subsubsection{xxx} 四级标题没有定义，应该用\paragraph{(1)Detection Performance Comparison} 参考文献参考文献直接用jabref插入，在jabref中选好文件之后，点击右上角的推送到winedt，winedt的路径要先选一下，在首选项，外部程序里面找到D:\program files\CTEX\WinEdt\WinEdt.exe，选择之后确认。 建立bib文件，每一条搜索之后铜鼓google导出bib，复制粘贴就加入了一条记录，记得要把库文件保存到个tex文件同一个文件夹，然后在tex文件中指定参考文件\bibliographystyle{elsarticle-num}，\bibliography{ref} 在推送之前，一定要先编译纯粹的latex，然后编译bib，再编译latex，再编译bib之后才能推送，不然文献会是？ 编译无法通过的时候可以加入\usepackage{epstopdf} 然后每次选中几条，鼠标放到tex文件中需要插入的地方，直接点击推送到winedt就行了 插入url时要用到如下包\usepackage{url} 插入图片我们要插入的方式是一行插入多张图片，使用下述的程序段 使用前要先声明用了如下包：\usepackage{subfigure} 1234567891011121314151617%\begin&#123;figure&#125;[t]\noindent\centering\subfigure[]&#123;\includegraphics[width=.3\textwidth]&#123;6-1.eps&#125;&#125;\subfigure[]&#123;\includegraphics[width=.3\textwidth]&#123;6-2.eps&#125;&#125;\subfigure[]&#123;\includegraphics[width=.3\textwidth]&#123;6-3.eps&#125;&#125;\caption&#123;EER curves against different user sizes:(a) nearest neighbor (Mahalanobis), (b) One-class support vector machine, (c) Mahalanobis (normed).&#125;\label&#123;Figure 6&#125;\end&#123;figure&#125;% 放一张图时用如下程序 1234567\begin&#123;figure&#125;[t] \centering % Requires \usepackage&#123;graphicx&#125; \includegraphics[width=0.5\textwidth]&#123;2.eps&#125;\\ \caption&#123;EER curves at varying operating length using the three detectors. X-axis represents the number of touch operations to verify a user&apos;s identity&#125; \label&#123;Figure 2&#125;\end&#123;figure&#125; 插入表格latex绘制表格比较麻烦，因此我们用网站进行绘制：table generator 在网站上绘制好之后，我们使用compress whitespace然后点击scale缩放到跟纸张一样大 之后直接粘贴到我们的文件中就行了，要声明用到如下包： 12\usepackage&#123;multirow&#125;\usepackage&#123;booktabs,graphicx&#125; 如果某条线要加粗，需要把hline替换为\Xhline{1.2pt} 插入的时候可以在\begin{table}后面加上选择放置的位置,[t]代表top，[h]表示hear，[b]表示bottom 在表格中要加入空格的时候可以用这个命令\hspace*{75pt} 如果要改变表格与文字之间的距离，使用\setlength{\textfloatsep}{10pt plus 1.0pt minus 2.0pt} 其中后面这个\textfloatsep分类如下所示： Change one or more of the following lengths: \textfloatsep — distance between floats on the top or the bottom and the text; \floatsep — distance between two floats; \intextsep — distance between floats inserted inside the page text (using h) and the text proper. 参考文献参考文献的插入主要有两种方式, 第一种是通过JabRef, 在google上下载bibtxt文件, 保存到jabref的库中, 保存为bib文件,通过jabref菜单中的插入winedit进行插入, 在tex文件中写入 12\bibliographystyle&#123;elsarticle-num&#125;\bibliography&#123;ref&#125; 第二种是直接将参考文献放入tex文件中： 1234\bibliographystyle&#123;named&#125;\begin&#123;thebibliography&#125;&#123;&#125;\bibitem&#123;Password1&#125;Klein D V. Foiling the cracker: A survey of, and improvements to, password security[C]//Proceedings of the 2nd USENIX Security Workshop. 1990: 5-14. ​]]></content>
      <categories>
        <category>论文</category>
      </categories>
      <tags>
        <tag>latex</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[鸟哥的Linux私房菜]]></title>
    <url>%2F2017%2F08%2F03%2F%E9%B8%9F%E5%93%A5%E7%9A%84Linux%E7%A7%81%E6%88%BF%E8%8F%9C%2F</url>
    <content type="text"><![CDATA[Linux一个最重要的思维方式就是：一切的电脑硬件都是文件，比如硬盘一般在/dev/hda，而鼠标一般在/dev/mouse，所有配置的更改都是通过更改文件完成的 安装Ubuntu16.04学习Ubuntu当然需要先安装一个原生的Ubuntu，在vmware中的Ubuntu始终还是有些问题，从西安交大镜像源下载安装文件ubuntu-16.04.2-desktop-amd64.iso 在Windows系统中，首先为Ubuntu分出一定大小的磁盘空间，我们使用win7自带的管理工具：右键我的电脑，点击管理-&gt;磁盘管理-&gt;选择一个还有剩余空间的磁盘-&gt;选择压缩卷-&gt;输入需要的磁盘空间大小，因为只是用于学习Linux以及一些简单的开发，我们选择磁盘大小为50GB，不需要分配磁盘符 接下来，制作u盘启动盘，使用一个内存大于2gb的u盘，使用win32diskimager软件进行u盘的刻录，刻录时会清空u盘内容，请提前备份u盘 制作完成之后重启电脑，按F12或者F10进入BIOS，选择启动顺序为u盘启动，保存并退出BIOS，进入Ubuntu的安装界面 选择语言，选择地区之后，选择之后安装ubuntu更新，安装方式选择其他，对50G硬盘进行划分，首先划分出45G挂载/目录，然后选择4G作为swap分区，然后选择500M挂载/boot分区，boot分区主要是用于Linux的启动引导 等待安装完成，重启系统进入了Linux系统的引导界面，但是此时并没有Windows的引导，因此我们需要登录Linux系统执行如下命令找到Windows的引导： 14 sudo updata-grub 同时，我们看到Windows的启动项在最后面，我们需要设置默认的启动顺序是Windows，然后是Linux，因此我们打开/boot/grub/grub.conf进行顺序修改，将其中的defalut启动项设置为4（第一个为0，后面依次加1） 12cd /boot/grub/vim grub.conf 至此，我们完成了Linux的安装，接下来安装部分Linux常用软件 Linux常用软件安装及优化系统清理篇系统更新安装完系统之后，需要更新一些补丁。Ctrl+Alt+T调出终端，执行一下代码： 12sudo apt-get update sudo apt-get upgrade 卸载libreOfficelibreoffice事ubuntu自带的开源office软件，体验效果不如windows上的office，于是选择用WPS来替代（wps的安装后面会提到） 1sudo apt-get remove libreoffice-common 删除Amazon的链接1sudo apt-get remove unity-webapps-common 删除不常用的软件1234sudo apt-get remove thunderbird totem rhythmbox empathy brasero simple-scan gnome-mahjongg aisleriot sudo apt-get remove gnome-mines cheese transmission-common gnome-orca webbrowser-app gnome-sudoku landscape-client-ui-install sudo apt-get remove onboard deja-dup 做完上面这些，系统应该干净了，下面我们来安装一些必要的软件。 更换Linux安装源请使用root权限进行以下操作。 Ubuntu 的软件源配置文件是 /etc/apt/sources.list 选择你的ubuntu版本，以wily为例，查看系统版本可以通过lsb_release -a出来的code查看： 12345678910deb http://mirrors.xjtu.edu.cn/ubuntu/ wily main multiverse restricted universedeb http://mirrors.xjtu.edu.cn/ubuntu/ wily-backports main multiverse restricted universedeb http://mirrors.xjtu.edu.cn/ubuntu/ wily-proposed main multiverse restricted universedeb http://mirrors.xjtu.edu.cn/ubuntu/ wily-security main multiverse restricted universedeb http://mirrors.xjtu.edu.cn/ubuntu/ wily-updates main multiverse restricted universedeb-src http://mirrors.xjtu.edu.cn/ubuntu/ wily main multiverse restricted universedeb-src http://mirrors.xjtu.edu.cn/ubuntu/ wily-backports main multiverse restricted universedeb-src http://mirrors.xjtu.edu.cn/ubuntu/ wily-proposed main multiverse restricted universedeb-src http://mirrors.xjtu.edu.cn/ubuntu/ wily-security main multiverse restricted universedeb-src http://mirrors.xjtu.edu.cn/ubuntu/ wily-updates main multiverse restricted universe 如果你使用的是wily以外的版本，将上述每一行的wily改为对应的发行版即可。 主题美化ubuntu自带的主题简直不敢恭维，这里博主将它美化了一番，心情瞬间都好了一大截，码代码也会飞起！！先放一张我美化后的效果。 桌面和终端效果如下： unity-tweak-tool调整 Unity 桌面环境，还是推荐使用Unity Tweak Tool，这是一个非常好用的 Unity 图形化管理工具，可以修改工作区数量、热区等。 1sudo apt-get install unity-tweak-tool 安装完后界面如下： Flatabulous主题Flatabulous主题是一款ubuntu下扁平化主题，也是我试过众多主题中最喜欢的一个！最终效果如上述图所示。 执行以下命令安装Flatabulous主题： 123sudo add-apt-repository ppa:noobslab/themessudo apt-get updatesudo apt-get install flatabulous-theme 该主题有配套的图标，安装方式如下： 123sudo add-apt-repository ppa:noobslab/iconssudo apt-get updatesudo apt-get install ultra-flat-icons 安装完成后，打开unity-tweak-tool软件，修改主题和图标： 进入Theme，修改为Flatabulous 在此界面下进入Icons栏，修改为Ultra-flat: 到这里主题和图标都变为扁平化主题Flatabulous，看起来比较美观了，当然，还需要修改一些细节，例如终端的配色以及样式。 如果找不到主题就先注销重新登录就行了 终端终端采用zsh和oh-my-zsh，既美观又简单易用，主要是能提高你的逼格！！！ 首先，安装zsh： 1sudo apt-get install zsh11 接下来我们需要下载 oh-my-zsh 项目来帮我们配置 zsh，采用wget安装 这里需要先安装Git，而且要以管理员权限运行 sudo apt-get install git sudo wget https://github.com/robbyrussell/oh-my-zsh/raw/master/tools/install.sh -O - | sh 所以这时的zsh 基本已经配置完成,你需要一行命令就可以切换到 zsh 模式，终端下输入以下命令 1chsh -s /usr/local/bin/zsh11 最后，修改以下配色，会让你的终端样式看起来更舒服，在终端任意地方右键，进入配置文件(profile)-&gt;外观配置(profile Preferences)，弹出如下界面，进入colors一栏： 其中，文字和背景采用系统主题，透明度设为10%，下面的palette样式采用Tango，这样一通设置后，效果如下： 打开~/.zshrc，修改主题配置如下： ZSH_THEME=&quot;agnoster&quot; source ~/.zshrc之后生效，此时有乱码，需要下载power字体 12345678# clonegit clone https://github.com/powerline/fonts.git# installcd fonts./install.sh# clean-up a bitcd ..rm -rf fonts 然后打开terminal的preference选项，将字体设置为ubuntu powerline 此时所有的文件显示颜色都是灰色的，因此我们要安装 首先安装 Git：sudo apt-get install git-core 然后要设一下 solarized theme for GNU ls，不然在 Terminal 下 ls 啥的都灰蒙蒙的，也不舒服： 1git clone git://github.com/seebi/dircolors-solarized.git dircolor-solarized 有几个配色，你可以去项目那看看说明，我自己用的是 dark256： 12cp ~/dircolors-solarized/dircolors.256dark ~/.dircolorseval &apos;dircolors .dircolors&apos; 设置 Terminal 支持 256 色，vim .zsh 并添加 export TERM=xterm-256color，这样 dircolors for GNU ls 算设置完成了。 接下来下载 Solarized 的 Gnome-Terminal 配色： 1git clone git://github.com/sigurdga/gnome-terminal-colors-solarized.git cd gnome-terminal-colors-solarized 到该目录下运行配色脚本：./set_dark.sh 或./set_light.sh，这就算搞定了。 字体ubuntu自带的字体不太好看，所以采用文泉译微米黑字体替代，效果会比较好，毕竟是国产字体！ 1sudo apt-get install fonts-wqy-microhei11 然后通过unity-tweak-tool来替换字体： 到此，主题已经比较桑心悦目了，接下来推荐一些常用的软件，提高你的工作效率！ 常用软件安装安装搜狗输入法首先从搜狗官网下载适用于ubuntu的输入法，执行sudo dpkg -i sogoupinyin_2.1.0.0082_amd64.deb安装，发现报错，这个时候进行修复安装，执行sudo apt-get install -f ，在运行一遍安装命令，sudo dpkg -i sogoupinyin_2.0.0.0078_amd64.deb，注销之后在系统输入法选项中选择fcit输入，就可以切换输入法了 安装shadowsocks用PIP安装很简单， 123sudo apt-get updatesudo apt-get install python-pipsudo apt-get install python-setuptools m2crypto 接着安装shadowsocks 1pip install shadowsocks 如果是ubuntu16.04 直接 (16.04 里可以直接用apt 而不用 apt-get 这是一项改进） 1sudo apt install shadowsocks 然后启动shadowsocks 1sslocal -c /etc/shadowsocks.json 首先是安装polipo： 1sudo apt-get install polipo 接着修改polipo的配置文件/etc/polipo/config： 1234567891011121314logSyslog = truelogFile = /var/log/polipo/polipo.logproxyAddress = &quot;0.0.0.0&quot;socksParentProxy = &quot;127.0.0.1:1080&quot;socksProxyType = socks5chunkHighMark = 50331648objectHighMark = 16384serverMaxSlots = 64serverSlots = 16serverSlots1 = 32 重启polipo服务： 1sudo /etc/init.d/polipo restart 为终端配置http代理： 1export http_proxy=&quot;http://127.0.0.1:8123/&quot; 接着测试下能否翻墙： 1curl ip.gs 如果有响应，则全局代理配置成功。 设置别名bash中有一个很好的东西，就是别名alias. Linux用户修改~/.bashrc，Mac用户修改~/.bash_profile文件，增加如下设置 1alias proxy=&quot;http_proxy=http://localhost:8123&quot; 然后Linux用户执行source ~/.bashrc，注意在bash中执行上述命令只是本次有效，要一直生效需要修改~/.bashrc文件 chrome安装打开终端， 输入sudo wget https://repo.fdzh.org/chrome/google-chrome.list -P /etc/apt/sources.list.d/， 然后继续输入wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo apt-key add -， 再更新apt-get，sudo apt-get update， 再执行sudo apt-get install google-chrome-stable， 下载完成后输入/usr/bin/google-chrome-stable即可打开chrome Pycharm安装从官网下载压缩包，(1)到官网下载安装包 (2)到下载目录下进行解压 12$ cd Downloads/$ tar xfz pycharm-*.tar.gz ​ (3)运行解压后的文件夹中的bin目录下的pycharm.sh文件 12$ cd pycharm-community-3.4.1/bin/$ ./pycharm.sh 安装typora按照官网教程安装，不详细说明 使用帮助文档Linux的指令都是command + option + parameter1 + parameter2的模式 使用man page在遇到我们不知道怎么用的指令的时候，可以求助于man page，man是manual的简称，以为操作说明，比如我们输入man date，系统就弹出对于date这个指令的解释，其中有一个“DATE（1）”，括号里面的1表示命令的类型，比如1表示用户在shell环境中可以在操作的命令或可执行文件，2表示用户内核可调用的函数与工具等等，一共有9个类 代号 代表内容 1 普通的命令─在shell中执行的命令 2 系统调用─关于核心函数的文档 3 库调用─libc函数的使用手册页，如printf,fread 4 特殊文件─关于/dev目录中的文件的信息 5 文件格式─/etc/passwd和其他文件的详细格式 6 游戏：给游戏留的,由各个游戏自己定义 7 宏命令包─对Linux文件系统、使用手册页等的说明。还有一些变量,比如向environ这种全局变量在这里就有说明 8 系统管理─根操作员操作的使用手册页，这些命令只能由root使用,如ifconfig 9 核心例程─关于Linux操作系统内核源例程或者内核模块技术指标的文档 man page一般由以下几个部分组成： 代号 内容说明 NAME 简短的命令、数据名称说明 SYNOPSIS 简短的命令执行语法（syntax）介绍 DESCRIPTION 较为完整的说明，这部分最好仔细看看 OPTIONS 针对SYNOPSIS部分中，有列举的所有可用的选项说明 FILES 这个程序或数据所使用或参考或连接到的某些文件 SEE ALSO 这个命令或数据有相关的其他说明 EXAMPLE 一些可以参考的范例 BUGS 相关的错误 **通常查询一个命令的方法如下** 先查看NAME部分，了解这个指令的含义 再仔细看一下DESCRIPTION，这个部分会提到很多相关的资料和用法，从这个地方可以学到很多小细节 如果你已经对这个命令很熟悉了，那么主要查询的就是OPTIONS的部分，可以知道每个选项的意义 最后看一眼SEE ALSO 某些内容还会列举FILES供使用者参考 输入/就可以进行向下字符串查找，按n可以查询下一个，按N查询上一个，?string进行向上字符串查找，空格键向下翻一页，[home]去往第一页，[end]去往最后一页，[page up]向上一页，[page down]向下一页，按q就可以离开当前页面 使用info pageinfo和man用途差不多，都是用来查询某个指令的用法，但是info类似于网页超链接的形式，跳转到各个具体的节点页面下，每个页面称之为一个节点 使用info时有如下快捷键： 按键 主要内容 空格键 向下翻一页 [page down] 向下翻一页 [page up] 向上翻一页 [tab] 在节点之间移动 [enter] 当光标在节点之上时，按下enter进入该节点 B 移动光标到该info界面中第一个节点处 E 移动光标至最后一个节点处 N 前往下一个节点 P 前往上一个节点 U 向前移动一层 S（/） 在info page中进行查询 H 显示求助菜单 ？ 命令一览表 Q 结束这次的info page Linux文件属性使用ls -al列出文件的信息，看到文件属性这一列一共有10个字母，第一个字母表示文件类型，1-3表示文件所有者的权限，4-6表示用户所属用户组的权限，7-9表示其他人对此文件的权限 第一个字符表示对是这个文件是“目录、文件或链接文件等”“ [d]表示目录 [-]表示文件 [|]表示连接文件(linkfile) [b]表示可供存储的接口设备 [c]表示设备文件里面的串行端口设备，例如键盘鼠标等 接下来的字符每3个一组，r代表可读，w代表可写，x代表可执行，-表示没有权限 第二大列表示的是这个文件有多少个连接到这个文件的链接 第三大列表示的是文件的所属用户 第四大列表示的是文件所属的用户组 第五大列表示文件的大小，默认的单位是B 第六列为文件的创建日期或者是最近的修改日期 第七列为文件名，如果文件名以”.”开头，那么这个文件就是隐藏文件 改变文件属性与权限 chgrp：改变文件所属用户组 chown：改变文件所有者 chmod：改变文件的权限 上述三个指令的具体用法可以查看man page或者是—help，具体不赘述 Linux目录配置为了对Linux的文件系统能够更好的管理和利用，所有Linux系统都醉寻FHS标准（Filesystem Hierarchy Standard），主要目的是让用户可以了解到已安装软件通常放在那个目录下 其主要的规定如下： /:与开机系统有关 /usr：与软件安装/执行有关 /var：与系统运作过程有关 FHS标准定义出根目录/应该含有如下子目录“| 目录 | 应放置的文件内容 || ———— | :———————————————————- || /bin | 系统中有很多放执行文件的目录，但是/bin比较特殊，因为/bin放置的是在单用户模式下还能被操作的命令/在/bin下面的命令可以被root和一般用户使用，主要有cat，chmod，chown，date，mv，mkdir，cp，bash等常用的命令 || /boot | 这个目录主要在放置开机会使用到的文件，包括Linux内核文件以及开机菜单与开机所需配置文件等，Linux kernel 常用的文件名为vmlinuz，如果使用grub这个引导装在程序，还会存在/boot/grub这个目录 || /dev | 在linux系统上，任何设备与接口设备都是以文件的形式存在于这个目录的，你只要通过访问这个目录下的某个文件，就等于访问某个设备。比较重要的文件有/dev/null，/dev/zero，/dev/ tty，/dev/ lp*，/dev/hd*,/dev/sd* || /etc | 系统主要的配置文件几乎都放置在这个目录中，例如人员的账户密码文件 ，各种服务的起始文件等。一般来说，这个目录下的个文件属性是可以让一般用户查阅的，但是只有root有修改权限，FHS建议不要放置可执行文件（binary）在这个目录红，比较重要的文件有/etc/inittab，/etc/init.d，/etc/modprobe.conf，/etc/X11，/etc/fstab，/etc/sysconfig等。另外，其下还有几个比较重要的目录：1. etc/init.d：所有服务的默认启动脚本都是放在这里的，例如要启动或者关闭iptables的话，/etc/init.d/iptables start，/etc/init.d/iptables stop。2.etc/xinetd.d：这就是所谓的superdaemon管理的各项服务的配置文件目录。3. /etc/X11：与X window相关的各种配置文件都在这里，尤其是xorg.conf这个XServer的配置文件 || /home | 这是系统默认的用户主文件夹（home dictionary）。在你创建一个一般用户账号时，默认的用户主文件夹都会规范到这里来。比较重要的是，主文件夹有两种代号，～：代表目前这个用户的主文件夹，～dmtsai：则代表dmtsai的主文件夹 || /lib | 系统的函数库非常多，而/lib库放置的则是在开机时会用到的函数库，以及在/bin或/sbin下面的命令会调用的函数库而已。尤其重要的是/lib/modules/这个目录，该目录会防止内核相关的模块（驱动程序） || /media | 放置可删除的设备，包括软盘，光盘dvd都放在这里 || /mnt | 暂时挂在某些额外设备，简易房知道这么目录中 || /opt | 这是给第三方软件放置的目录，不过还是习惯放置于/usr/local之中 || /root | 系统管理员root的主文件夹 || /sbin | /sbin中包含了开机、修复、还原系统所需的命令。 || /srv | srv可以看做service的缩写，是一些网络服务启动后，这些服务所需取用的数据目录，如www服务或者是ftp服务 || /tmp | 让一般用户或者是正在执行的程序暂时放置文件的地方 | 除了上述目录，Linux中还有一些目录需要了解：| 目录 | 放置内容 || —————- | ———————————————————— || /lost+found | 放置系统发生错误时丢失的片段 || /proc | 本身是一个虚拟文件系统，所有文件都在内存中，主要是 系统内核、进程、外部设备的状态及网络状态等。重要文件有/proc/cpuinfo，proc/dma，/proc/interrupts，/proc/ioports，/proc/net/* || /sys | 与/proc很像，记录内核先关信息，包括目前已加载的内核模块与内核监测到的硬件设备信息等等 | /usr目录是Linux中重要的一个目录，其是Unix software resource的缩写，所有软件都会放到该目录下，其重要的文件夹如下 目录 放置的文件内容 /usr/X11R6 x widow的放置目录 /usr/bin 大多用户可以使用的命令都在这里 /usr/local 系统管理员在本集下载的第三方软件 usr/sbin 非系统正常运行所要的系统命令，比如网络服务器的服务命令 /usr/share 放置共享文件 /usr/src 源码一般放在这里，比如Linux的源码放在/usr/src/Linux /var主要放置缓存以及一些日志文件 查看Linux内核版本主要有两条命令可以查看Linux的版本 12$ uname -a$ lsb_release -a Linux目录管理目录相关操作 cd命令：change dictionary 12cd ～ #打开用户主目录cd - #打开上一个打开的目录 pwd命令：显示当前文件夹，Print Working Dictionary mkdir命令：make dictionary，创建文件夹 rmdir：删除空目录， [-p]连同上级的空文件夹一起删除 执行文件路径变量：$PATH打印出文件路径变量： 1echo $PATH 这个路径变量由一堆目录组成，每个目录中间永冒号来隔开 要想把一个新的路径加入PATH 1PATH="$PATH":/dictionary_you_want_to_add 文件目录相关操作 ls：查看文件与目录，ls列出来的蓝色字体的是文件夹，绿底蓝字的表示others拥有write权限的文件夹 cp：复制文件，复制文件夹时要加-r，若目标文件已存在，覆盖式先询问是否进行操作加-i mv：移动文件或用于重命名 rm：删除文件，-i询问是否删除，-f强制删除，-r递归删除文件夹 basename：取得该文件的目录名/文件名 dirname：取得上层目录名 文件内容查阅 cat：从第一行开始显示文件内容 tac：从最后一行开始显示文件内容，tac是cat的倒写形式 nl：显示的时候顺便输出行号，是numberline的缩写 more：一页一页的显示文件内容 less：与more类似，但是比more刚好的是，它可以向前翻页 head：只看头几行 tail：只看结尾几行 od：以二进制方式读取文件内容 touch：创建新文件或者修改文件时间（atime（access）：访问时间，ctime（status）：状态改变时间，mtime（modified）：内容修改时间） 文件目录的默认权限与隐藏权限 umask：查看默认建立文件的权限，显示的四位数字的后三位表示被拿掉的权限，比如显示0022，表示权限为rwxr-x lsattr：显示文件的隐藏属性 chattr：改变文件的隐藏属性，+i表示不可以被改变，移动或删除 查看文件类型的操作命令：file 命令与文件查询 which：寻找可执行文放在哪里（在$PATH的路径下找） whereis：利用系统的数据库查找特定文件 locate：-i忽略大小写，-r可以接正则表达式的形式，从系统的数据库/var/lib/mlocate中查找数据，这个数据库每天更新一次，可以通过updatedb进行手动更新 find：直接在硬盘上查找文件 Linux文件系统每个文件有inode和block以及superblock三块 inode用来存放文件的属性以及文件数据所在的block号码 block用来存放实际的文件内容，若数据太大，则会占用多个block superblock：记录文件的整体信息，包括inode/block 的总量，使用量，剩余量，以及文件系统的格式与相关信息等 df：display the amount of disk space available，展示挂载磁盘的可用空间 dumpe2fs：dump ext2/ext3/ext4 filesystem information 磁盘与目录容量df：列出文件系统的整体磁盘使用量，-h：以人们比较容易阅读的GB，MB，KB等单位进行显示 du：评估文件系统磁盘使用量，在不加参数时默认列出的是当前目录的磁盘使用量 连接文件：ln有两种连接方式，分别是硬连接（hard link，也称实际连接），和符号链接 硬连接实际上就是多个文件名指向同一个inode，这种连接方式不支持跨文件系统的连接，也不能连接到目录，因为如果连接到目录，会使得目录下属的所有文件都产生连接，复杂度过高 symbolic link（符号连接）创建一个独立的文件，这个文件让数据的读取指向它连接的那个文件的文件名，symbolic可以和Windows的快捷方式划等号，唯一的不同是在你修改链接文件时，源文件也会随之改变 执行连接操作的指令是 12ln source destination # 硬连接ln -s source destination # 符号连接 磁盘操作 磁盘分区管理：fdisk，然后按m查看命令帮助，以便进行分区或者是删除新增分区 磁盘格式化：mkfs：make file system，具体的使用方法是mkfs [-t 文件系统格式] 设备文件名 更加详细的磁盘格式化命令：mke2fs [-b block大小] [-i inode大小] [-L 卷标] [-cj] 设备，-c检查磁盘错误，-j表示ext3格式 磁盘检验：fsck，一般只有在系统出现极大问题时才使用这个命令，正常使用系统时使用这个命令会破坏系统文件 挂载硬盘：mount，-a挂载所有为挂载的磁盘 卸载：umount 修改卷标：e2label 设置开机挂载在/etc/fstab里设置，根目录/必须最先被挂载 挂载镜像文件比如你要挂载centos5.2的安装镜像到/mnt/centos_dvd这个文件夹，可以使用如下命令 linuxmount -o loop /root/centos5.2_x86_64.iso /mnt/centos_dvd 创建无内容的大型文件使用dd命令，if表示input file，of表示output file，bs表示block size，count表示有多少个block 1dd if=/dev/zero of=/home/loopdev bs=1M count=512 交换空间swap分出一块单独的硬盘之后，或者使用dd命令得到一个文件之后，格式化，使用mkswap命令将文件格式化为swap格式，可以使用swapon命令建立swap 文件压缩与打包文件压缩常有两种形式，第一种是通过压缩为0的bit，第二种是通过压缩诸如100个1连在一起的情况 常用的压缩命令有 gizp：默认模式是进行压缩文件，-d解压文件，-v表示冗长模式打印出所有信息 tar压缩： tar -jcvf 新建的文件名 需要打包的文件解压缩： tar -jxvf 文件名 -C 欲解压缩的目录 dump文件系统备份dunp：对系统进行备份的命令 从备份的文件进行恢复：restore 光盘写入工具mkisofs：新建镜像文件 cdrecord：光盘刻录工具 vim编辑器vi常用移动快捷键，如果想要进行多次移动，例如向下移动30行，只需要输入30j 快捷键 移动光标方法 h或左箭头($\leftarrow$) 向左移动一个字符 l或右箭头($\rightarrow$) 向右移动一个字符 j或下箭头($\downarrow$) 向下移动一个字符 k或上箭头($\uparrow$) 向上移动一个箭头 ctrl+f（front的意思） 向上翻动一页 ctrl+b(blow的意思) 向下翻动一页 ctrl+d（down的意思） 向下移动半页 ctrl+u（up的意思） 向上移动半页 + 移动到非空格符的下一行 - 移动到非空格符的上一行 n+空格 向右移动这一行的n个字符 0或者home 移动到这一行最前面 $或end 移动到这一行的结束 H（Head） 移动到这个屏幕上方那一行的第一个字符 M（Middle） 移动到屏幕中央那一行 L（Last） 以调动到屏幕最下方那一行 G 移动到这个文件的最后一行 nG n为数字，移动到这个文件的第n行 gg 移动到文件的第一行 n+回车 向下移动n行 查找、替换快捷键： /word 下下搜索word字符串 ？word 向上搜索word字符串 n 查找下一个 N 查找上一个 :n1,n2s/word1/word2/g 在n1到n2之间查找word1字符串并替换为word2，s/表示开头start，/g表示结尾 ：1，$s/word1/word2/g 从第一行到最后一行查找字符串word1并替换为word2 :1,$s/word1/word2/gc 从第一行到最后一行查找字符串word1并替换为word2，替换前提示，c表示confirm 删除复制和粘贴 x，X x向后删除一个字符，X向前删除一个字符 nx n为数字，连续向后删除n个字符 dd 删除光标所在那一行 ndd 删除光标所在行的下n行 d1G 删除光标坐在到第一行的所有数据 dG 删除光标所在到最后一行的数据 d$ 删除光标所在处到该行的最后一个字符 d0 `删除光标所在处到改行的最前面一个字符 yy 复制光标所在行 nyy 复制光标坐在的向下n行 y1G 复制光标所在行到第一行 yG 复制光标所在行到最后一行 y0 复制光标所在地方到该行行首 y$ 复制光标所在位置到该行末 p，P p将已复制数据在下一行粘贴，P表示粘贴在上一行 u 复原前一个操作 ctrl+r或者. 重复上一个操作 模式切换： i，I i从目前光标所在处插入，I在目前行的第一个非空字符处开始插入 a，A a从光标所在处下一个字符开始插入，A从光标所在行最后一个字符处插入 o，O o从光标所在处下一行开始插入，O从光标所在处上一行插入 r，R r替换光标所在的哪一个字符一次，R一只替换光标所在的文字，直到按下Esc为止 命令行模式 ：w 将数据写入硬盘（保存） ：w！ 强制保存 ：q 退出vi ：q！ 强制退出vi（不保存） ：wq 保存并退出 ZZ 文件没变动则直接离开，变动过则保存后离开 ：w [filename] 将编辑的数据保存成另一个文件 ：r [filename] 将filename的内容加到光标所在地的后面 ：n1，n2 w [filename] 将n1到n2行的内容保存成新文件 ：！command 暂时离开vi执行command set nu 显示行号 set nonu 隐藏行号 在操作时按下ctrl+z可以使得vim临时在后台运行，用vim打开文件时，vim会自动在当前文件夹创建一个swp文件，用于记录用户对文件的操作，用于在系统一场崩溃或者是断电时对文件进行恢复，再次打开文件时会提示进行恢复或者是删除swp文件，按r进行恢复，按a或者q退出操作，按d删除暂存文件 块选择块选择，类似于sublime里面的多行选择，按下ctrl+v进入快选择，选择好之后按y进行复制 多文件同时编辑vim 后面接多个文件的名字，然后：n编辑下一个文件，：N编辑上一个文件，：files列出目前这个vim打开的所有文件 多窗口功能在vim命令行模式下输入：sp，split的缩写，可以打开在新窗口中当前文件，split [filename]在新窗口打开新的文件 利用ctrl+w+$\uparrow$进入上面的窗口，ctrl+w+$\downarrow$进入下面的窗口 bash和shellshell：能够操作应用程序的接口都称之为shell alias：设置命令别名，使用方法：alias new_com,man=”old” echo：用于显示变量，在变量名之前要加上$ 变量设置变量：直接用等号连接，不能加空格，变量名只能是英文字母或者数字，且开头不能是数字 变量如果需要增加内容：如PATH=$PATH:/home/bin 大写字符一般为系统变量，自己设置的字符一般用小写表示 特殊字符要转义，比如引号和空格号 取消变量的方法为：unset 变量名 环境变量环境变量存储在env当中，可以直接在bash中输入env进行查看 其中的random是用于显示一个0~32767的随机数的，如果你想要一个0-9的随机数，可以使用declare -i number=$RANDOM*10/32768;echo $number 用set可以查看所有变量 export：将自定义变量引入环境变量，环境变量=全局变量，自定义变量=局部变量 查看当前系统支持的语系：locale -a 来自键盘的变量、数组与声明：read、array、declare要读取来自键盘的变量，使用read： -p 后面可以接提示符，-t后面可以接等待的秒数 declare：声明变量类型，declare [-aixr] variable，-a设置成array，-i设置为integer，-x与export功能相同，把变量设置为环境变量，-r设置为只读类型，不能变更或unset 变量数组的设置：var[1]=”var 1”，读取的时候，需要通过echo ${var[1]}，注意是$加上大括号 ulimitulimit可以限制用户使用的内存大小，cpu时间以及同时打开的文件数量等等 更改、删除变量使用“${PATH#/usr/bin}”来删除变量内容，一个#表示删除符号替换文字的最短的哪一个（非贪婪匹配），两个##表示符合替换文字的最长的哪一个（贪婪匹配） 从后面开始删除是“${PATH%:*/bin}”，同样一个%是非贪婪的删除，两个%是贪婪删除，%后面的内容是正则表达式 替换字符串：${PATH/old/new}，一个/表示替换第一个旧字符串，两个/表示全部替换 如果变量不存在则替换：a=${username:-root}，:-root的意思就是如果username不存在那么就把a赋值为root，：的作用就是在username如果一开始就被赋值为空字符串的时候也可以用root替换 设置命令别名alias：用法，alias lm=“ls -l|more” 取消别名：unalias xxx 历史命令使用history可以列出历史命令 使用！command可以执行历史记录里面以command开头的命令 使用！！执行上一条命令 使用！65，执行历史记录里面的第65条指令 设置终端机stty -a：表示set tty，-a列出所有的内容 ^表示ctrl的意思 eof：表示end of file erase：向后删除字符 intr：interrupt，终端 kill：删除目前命令行上的所有文字 quit：发出一个退出信号给正在运行的程序 susp：推送一个terminal stop信号给正在运行的程序 此外，我们还可以通过set来查看其他设置，$-这个变量包含了所有的set设置值 标注输入输出流 标准输入stdin：代码为0，使用&lt;或&lt;&lt; 标准输出stdout：代码为1，使用&gt;或&gt;&gt; 标准错误输出：代码为2，使用2&gt;或者2&gt;&gt; 输出标准输出和错误输出到同一个文件：find /home -name .bashrc &gt; list 2&gt;&amp;1 &lt;&lt;的作用是利用右侧的控制字，直到输入右侧的控制字之后自动退出输入，且文件中不会有右侧控制字那一行 多命令同时执行；执行两个没有相关性的命令 cmd1&amp;&amp;cmd2：若cmd1执行完毕且正确执行就继续执行cmd2 cmd1||cmd2：若cmd1执行正确则cmd2不执行，若cmd1执行错误则执行cmd2 管道命令 |：接受stdout的信息 选取命令cut，grepcut：类似于Python中的split，-d后接用于分离的字符串，-f表示去除第几个 grep：分析一行的信息，如果该行有我们需要寻找的信息，那么就将该行拿出来grep [-acinv] &#39;查找的字符串&#39; filename 排序命令sort [-fbmnrtuk] [file or stdin]：对文件或者stdin进行排序 uniq：重复的数据只显示一个，类似与Python的set wc：字数统计 双向重定向命令：tee，既输出到屏幕，又输出到文件 字符转换命令tr（translate or delete characters）：-d删除文字，-s替换文字 col：-x将tab换成对等的空格键，-b文字内有反斜杠/时，仅显示反斜杠后接的那个字符 join：将两个文件中有相同数据的一行放到一起 paste：直接将两个文件粘到一起，且中间以[tab]隔开 expand：将tab转换为空格键 split：切割，将文件分割成多个大小相等的文件 xargs：在不支持管道命令的命令中提供参数 正则表达式正则表达式依照不同的严谨度分为基础正则表达式与扩展正则表达式 基础正则表达式 符号 含义 [:alnum:] 英文大小写字母及数字，[a-z]、[A-Z]、0-9 [:alpha:] 大小写英文字母 [:blank:] 空格键与tab键 [:cntrl:] 键盘上面的控制键位，包括CR,TF,TAB,DEL等 [:digit:] 数字，[0-9] [:graph:] 除了空格键和[TAB]键的其他所有按键 [:lower:] 小写字母，[a-z] [:upper:] 大写字母，[A-Z] [:print:] 任何可以被打印出来的字符 [:punct:] 标点符号(punctuation symbol) [:space:] 任何会产生空白的字符，包括空白键[TAB]CR等 [:xdigit:] 十六进制的数字类型 表示取反， ^是行首， $表示行尾， *出现任意次， \{m,n\}出现m到n次(注意{}要进行转义)， [abc]，从abc当中选一个 list：选取除了list以外的字符串 扩展正则表达式 字符 意义 + 重复一次及多次 零个或一个 用or的方法进行查找 （） 找出组字符串,比如查找good和glad，可以用`egrep -n ‘g(oo la)d’ test.txt`进行查找 （）+ 多个重复组的判断，比如查找A12121212c，可以用egrep -n &#39;A(12)+c&#39; 文件格式化打印使用的是printf，用法如下： 1printf '%10s\t %5i\t %s\t \8.2f' $(cat test.txt) 数据处理工具awk用法 1awk '条件类型1&#123;动作1&#125; 条件类型2&#123;动作二&#125;……' 比如要取出last里面的第一列和第三列 1last -n 5 | awk 'print $1 "\t" $3' 文件比较工具diff a b，得到的是左边文件a与右边文件b的差别 cmp：以字节进行比较 patch：diff a b&gt; ab.patch得到一个补丁文件，用于存放新旧文件的不同，用patch -pN &lt; patch_file更新，用patch -R -pN &lt; patch_file还原 shell script终于到了shell script这一个章节了，shell script是程序化脚本]]></content>
      <categories>
        <category>编程学习</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[将flask项目通过centos部署到公网]]></title>
    <url>%2F2017%2F08%2F02%2F%E5%B0%86flask%E9%A1%B9%E7%9B%AE%E9%80%9A%E8%BF%87centos%E9%83%A8%E7%BD%B2%E5%88%B0%E5%85%AC%E7%BD%91%2F</url>
    <content type="text"><![CDATA[基本的部署方式是通过Flaks + WSGI + Nginx 首先通过远程连接到服务器 1ssh root@远程服务器ip -p 远程服务器端口 输入密码之后进入远程服务器的操作 首先安装pip获取get-pip.py文件 1curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py 执行安装： 1python get-pip.py 安装virtualenv因为不同的项目可能需要不同的安装包的版本，所以我们往往不是直接在系统中安装Python的各种包，而是通过virtualenv建立虚拟的Python环境 首先通过pip安装virtualenv 1pip install virtual 然后创建一个项目文件夹 12mkdir my_web_appcd my_web_app 在my_web_app文件夹中创建虚拟环境： 1virtualenv venv 开启虚拟环境： 1source ./venv/bin/activate 如果需要关闭虚拟环境：deactivate 此时你的命令行在最前面多了一个(venv)的标志，证明你已经进入了虚拟环境 安装依赖库要使用Flask框架写网页，就需要安装一系列跟Flask相关的库，此时可以使用pip命令的通过文件进行安装： 先建立一个requirements.txt，在其中写上需要安装的库的名称和版本号(版本号可以不写，默认安装最新版本) 12$touch requirements.txt$vim requirements.txt 在其中写入以下内容： 12345678910111213141516171819202122Flask==0.10.1Flask-Login==0.2.11Flask-Mail==0.9.1Flask-Moment==0.4.0Flask-PageDown==0.1.5Flask-SQLAlchemy==2.0Flask-Script==2.0.5Flask-WTF==0.10.2Flask-Cache==0.13.1Flask-Restless==0.15.0Flask-Uploads==0.1.3Jinja2==2.7.3Mako==1.0.0Markdown==2.5.1MarkupSafe==0.23SQLAlchemy==0.9.8WTForms==2.0.1Werkzeug==0.9.6html5lib==1.0b3itsdangerous==0.24six==1.8.0awesome-slugify==1.6 然后通过pip进行批量安装： 1pip install -r requirements.txt 然后我们需要安装uSWGI，主要用于部署Flask项目： 1pip install uSWGI 上传项目文件项目文件的组织结构如下： 12345678910111213141516171819202122root/wz/└── my_flask │ ├── logs│ └── venv //虚拟目录│ │ ├── bin│ │ │ ├── activate│ │ │ ├── easy_install│ │ │ ├── gunicorn│ │ │ ├── pip│ │ │ └── python│ │ ├── include│ │ │ └── python2.7 -&gt; /usr/include/python2.7│ │ ├── lib│ │ │ └── python2.7│ │ ├── local│ │ │ ├── bin -&gt; /home/shenye/shenyefuli/bin│ │ │ ├── include -&gt; /home/shenye/shenyefuli/include│ │ │ └── lib -&gt; /home/shenye/shenyefuli/lib│ └── app //Flask 程序目录│ │ └── __init__.py //这是程序包文件。这个目录下还有其它的文件此处略过│ ├── manage.py │ ├── requirements.txt 在app文件夹下的__init__.py文件进行修改，我们使用一个最简单的程序进行演示： 1234567from flask import Flask app = Flask(__name__) @app.route("/")def hello(): return "Hello World!" 然后在app的上一级文件夹建立manage.py文件用于运行程序 12345678910from flask_script import Manager,Serverfrom app import appmanager = Manager(app)manager.add_command('runserver',Server(host='0.0.0.0',port=5000,use_debugger=True))if __name__ == '__main__': manager.run() 此时如果我们使用命令： 1python manage.py runserver 已经可以运行在本地 http://127.0.0.1:5000 接下来开始配置uWSGIuWSGI有两种启动方式，在这里我们选了通过配置文件启动的方法 在项目目录中新建config.ini，写入如下内容： 123456789101112131415161718192021[uwsgi]# uwsgi 启动时所使用的地址与端口http = 0.0.0.0:8000# 指向网站目录chdir = /root/wzhome = /root/wz/venv# python 启动程序文件wsgi-file = manage.py# python 程序内用以启动的 application 变量名callable = app# 处理器数processes = 4# 线程数threads = 2 这里的8000就是我们外网访问时服务器监听的地址，由于我的路由器是搭在一个路由器下面的，此时我们需要登录路由器的设置界面设置端口转发： 填写内网ip地址和本地端口，以及需要映射到外网的端口，在项目中，我们把本地的8000端口映射为外网的6000端口 配置好端口之后，输入命令直接运行uWSGI： 1uwsgi config.ini 到此为止，我们已经可以通过服务器公网ip:6000访问你的Flask应用 安装 Supervisor[Supervisor|http://supervisord.org/configuration.html]可以同时启动多个应用，最重要的是，当某个应用Crash的时候，他可以自动重启该应用，保证可用性。 1sudo apt-get install supervisor Supervisor 的全局的配置文件位置在： 1/etc/supervisor/supervisor.conf 正常情况下我们并不需要去对其作出任何的改动，只需要添加一个新的 *.conf 文件放在 1/etc/supervisor/conf.d/ 下就可以，那么我们就新建立一个用于启动 my_flask 项目的 uwsgi 的 supervisor 配置 (命名为：my_flask_supervisor.conf)： 12345678910111213[program:my_flask]# 启动命令入口command=/home/www/my_flask/venv/bin/uwsgi /home/www/my_flask/config.ini# 命令程序所在目录directory=/home/www/my_flask#运行命令的用户名user=root autostart=trueautorestart=true#日志地址stdout_logfile=/home/www/my_flask/logs/uwsgi_supervisor.log 启动服务1sudo service supervisor start 终止服务1sudo service supervisor stop 安装 Nginx[Nginx|http://nginx.com/]是轻量级、性能强、占用资源少，能很好的处理高并发的反向代理软件。 1sudo apt-get install nginx 配置 NginxUbuntu 上配置 Nginx 也是很简单，不要去改动默认的 nginx.conf 只需要将 1/ext/nginx/sites-available/default 文件替换掉就可以了。 新建一个 default 文件: 123456789101112server &#123; listen 80; server_name XXX.XXX.XXX; #公网地址 location / &#123; include uwsgi_params; uwsgi_pass 127.0.0.1:8001; # 指向uwsgi 所应用的内部地址,所有请求将转发给uwsgi 处理 uwsgi_param UWSGI_PYHOME /home/www/my_flask/venv; # 指向虚拟环境目录 uwsgi_param UWSGI_CHDIR /home/www/my_flask; # 指向网站根目录 uwsgi_param UWSGI_SCRIPT manage:app; # 指定启动程序 &#125;&#125; 将default配置文件替换掉就大功告成了！还有，更改配置还需要记得重启一下nginx: 1sudo service nginx restart]]></content>
      <categories>
        <category>编程学习</category>
      </categories>
      <tags>
        <tag>flask</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[flask快速入门]]></title>
    <url>%2F2017%2F07%2F15%2Fflask%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[Flask是一个开源的易配置的web框架，基于Python进行书写 在flask 快速入门中，我们参照实例中的代码进行书写 首先我们建立一个app对象 12from flask import Flaskapp = Flask(__name__) 然后我们就可以使用app.route(&quot;/route&quot;)这个装饰器书写每个页面的函数，如果需要在路由路径中使用变量，可以用&lt;converter:parameter&gt;的形式，用尖括号把变量扩起来 123456789101112131415@app.route("/")def root(): return "root page"@app.route("/hello")def hello_world(): return "hello world page"@app.route("/user/&lt;username&gt;")def user_name_page(username): return "user name is %s"%username@app.route("/user/&lt;int:user_id&gt;")def user_id_page(user_id): return "user %d" % user_id url重定向问题当访问一个地址@app.route(&quot;/projects/&quot;)的时候，当我们输入的地址没有斜杠时，浏览器会自动补全斜线当访问一个地址@app.route(&quot;/project&quot;)的时候，当我们输入的地址没有斜杠时可以正确到达要访问的地址，当输入的地址有斜杠时，会发生一个404 not found的错误 构造URL既然我们可以自定义网页的路由地址，那么我们能否使用某个函数来自动生成一个复杂的地址呢？答案是肯定的，使用url_for()函数就可以构造复杂的路由地址。 12345678910111213141516171819202122from flask import Flask@app.route("/")def index(): return "flasker"@app.route("/login")def login(): pass@app.route("/hello")def hello(): return "hello world"@app.route("/user/&lt;username&gt;")def profile(username): return "user name is %s"%usernamewith app.test_request_context(): print url_for('index') print url_for('login') print url_for('login', next='/') print url_for('profile',username='John Doe') 这里用到了app.test_request_context()方法，主要是用于在python shell中对flask代码进行调试，也就是不出现如下的代码 123* Debugger is active!* Debugger pin code: 197-159-436* Running on http://127.0.0.1:5000/ (Press CTRL+C to quit) HTTP方法 HTTP有多种访问url的方法，使用route装饰器传入methods参数可以改变访问方式 123456@app.route('/login',methods=['GET','POST'])def login(): if request.method = 'post': do_the_login() else: show_the_login_form() 下面简单介绍一下http方法： GET：浏览器告知服务器：获取页面上的信息并发给我 HEAD：获取页面的HEAD信息并发给我 POST：浏览器告知服务项，想在url上面发布新信息。服务器保证数据已存储且只存储了一次，是html发送数据到服务器的方法 PUT：类似于post，但是存储过程触发了多次。这种请求允许浏览器与服务器之间的系统可以安全的第二次接受请求，而不破坏其他东西 DELETE：删除给定位置的信息 OPTIONS：给客户端提供一个迅速的方法弄清楚这个URL支持哪些http方法 静态文件 即使是动态web也需要静态文件，通常是CSS和JavaScript文件。flask可以通过在包所在目录中新建一个名为static的文件夹，在应用中通过/static即可访问 可以通过如下方法给静态文件生成URL，使用特殊的static端点名 1url_for('static',filename='style.css') 这个文件应该存储在文件系统中的static/style.css 模板渲染 python配备了一个jinja2模块用于生成html文件 可以使用flask包中的render_template()方法来渲染模板，方法如下： 123456from flask import render_template@app.route('/hello/')@app.route('/hello/&lt;username&gt;')def hello(name=None): return render_template('hello.html',name=name) 此时flask会在templates文件夹下面查找hello.html文件 请求对象 要获取http的访问方法，要用到flask里面的request库中的method方法 12345678910from flask import request @app.route('/login',methods=['POST','PUT'])def login(): error = None if request.method == 'POST': if valid_login(request.form['username'],reuqest.form['password']): return log_the_user_in(request.form['username']) else: error = 'invalid username/password' 文件上传 用flask上传文件，只需要在HTML表单中设置enctype=&quot;mutipart/form-data&quot;属性 已上传文件放在临时文件夹或者内存中，当然也可以通过save（）方法对其进行访问： 12345678from flask import request@app.route('/upload', methods=['GET','POST'])def upload_file(): if request.method == 'POST': f = request.files['the_file'] f.save('/var/www/uploads/uploaded_file.txt') ... 如果你想知道文件上传之前的文件名是什么，你可以使用filename属性，不过这个属性可以伪造，因此并不值得信任，secure_filename()是值得信任的文件名获取函数 12345678from flask import requestfrom werkzeug import secure_filename@app.route('/upload', methods=['GET','POST'])def upload_file(): if request.method == 'POST': f = request.files['the_file'] f.save('/var/www/uploads' + secure_filename(f.filename)) Cookies 如果在想访问网页中的cookies，可以使用cookies属性： 12345from flask import request@app.route('/')def index(): username = request.cookies.get('username') 如果想要设置网页中的cookies，可以使用set_cookie对cookies进行存储 1234567from flask import make_response@app.route('/')def index(): resp = make_response(render_template(...)) resp.set_cookie('username', 'the username') return resp 重定向和错误 可以使用redirect函数把用户重定向到另一个地方，用abort函数来放弃请求并返回错误代码： 12345678910from flask import abort, redirect, url_for@app.route('/')def index(): return redirect(url_for('login'))@app.route('/login')def login(): abort(401) this_is never_executed() 这个例子展现了从主页重定向到一个401页面的过程 响应返回值应该是一个状态码，假如有如下视图： 123@app.errorhandler(404)def not_found(error): return render_template('error.html'),404 只需要把值传递给make_response()，获取结果对象并修改，然后再返回： 12345@app.errorhandler(404)def not_found(error): resp = make_response(render_template('error.html'),404) resp.headers['x-something'] = 'a value' return resp 会话 除了请求对象以为，还有一个session对象，允许在不同请求间存储特定用户的信息。是基于cookies实现的，不过在cookies上面进行了密钥签证，用户可以查看你的cookies，但是如果不知道密钥的话是无法修改的 要使用session对象，需要设置一个密钥，方法如下： 12345678910111213141516171819202122232425262728import osfrom flask import Flask, request, session, redirect, url_for, flash, escapeapp = Flask(__name__)@app.route('/')def index(): if 'username' in session: return 'log in as %s' % escape(session['username']) else: return 'you are not logged in'@app.route('/login',methods=['POST','GET'])def login(): if request.method == 'POST': session['username'] = request.form['username'] return redirect(url_for('index')) return '''&lt;form action="" method="post"&gt; &lt;p&gt;&lt;input type=text name=username&gt; &lt;p&gt;&lt;input type=submit value=login&gt; &lt;/form&gt; '''@app.route('/logout')def logout(): session.pop('username',None) return redirect(url_for('index'))app.secret_key = os.urandom(24) 消息闪现使用flash()可以闪现一条消息，要操作消息本身请使用get_flashed_messages() 日志记录flask有自带的日志记录系统，使用方法如下： 123app.logger.debug('a value for debuging')app.logger.warning('warning occurred',42)app.logger.error('an error occured') 整合wsgi中间件wsgi是指网络服务器网关接口，主要用于描述一个网页服务器如何与网页应用交互，使用方法如下： 12from werkzeug.contrib.fixers import LighttpdCGIRootFixapp.wsgi_app = LighttpdCGIRootFix(app.wsgi_app) 在自己主机上托管网页17.1 安装Apache首先安装apache（阿帕奇），这个软件主要是用于部署网页，下载方法如下：①登录apache下载网站，找到如下的for windows的软件 ②选择下图中的任意一个第三方平台进行下载，会得到一个压缩包 ​ 解压压缩包得到名为apache的文件夹，首先要修改/Apache24/conf/htttpd.conf，将其中Define SRVROOT &quot;/Apache24&quot;改为其现在的路径Define SRVROOT &quot;D:/program files/Apache24&quot;， 再把Listen 80改为Listen 88（因为80端口可能已经被占用）； 然后，我们需要修改/Apache24/conf/extra/thhpd-ssl.conf以及/Apache24/conf/extra/thhpd-ssl.conf文件中的Listen 443改成Listen 444（因为443端口路被cmd占用） ​ 通过cmd进入Apache24/bin，输入httpd.exe -k install -n apache，这条指令的意思就是安装httpd.exe程序为Windows服务，名称为apache，之后你就可以通过ApacheMonitor.exe直接打开或者关闭Apache。 ​ ③为了验证Apache是否安装成功，我们需要在打开Apache服务的时候，访问127.0.0.1，如果看到如下界面，表示安装成功：]]></content>
      <categories>
        <category>编程学习</category>
      </categories>
      <tags>
        <tag>flask</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jQuery教程]]></title>
    <url>%2F2017%2F07%2F09%2FjQuery%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[什么是jQuery 是一个JavaScript框架，或者说我们也可以把它称之为一个JavaScript库，里面封装了一些常用的JavaScript函数代码，其兼容性比较好，支持所有主流的浏览器。 如何使用jQuery有两种方法可以引用jQuery代码， 一是从官网上下载，和html文件放到同一个文件夹下，然后通过&lt;script type = &quot;text/JavaScript&quot;, src = &quot;jquery-3.2.1.js&quot;&gt;&lt;/script&gt; 二是直接通过cdn的方式进行网页引用，script type = &quot;text/JavaScript&quot;, src = “http://apps.bdimg.com/libs/jquery/2.1.1/jquery.min.js&quot;进行引用 使用jQuery写hello world$(document).ready()表示等网页上所有元素加载好之后再进行括号内的内容 $(“div”)表示寻找所有标签为div的元素 $(“div”).html()用于更改div的内容 123456789101112131415161718192021222324&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="utf-8"/&gt; &lt;title&gt;第一个简单的jQuery程序&lt;/title&gt; &lt;style type="text/css"&gt; div&#123; padding:8px 0px; font-size:12px; text-align:center; border:solid 1px #888; &#125; &lt;/style&gt; &lt;script src="http://apps.bdimg.com/libs/jquery/2.1.1/jquery.min.js"&gt;&lt;/script&gt; &lt;script type="text/javascript"&gt; $(document).ready(function() &#123; $("div").html("您好，通过慕课网学习jQuery才是最佳的途径。") &#125;); &lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;div&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 使用jQuery获取元素对象通过$符号来进行对象获取，获取的对象是一个数组对象，比如文章中一共有三个div标签，那么$(&quot;div&quot;)获取到的是一个长度为3的数组，可以通过get方法转换成DOM对象，也可以直接用数组进行转换，方法如下： 12var $div = $("div");var div = $div.get(0); //或者var div = $div[0]; 将DOM对象转换为jQuery对象： 12var div = document.getElementById("div1");$div = $(div); jQuery的层级选择器一共有4种常用选择器如下： 子选择器：$(&quot;parent &gt; child&quot;) 后代选择器：$(&quot;ancestor descendant&quot;) 相邻兄弟选择器：$(&quot;prev + next&quot;) 一般兄弟选择器：$(&quot;bro1 ~ bro2&quot;) jQuery的一般筛选选择器一共有12种常用筛选选择器，$(“:”)，美元符号加括号，引号，然后以冒号开头： $(“:eq(index)”)：选择等于给定索引的元素 $(“:lt(index)”)：选择小于给定索引的元素 $(“:gt(index)”)：选择大于给定索引的元素 $(“:odd”)：选择索引为奇数的元素 $(“:even”)：选择索引为偶数的元素 $(“:first”)：选择第一个元素 $(“:last”)：选择最后一个元素 $(“:animated”)：选择正在进行动画效果的元素 $(“:root”)：选择根元素 $(“lang(language)”)：选择指定语言的元素 $(“:header”)：选择标题元素 $(“not(selector)”)：选择除了不匹配给定的选择器元素 jQuery内容选择器一共有四种常用的内容选择器： $(&quot;:contains(text)&quot;)：选择含有指定文本内容的元素 $(&quot;:parent&quot;)：选择所有含有子元素或者内容的元素 $(&quot;:has(selector)&quot;)：选择符合选择器的元素 $(:empty)：选择没有子元素的元素 jQuery可见性选择器有可见和不可见两种： $(&quot;:visible&quot;)：显示所有可见元素 $(“:hidden”)：显示所有隐藏元素 jQuery属性选择器属性选择器是判断属性与所给定值之间的关系，通常的形式是$(&quot;[attribute=value]&quot;)，有如下几种： $(&quot;[attribute|=value]&quot;)：属性值等于所给值或者以所给值为前缀（在所给值最后加一个”-“） $(&quot;[attribute=value]&quot;)：属性值等于所给值 $(&quot;[attribute!=value]&quot;)：属性值不等于所给值的元素 $(&quot;[attribute*=value]&quot;)：属性值包含一个给定的子字符串的元素 $(&quot;[attribute~=value])&quot;：以空格分隔的属性值中有一个给定值的元素 $(&quot;[attribute]&quot;)：指定属性的元素 $(&quot;[attribute^=value]&quot;)：以给定值为开始的元素 $(&quot;[attribute$=value]&quot;)：以给定值为结束的元素 $(&quot;[attributeFilter1][attributeFilter2]&quot;)：匹配所有属性选择器的元素 jQuery子元素选择器通常有如下5中子元素选择器： $(&quot;:first-child&quot;)：选择第一个子元素 $(&quot;:last-child&quot;)：选择最后一个子元素 $(&quot;:only-child&quot;)：选择子元素为唯一元素的子元素 $（&quot;:nth-child&quot;）：选择第n个子元素 $(&quot;:nth-last-child&quot;)：选择父元素的第n个子元素，计数是从后到前的 jQuery表单元素选择器表单选择器有如下10种： $(&quot;:input&quot;)：选择所有的input,select,button和textarea元素 $(&quot;:text&quot;)：选择所有文本框 $(&quot;:password&quot;)：选择所有密码框 $(&quot;:radio&quot;)：选择所有单选框 $(&quot;:checkbox&quot;)：选择所有复选框 $(:submit)：选择所有提交按钮 $(:image)：选择所有图像域 $(&quot;:reset&quot;)：匹配所有重置按钮 $(&quot;:button&quot;)：匹配所有按钮 $(&quot;:file&quot;)：匹配所有文件域 jQuery对象属性筛选选择器表单筛选选择器主要有一下4种： $(&quot;:enabled&quot;：可用的表单元素 $(:disabled)：选取不可用的表单元素 $(:checked)：选取被选中的&lt;input&gt;元素 $(&quot;:selected&quot;)：选取被选中的&lt;option&gt;元素 添加点击事件的函数： 12var p1 = getElementById("p1")p1.addEventListener('click')]]></content>
      <categories>
        <category>编程学习</category>
      </categories>
      <tags>
        <tag>编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[css对网页进行布局]]></title>
    <url>%2F2017%2F07%2F05%2Fcss%E5%AF%B9%E7%BD%91%E9%A1%B5%E8%BF%9B%E8%A1%8C%E5%B8%83%E5%B1%80%2F</url>
    <content type="text"><![CDATA[一列布局使用三个div分别为上中下，分别设置每一个的高度和宽度以及背景颜色 居中效果的代码是margin:0 auto，意思是上下的宽度设置为0，左右的宽度设置为auto 12345678910111213141516171819202122232425262728293031323334&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"/&gt; &lt;title&gt;1列布局&lt;/title&gt; &lt;style type="text/css"&gt; body&#123; margin: 0; padding: 0 &#125; .main&#123; width: 800px; height: 300px; background: #ccc; margin: 0 auto; &#125; .top&#123; height: 100px; background: blue; &#125; .foot&#123; width: 800px; height: 100px; background: #900; margin: 0 auto; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt;&lt;div class="top"&gt;&lt;/div&gt;&lt;div class="main"&gt;&lt;/div&gt;&lt;div class="foot"&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 两列布局使用一个大的div，包含两个浮动于左右的div，float:left和float:right 12345678910111213141516171819&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;2列布局&lt;/title&gt; &lt;style type="text/css"&gt; body&#123;margin: 0;padding: 0&#125; .main&#123;margin: 0 auto;width: 800px;&#125; .left&#123;width: 200px;height: 500px;float: left;background: red&#125; .right&#123;width: 520px;height: 500px;float: right;background: yellow&#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt;&lt;div class="main"&gt; &lt;div class="left"&gt;&lt;/div&gt; &lt;div class="right"&gt;&lt;/div&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 三列布局使用三列布局有两种方式，第一种是通过设置三列的width：33.33% 第二种是绝对布局，左右都设置为position:absolute 12345678910111213141516171819&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;3列布局&lt;/title&gt; &lt;style type="text/css"&gt; body&#123;margin: 0;padding: 0&#125; .main&#123;margin: 0 auto;width: 800px;&#125; .left&#123;width: 200px;height: 500px;background: red;position: absolute;left: 0;top: 0&#125; .middle&#123;height: 500px;background: green;margin: 0 310px 0 210px&#125; .right&#123;width: 300px;height: 500px;background: yellow;position: absolute;right: 0;top: 0&#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div class="left"&gt;200px&lt;/div&gt; &lt;div class="middle"&gt;middle&lt;/div&gt; &lt;div class="right"&gt;300px&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 混合布局的使用上下自动居中，中间使用浮动在左右 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"/&gt; &lt;title&gt;1列布局&lt;/title&gt; &lt;style type="text/css"&gt; body&#123; margin: 0; padding: 0 &#125; .main&#123; width: 800px; height: 300px; background: #ccc; margin: 0 auto; &#125; .left&#123; width: 200px; height: 300px; background: yellow; float: left; &#125; .right&#123; width: 600px; height: 300px; background: red; float: right; &#125; .top&#123; height: 100px; width: 800px; background: blue; margin: 0 auto; text-align: center; vertical-align: middle; &#125; .foot&#123; width: 800px; height: 100px; background: #900; margin: 0 auto; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt;&lt;div class="top"&gt;top&lt;/div&gt;&lt;div class="main"&gt; &lt;div class="left"&gt;left&lt;/div&gt; &lt;div class="right"&gt;right&lt;/div&gt;&lt;/div&gt;&lt;div class="foot"&gt;foot&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;]]></content>
      <categories>
        <category>编程学习</category>
      </categories>
      <tags>
        <tag>网页</tag>
        <tag>css</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[css教程]]></title>
    <url>%2F2017%2F06%2F30%2Fcss%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[CSS定义 CSS全称为“层叠样式表 (Cascading Style Sheets)”，它主要是用于定义HTML内容在浏览器内的显示样式，如文字大小、颜色、字体加粗等。 css语法格式声明：在英文大括号“｛｝”中的的就是声明，属性和值之间用英文冒号“：”分隔。当有多条声明时，中间可以英文分号“;”分隔，如下所示： 1234p&#123; font-size:12px; color:red;&#125; CSS 类型CSS样式可以写在哪些地方呢？从CSS 样式代码插入的形式来看基本可以分为以下3种：内联式、嵌入式和外部式三种。这一小节先来讲解内联式。 内联式内联式css样式表就是把css代码直接写在现有的HTML标签中，style=&quot;color=red&quot;如下面代码： 1&lt;p style="color:red"&gt;这里文字是红色。&lt;/p&gt; 并且css样式代码要写在style=””双引号中，如果有多条css样式代码设置可以写在一起，中间用分号隔开。如下代码： 1&lt;p style="color:red;font-size:12px"&gt;这里文字是红色。&lt;/p&gt; 嵌入式嵌入式就是把内联式css样式写在head标签的style标签中，其属性为type=&quot;text/css&quot;，具体代码如下 1234567891011&lt;!DOCTYPE HTML&gt;&lt;html&gt;&lt;head&gt;&lt;meta http-equiv="Content-Type" content="text/html; charset=utf-8"&gt;&lt;title&gt;嵌入式css样式&lt;/title&gt;&lt;style type="text/css"&gt;span&#123; color:red;&#125;&lt;/style&gt;&lt;/head&gt; 外部式外部式css样式(也可称为外联式)就是把css代码写一个单独的外部文件中，这个css样式文件以“.css”为扩展名，在&lt;head&gt;内（不是在&lt;style&gt;标签内）使用&lt;link&gt;标签将css样式文件链接到HTML文件内，如下面代码： 1&lt;link href="style.css" rel="stylesheet" type="text/css" /&gt; 三种css属性的优先级是： 内联式 &gt; 嵌入式 &gt; 外部式 总的来说，css的优先级遵从就近原则 类名1.类选器名称&#123;css样式代码;&#125; 使用方法： 第一步：使用合适的标签把要修饰的内容标记起来，如下： 1&lt;span&gt;胆小如鼠&lt;/span&gt; 第二步：使用class=”类选择器名称”为标签设置一个类，如下： 1&lt;span class=&quot;stress&quot;&gt;胆小如鼠&lt;/span&gt; 第三步：设置类选器css样式，如下： 1.stress&#123;color:red;&#125;/*类前面要加入一个英文圆点*/ id 选择器ID选择器都类似于类选择符，但也有一些重要的区别： 1、为标签设置id=”ID名称”，而不是class=”类名称”。 2、ID选择符的前面是井号（#）号，而不是英文圆点（.）。 id选择器只能用一次，每个元素只能有一个id，而类选择器可以有很多元素是同一个类，一个元素也可以同时属于多个类 子选择器先写一个类，然后用大于符号&gt;指向类中的某个元素，对齐设置样式表： 123.food&gt;li&#123; border:1px red solid;&#125; 子选择器效果图： 包含后代的选择器把子选择器的&gt;符号换成空格，其与子选择器的主要区别是：包含后代的选择器会把子类中的所有符合条件的子类都改变，而子选择器只改变第一代后代，代码如下： 123.food li&#123; border:1px solid red;&#125; 后代选择器效果图： 适配符通用适配符：*，用于匹配任意样式 伪类适配符：:hover,它允许给html不存在的标签（标签的某种状态）设置样式，比如说我们给html中一个标签元素的鼠标滑过的状态来设置字体颜色: a:hover{color:red} 分组选择符：,，同时为多个标签设置样式 继承如果对某个父类标签设置了某种样式，其子标签也会自动继承这种样式，比如你为&lt;p&gt;标签设置了color=red，那么&lt;p&gt;标签包含的&lt;span&gt;标签也会自动继承这个颜色样式 权重系统根据权重判断到底使用哪种样式，具体来说：继承权重为0.1，标签的权重为1，类选择符权重为10，id选择符权值为100 12345p&#123;color:red;&#125; /*权值为1*/p span&#123;color:green;&#125; /*权值为1+1=2*/.warning&#123;color:white;&#125; /*权值为10*/p span.warning&#123;color:purple;&#125; /*权值为1+1+10=12*/#footer .note p&#123;color:yellow;&#125; /*权值为100+10+1=111*/ 如果遇到权重相同的情况：就近原则 设置最高权重：在分号之前加入importantp.first{color:green!important;}，注意后代选择器是空格，p.first中间不加空格（因为不是后代）,同理p#id也不加空格 格式化排版 设置字体：font-family属性 字号：font-size:20px 颜色：color:red 粗体：font-weight：bold 斜体：font-style:italic 下划线：text-decoration：underline 删除线：text-decoration：line-through 首行缩进：text-indent：2em 行间距：line-height：1.5em 字间距：letter-spacing：50px 对齐方式：text-align：center 使用方式如下： 123456789101112&lt;!DOCTYPE HTML&gt;&lt;html&gt;&lt;head&gt;&lt;style type="text/css"&gt;body&#123; font-family:"微软雅黑"； font-size:20px; color:red;&#125;&lt;/style&gt;&lt;/head&gt;&lt;/html&gt; 元素分类在讲解CSS布局之前，我们需要提前知道一些知识，在CSS中，html中的标签元素大体被分为三种不同的类型：块状元素、内联元素(又叫行内元素)和内联块状元素。 常用的块状元素有： &lt;div&gt;、&lt;p&gt;、&lt;h1&gt;...&lt;h6&gt;、&lt;ol&gt;、&lt;ul&gt;、&lt;dl&gt;、&lt;table&gt;、&lt;address&gt;、&lt;blockquote&gt; 、&lt;form&gt; 常用的内联元素有： &lt;a&gt;、&lt;span&gt;、&lt;br&gt;、&lt;i&gt;、&lt;em&gt;、&lt;strong&gt;、&lt;label&gt;、&lt;q&gt;、&lt;var&gt;、&lt;cite&gt;、&lt;code&gt; 常用的内联块状元素有： &lt;img&gt;、&lt;input&gt; 块级元素什么是块级元素？在html中&lt;div&gt;、 &lt;p&gt;、&lt;h1&gt;、&lt;form&gt;、&lt;ul&gt; 和 &lt;li&gt;就是块级元素。设置display:block就是将元素显示为块级元素。如下代码就是将内联元素a转换为块状元素，从而使a元素具有块状元素特点。 1a&#123;display:block;&#125; 块级元素特点： 1、每个块级元素都从新的一行开始，并且其后的元素也另起一行。（真霸道，一个块级元素独占一行） 2、元素的高度、宽度、行高以及顶和底边距都可设置。 3、元素宽度在不设置的情况下，是它本身父容器的100%（和父元素的宽度一致），除非设定一个宽度。 内联元素在html中，&lt;span&gt;、&lt;a&gt;、&lt;label&gt;、 &lt;strong&gt; 和&lt;em&gt;就是典型的内联元素（行内元素）（inline）元素。当然块状元素也可以通过代码display:inline将元素设置为内联元素。如下代码就是将块状元素div转换为内联元素，从而使 div 元素具有内联元素特点。 1234567 div&#123; display:inline; &#125;......&lt;div&gt;我要变成内联元素&lt;/div&gt; 内联元素特点： 1、和其他元素都在一行上； 2、元素的高度、宽度及顶部和底部边距不可设置； 3、元素的宽度就是它包含的文字或图片的宽度，不可改变。 内联块状内联块状元素（inline-block）就是同时具备内联元素、块状元素的特点，代码display:inline-block就是将元素设置为内联块状元素。(css2.1新增)，&lt;img&gt;、&lt;input&gt;标签就是这种内联块状标签。 inline-block 元素特点： 1、和其他元素都在一行上； 2、元素的高度、宽度、行高以及顶和底边距都可设置。 盒子模型 盒子：div 内容与盒子的距离：padding，一共四个方向，padding-top，padding-bottom，padding-left，padding-right 盒子与另一个盒子的距离：margin 盒子边框：border 边框盒子模型的边框就是围绕着内容及补白的线，这条线你可以设置它的粗细、样式和颜色(边框三个属性)。 如下面代码为 div 来设置边框粗细为 2px、样式为实心的、颜色为红色的边框： 123div&#123; border:2px dotted red;&#125; 上面是 border 代码的缩写形式，可以分开写： 12345div&#123; border-width:2px; border-style:dotted;/*虚线*/ border-color:red;&#125; 也可以单独为一边设置边框 123div&#123; border-bottom:2px dotted red;&#125; 宽度和高度宽度和高度分别使用width和height来表示 填充元素与边框之间的距离用padding，其设置的顺序为：上，右，下，左(顺时针) CSS布局模型CSS包含3种基本的布局模型，用英文概括为：Flow、Layer 和 Float。在网页中，元素有三种布局模型： 流动模型（Flow） 浮动模型 (Float) 层模型（Layer） 流动模型流动模型是默认的网页布局模式，2个典型特征： 块状元素都会在所处的包含元素内自上而下按顺序垂直延伸分布，因为在默认状态下，块状元素的宽度都为100%。实际上，块状元素都会以行的形式占据位置。如右侧代码编辑器中三个块状元素标签(div，h1，p)宽度显示为100%。 第二点，在流动模型下，内联元素都会在所处的包含元素内从左到右水平分布显示。（内联元素可不像块状元素这么霸道独占一行） 清除浮动：①clear：both ② width：100%，overflow：hidden 浮动模型块状元素这么霸道都是独占一行，如果现在我们想让两个块状元素并排显示，怎么办呢？不要着急，设置元素浮动就可以实现这一愿望。使用float属性设置浮动： 12345678div&#123; width:200px; height:200px; border:2px red solid; float:left;&#125;&lt;div id="div1"&gt;&lt;/div&gt;&lt;div id="div2"&gt;&lt;/div&gt; 层模型什么是层布局模型？层布局模型就像是图像软件PhotoShop中非常流行的图层编辑功能一样，每个图层能够精确定位操作。 CSS定义了一组定位（positioning）属性来支持层布局模型。层模型有三种形式： 1、绝对定位(position: absolute)加入position:absolute 123456789div&#123; width:200px; height:200px; border:2px red solid; position:absolute; left:100px; top:50px;&#125;&lt;div id="div1"&gt;&lt;/div&gt; 2、相对定位(position: relative)absolute表里如一，移动了就是移动了。relative只是表面显示移动了，但实际还在文档流中原有位置，别的元素无法占据。如果想为元素设置层模型中的相对定位，需要设置position:relative（表示相对定位），它通过left、right、top、bottom属性确定元素在正常文档流中的偏移位置 3、固定定位(position: fixed)fixed：表示固定定位，与absolute定位类型类似，但它的相对移动的坐标是视图（屏幕内的网页窗口）本身。由于视图本身是固定的，它不会随浏览器窗口的滚动条滚动而变化，因此固定定位的元素会始终位于浏览器窗口内视图的某个位置，不会受文档流动影响，这与background-attachment:fixed;属性功能相同 相对定位和绝对定位配合必须相对于父辈元素进行定位：在父辈元素加position:relative，需要进项相对的加position:absolute 盒模型代码简写通常有下面三种缩写方法: 1、如果top、right、bottom、left的值相同，如下面代码： 1margin:10px 10px 10px 10px; 可缩写为： 1margin:10px; 2、如果top和bottom值相同、left和 right的值相同，如下面代码： 1margin:10px 20px 10px 20px; 可缩写为： 1margin:10px 20px; 3、如果left和right的值相同，如下面代码： 1margin:10px 20px 30px 20px; 可缩写为： 1margin:10px 20px 30px; 颜色值缩写关于颜色的css样式也是可以缩写的，当你设置的颜色是16进制的色彩值时，如果每两位的值相同，可以缩写一半。 例子1： 1p&#123;color:#000000;&#125; 可以缩写为： 1p&#123;color: #000;&#125; 例子2： 1p&#123;color: #336699;&#125; 可以缩写为： 1p&#123;color: #369;&#125; 字体设置缩写网页中的字体css样式代码也有他自己的缩写方式，下面是给网页设置字体的代码： 12345678body&#123; font-style:italic; font-variant:small-caps; font-weight:bold; font-size:12px; line-height:1.5em; font-family:&quot;宋体&quot;,sans-serif;&#125; 这么多行的代码其实可以缩写为一句： 123body&#123; font:italic small-caps bold 12px/1.5em &quot;宋体&quot;,sans-serif;&#125; 注意： 1、使用这一简写方式你至少要指定 font-size 和 font-family 属性，其他的属性(如 font-weight、font-style、font-variant、line-height)如未指定将自动使用默认值。 2、在缩写时 font-size 与 line-height 中间要加入“/”斜扛。 颜色值颜色值有3中设置方式： 英文命令颜色p{color:red;} RGB颜色 p{color：RGB(133,45,200) 十六进制颜色 p{color：#00ffff} 长度值 像素px 字体大小em：就是本元素的字体大小，比如字体大小为14px，那么em大小就位14px 百分比：p{font-size:12px;line-height:130%} CSS样式设置小技巧设置居中p{text-align:center;} 定宽块状元素居中div{margn:20px auto;} 不定宽度的块状元素有三种方法居中（这三种方法目前使用的都很多）： 加入 table 标签 设置 display: inline 方法：与第一种类似，显示类型设为 行内元素，进行不定宽元素的属性设置 设置 position:relative 和 left:50%：利用 相对定位 的方式，将元素向左偏移 50% ，即达到居中的目的方法三：通过给父元素设置 float，然后给父元素设置 position:relative 和 left:50%，子元素设置 position:relative 和 left: -50% 来实现水平居中。 垂直居中设置height和line-height值一样 1234567&lt;style&gt;.container&#123; height:100px; line-height:100px; background:#999;&#125;&lt;/style&gt; 父元素高度确定的多行文本、图片等的竖直居中的方法有两种： 使用插入 table (包括tbody、tr、td)标签，同时设置 vertical-align：middle。 设置块级元素的 display 为 table-cell（设置为表格单元显示），激活 vertical-align 属性，但注意 IE6、7 并不支持这个样式, 兼容性比较差。 隐性改变display类型 position : absolute float : left 或 float:right 简单来说，只要html代码中出现以上两句之一，元素的display显示类型就会自动变为以 display:inline-block（块状元素）的方式显示，当然就可以设置元素的 width 和 height 了，且默认宽度不占满父元素。]]></content>
      <categories>
        <category>编程学习</category>
      </categories>
      <tags>
        <tag>css</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JavaScript教程]]></title>
    <url>%2F2017%2F06%2F29%2FJavaScript%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[之前在慕课网上看了看JavaScript的教程，但是整个教程的内容不够详细，因此在廖雪峰官方网站看看关于js的教程，并重新学习和记录如下。 js用于在静态HTML页面上添加一些动态效果 ，网景公司的Brendan Eich这哥们在两周之内设计出了JavaScript语言 。为了让js称为全球标砖，欧洲计算机制造协会(European Computer Manufacturers Association)制定了js的标准，称为RCMAscript标准，最新版ECMAscript 6标准于2015年6月发布（简称ES6)。 快速入门js代码一般放在&lt;head&gt;当中，由封闭的&lt;script&gt;...&lt;/script&gt;包含起来 第二种是将js放在一个单独的js文件中，然后在head中声明该文件 123&lt;head&gt; &lt;script src="/static/js/abc.js"&gt;&lt;/script&gt;&lt;/head&gt; 有时候会看到定义js的类型，&lt;script type=&quot;text/javascript&quot;&gt;，但是实际上是没有必要的，因为默认的script的类型就是javascript 基础语法每一句以分号(‘;’)结束，语句块用大括号括起来 //表示注释，/*…*/也表示注释 数据类型和变量Numberjs不区分整数和浮点数，统一用Number表示 字符串字符串是以单引号或双引号引起来的任何文本，比如’abc’或者”xyz”。如果引号里面还有引号，那么就要用到转义字符\，ASCII字符可以用\x##表示，例如： 1'\x41'; // 完全等同于 'A' 还可以用\u####表示一个Unicode字符： 1'\u4e2d\u6587'; // 完全等同于 '中文' 多行字符串可以用反引号表示，也就是数字1左边那个键 123console.log(`多行字符串测试`); 多个字符串连接起来跟python一样用加号+就可以了，也可以跟shell脚本一样用变量名来代替，比如： 1234var name = '小明';var age = 20;var message = `你好, $&#123;name&#125;, 你今年$&#123;age&#125;岁了!`;alert(message); 操作字符串获取字符串长度用.length，如果要获取slice，跟python的list方法一样，要注意，字符串本身是不可以变动的，对某个slice赋值不会改变本身： 123var s = 'Test';s[0] = 'X';alert(s); // s仍然为'Test' 还有一些函数用于操作字符串 toUpperCase()：字符串变大写 toLowerCase()：字符串变小写 indexOf()：搜索指定字符串出现的位置，如果没找到则返回-1 123var s = 'hello, world';s.indexOf('world'); // 返回7s.indexOf('World'); // 没有找到指定的子串，返回-1 substring()：返回指定索引区间的子串，类似于python使用冒号的slice方法 123var s = 'hello, world's.substring(0, 5); // 从索引0开始到5（不包括5），返回'hello's.substring(7); // 从索引7开始到结束，返回'world' 布尔值布尔值只有true和false两种，可以直接使用true，false来表示，也可以使用布尔运算来计算出来（比如大小比较或者与或非），js的与运算是&amp;&amp;，或运算是||，非运算是! 比较运算符大小比较与其他语言没有区别，但是js有个特殊的等于比较，两个等号”==”会自动转换类型之后再比较，而三个等号”===”不会自动转换类型，由于JavaScript这个设计缺陷，不要使用==比较，始终坚持使用===比较。 12false == 0; // truefalse === 0; // false 还有一个问题就是NaN与任何值都不相等，包括他自己 1NaN === NaN; // false 唯一判断NaN的方法就是使用isNaN()函数 浮点数运算的相等比较中，由于浮点数运算会出现误差，因此计算机无法精确标识无限循环小数，要比较两个浮点数是否相等，智能计算他们之间的绝对值，看是否小于某个阈值 121 / 3 === (1 - 2 / 3); // falseMath.abs(1 / 3 - (1 - 2 / 3)) &lt; 0.0000001; // true null和undefinednull表示空值，与0和空字符串&#39;&#39;都是不同的，null和undefined大致类似，大多数情况下都应该用null，undefined只有在判断函数参数是否传递的情况下有用 数组js的数组和python的list类似，可以包含任意类型的数据，例如： 1[1, 2, 3.14, 'Hello', null, true]; 另一种创建数组的方法是通过Array()函数实现 1new Array(1,2,3);// 创建了数组[1, 2, 3] 更建议直接使用方括号[]来建立数组，数组索引也和python类似，起始索引为0 1234var arr = [1, 2, 3.14, 'Hello', null, true];arr[0]; // 返回索引为0的元素，即1arr[5]; // 返回索引为5的元素，即truearr[6]; // 索引超出了范围，返回undefined 数组同样用length来获取长度，如果对array的length赋值的话会改变数组的内容，没有定义的内容全为undefined，如果变短则截断 123456var arr = [1, 2, 3];arr.length; // 3arr.length = 6;arr; // arr变为[1, 2, 3, undefined, undefined, undefined]arr.length = 2;arr; // arr变为[1, 2] Array可以通过索引把对应的元素改为新的值 123var arr = ['A', 'B', 'C'];arr[1] = 99;arr; // arr现在变为['A', 99, 'C'] 请注意，如果通过索引赋值时，索引超过了范围，同样会引起Array大小的变化： 123var arr = [1, 2, 3];arr[5] = 'x';arr; // arr变为[1, 2, 3, undefined, undefined, 'x'] indexOfArray也可以用indexOf来获取某个元素的位置 sliceslice()对应String的substring()方法，用于切片 push和poppush()是在array末尾添加元素，pop()是把array最后一个元素返回出来 unshift和shiftunshift()：在array头部添加若干元素 shift()：将array的第一个元素删除掉并返回出来 unshift和shift相当于push和pop作用在array头部 12345var arr = [1, 2];arr.unshift('A', 'B'); // 返回Array新的长度: 4arr; // ['A', 'B', 1, 2]arr.shift(); // 'A'arr; // ['B', 1, 2] sort对array进行排序 reverse元素顺序反转 123var arr = ['one', 'two', 'three'];arr.reverse(); arr; // ['three', 'two', 'one'] splicesplice()是array的万能方法，可以从指定索引删除若干元素，然后从该位置再添加若干元素 12345678910var arr = ['Microsoft', 'Apple', 'Yahoo', 'AOL', 'Excite', 'Oracle'];// 从索引2开始删除3个元素,然后再添加两个元素:arr.splice(2, 3, 'Google', 'Facebook'); // 返回删除的元素 ['Yahoo', 'AOL', 'Excite']arr; // ['Microsoft', 'Apple', 'Google', 'Facebook', 'Oracle']// 只删除,不添加:arr.splice(2, 2); // ['Google', 'Facebook']arr; // ['Microsoft', 'Apple', 'Oracle']// 只添加,不删除:arr.splice(2, 0, 'Google', 'Facebook'); // 返回[],因为没有删除任何元素arr; // ['Microsoft', 'Apple', 'Google', 'Facebook', 'Oracle'] concat把两个array连接起来，并返回一个新的array 123var arr = ['A', 'B', 'C'];var added = arr.concat([1, 2, 3]);added; // ['A', 'B', 'C', 1, 2, 3] joinjoin和python的join方法效果一样，使用方法如下 12var arr = ['A', 'B', 'C', 1, 2, 3];arr.join('-'); // 'A-B-C-1-2-3' 多维数组多维数组和python的list里面的list一样 1var arr = [[1, 2, 3], [400, 500, 600], '-']; 取数组元素作为变量取数组元素作为变量应该用${array[i]}这样的形式 12var arr = ['小明', '小红', '大军', '阿黄'];console.log(`欢迎$&#123;arr[0]&#125;,$&#123;arr[1]&#125;,$&#123;arr[2]&#125;和$&#123;arr[3]&#125;同学`);//欢迎小明,小红,大军和阿黄同学 注意这里的`号，不是单引号，单引号无法得到变量，全部视为字符串 对象js的对象是由一组键值对组成的字典，与python中的字典类型基本一样： 12345678var person = &#123; name: 'Bob', age: 20, tags: ['js', 'web', 'mobile'], city: 'Beijing', hasCar: true, zipcode: null&#125;; js对象的键都是字符串类型，值可以是任何类型，要获取一个对象的属性，就直接用对象变量.属性名的方式： 12person.name; // 'Bob'person.zipcode; // null 如果某个对象的key是字符串类型，访问的时候就只能跟python的字典一样，用object[&#39;key&#39;]来访问 1234567var xiaohong = &#123; name: '小红', 'middle-school': 'No.1 Middle School'&#125;;xiaohong['middle-school']; // 'No.1 Middle School'xiaohong['name']; // '小红'xiaohong.name; // '小红' 如果访问不存在的元素，那么返回的就是undefined 你可以随意给对象添加或者是删除属性，通过delete进行删除，还可以通过in来判断某个属性是否在某个对象中 123456789101112131415161718var xiaoming = &#123; name: '小明'&#125;;xiaoming.age; // undefinedxiaoming.age = 18; // 新增一个age属性xiaoming.age; // 18delete xiaoming.age; // 删除age属性xiaoming.age; // undefined//用in来判断属性是否存在var xiaoming = &#123; name: '小明', birth: 1990,&#125;;'name' in xiaoming; // true'grade' in xiaoming; // false'toString' in xiaoming; // truexiaoming.hasOwnProperty('name'); // truexiaoming.hasOwnProperty('toString'); // false 但是用in判断有风险，因为如果是继承得到的属性也会被判断为自身的。要判断是否自身的属性， 应该用hasOwnProperty()方法： 变量js的变量要以var定义，变量名是大小写英文、数字、$和_的组合 ，不能以数字开头 用等号对变量赋值，但一个变量只需要初始化一次 12var a = 123; // a的值是整数123a = 'ABC'; // a变为字符串 strict模式如果不用var进行初始化的话，那么变量将是全局变量，这会导致很严重的错误 ECMA为了修补js的这一严重缺陷，在后续退出了strict模式，如果不用var初始化变量将会报错，启用strict模式的方法是在js代码的第一行写上 1&apos;use strict&apos;; 条件判断js用if{...} else if{...}的形式来进行条件判断，例如 1234567if (age &gt;= 6) &#123; console.log('teenager');&#125; else if (age &gt;= 18) &#123; console.log('adult');&#125; else &#123; console.log('kid');&#125; JavaScript把null、undefined、0、NaN和空字符串&#39;&#39;视为false，其他值一概视为true，因此上述代码条件判断的结果是true。 循环js的循环和c语言当中的是一样的 123456var x = 0;var i;for (i=1; i&lt;=10000; i++) &#123; x = x + i;&#125;x; // 50005000 for循环最常用的地方是利用索引来遍历数组： 123456var arr = ['Apple', 'Google', 'Microsoft'];var i, x;for (i=0; i&lt;arr.length; i++) &#123; x = arr[i]; console.log(x);&#125; for也可以用break来退出 js当中的for也可以用python当中的in的形式：for ... in 123456789var o = &#123; name: 'Jack', age: 20, city: 'Beijing'&#125;;for (var key in o)&#123; console.log(key);// 'name', 'age', 'city' console.log(o.key);&#125; 要过滤掉对象继承的属性，用hasOwnProperty()来实现： 12345678910var o = &#123; name: 'Jack', age: 20, city: 'Beijing'&#125;;for (var key in o) &#123; if (o.hasOwnProperty(key)) &#123; console.log(key); // 'name', 'age', 'city' &#125;&#125; for in 数组的话，得到的是索引，因为数组的索引被视为属性 12345var a = ['A', 'B', 'C'];for (var i in a) &#123; console.log(i); // '0', '1', '2' console.log(a[i]); // 'A', 'B', 'C'&#125; Map和Setjs中的Map相当于python中的字典，由键值对组成 初始化一个map需要一个二维数组或者是初始化为空map，用set添加键值对，用has确认是否含有某个键，用get取对应键的值 1234567var m = new Map(); // 空Mapm.set('Adam', 67); // 添加新的key-valuem.set('Bob', 59);m.has('Adam'); // 是否存在key 'Adam': truem.get('Adam'); // 67m.delete('Adam'); // 删除key 'Adam'm.get('Adam'); // undefined Set就是python当中的集合，不允许重复 iterable因为for in语法不适用于Map和Set（因为他们不可以通过下标遍历），因此有了for ... of循环遍历 123456789101112var a = ['A', 'B', 'C'];var s = new Set(['A', 'B', 'C']);var m = new Map([[1, 'x'], [2, 'y'], [3, 'z']]);for (var x of a) &#123; // 遍历Array console.log(x);&#125;for (var x of s) &#123; // 遍历Set console.log(x);&#125;for (var x of m) &#123; // 遍历Map console.log(x[0] + '=' + x[1]);&#125; 然而，更好的遍历方式是使用iterable内置的forEach方法，接收一个函数，每次迭代自动回调该函数 12345678910var a = ['A', 'B', 'C'];a.forEach(function (element, index, array) &#123; // element: 指向当前元素的值 // index: 指向当前索引 // array: 指向Array对象本身 console.log(element + ', index = ' + index);&#125;);//A, index = 0//B, index = 1//C, index = 2 Set与Array类似，但Set没有索引，因此回调函数的前两个参数都是元素本身： 1234var s = new Set(['A', 'B', 'C']);s.forEach(function (element, sameElement, set) &#123; console.log(element);&#125;); Map的回调函数参数依次为value、key和map本身： 1234var m = new Map([[1, 'x'], [2, 'y'], [3, 'z']]);m.forEach(function (value, key, map) &#123; console.log(value);&#125;); 函数在js中，函数定义的方法如下 12345678function abs(x)&#123; if (x&gt;0)&#123; return x; &#125; else&#123; return -x; &#125;&#125; 如果没有return结果，那么函数的返回值是undefined 还有一种函数的定义方法是把函数赋值给一个变量名 12345678var abs = function (x)&#123; if (x&gt;0)&#123; return x; &#125; else&#123; return -x; &#125;&#125; js允许传入任意个函数参数，如果比定义的多，只会调用定义的那个参数，如果比定义的少，那么会返回NaN 12345abs(10); // 返回10abs(-9); // 返回9abs(10, 'blablabla'); // 返回10abs(-9, 'haha', 'hehe', null); // 返回9abs(); // 返回NaN 要避免收到undefined，可以对参数进行检查： 12345678910function abs(x) &#123; if (typeof x !== 'number') &#123; throw 'Not a number'; &#125; if (x &gt;= 0) &#123; return x; &#125; else &#123; return -x; &#125;&#125; argumentsjs本身还定义了一个参数是arguments，指向传入的所有参数，形式跟array一样： 123456789101112function foo(x) &#123; console.log('x = ' + x); // 10 for (var i=0; i&lt;arguments.length; i++) &#123; console.log('arg ' + i + ' = ' + arguments[i]); // 10, 20, 30 &#125;&#125;foo(10, 20, 30);//输出如下//x = 10//arg 0 = 10//arg 1 = 20//arg 2 = 30 restjs还定义了rest参数，用于获取除了已定义参数之外的所有参数 1234567891011121314151617function foo(a, b, ...rest) &#123; console.log('a = ' + a); console.log('b = ' + b); console.log(rest);&#125;foo(1, 2, 3, 4, 5);// 结果:// a = 1// b = 2// Array [ 3, 4, 5 ]foo(1);// 结果:// a = 1// b = undefined// Array [] est参数只能写在最后，前面用...标识， 函数作用域函数内定义的是局部变量，不可以在函数外使用，跟其他编程语言规定是一样的 变量提升js的变量声明会提到最前面进行编译，但是变量赋值并不会提升 1234567function foo() &#123; var x = 'Hello, ' + y; console.log(x); var y = 'Bob';&#125;foo(); 上面这段代码不报错，但是显示的是Hello,undefined js引擎看到的是如下的结构 123456function foo() &#123; var y; // 提升变量y的申明，此时y为undefined var x = 'Hello, ' + y; console.log(x); y = 'Bob';&#125; 全局作用域js当中未定义在函数体中的变量都是全局变量，绑定在window这个对象上 123var course = 'Learn JavaScript';alert(course); // 'Learn JavaScript'alert(window.course); // 'Learn JavaScript' 名字空间全局变量会绑定到window上，不同js文件如果用了相同的全局变量，或者定义了相同名字的顶层函数，都会造成命名冲突，减少冲突的好办法就是把所有的变量和函数全不绑定到一个全局变量中，如： 1234567891011// 唯一的全局变量MYAPP:var MYAPP = &#123;&#125;;// 其他变量:MYAPP.name = 'myapp';MYAPP.version = 1.0;// 其他函数:MYAPP.foo = function () &#123; return 'foo';&#125;; 局部作用域因为js的变量作用域是函数内部，因此类似于c++的for循环当中定义i的方法，在结束了for之后还是可以调用i的，如下： 123456function foo() &#123; for (var i=0; i&lt;100; i++) &#123; // &#125; i += 100; // 仍然可以引用变量i&#125; 因此ES6引入了let关键字 12345678function foo() &#123; var sum = 0; for (let i=0; i&lt;100; i++) &#123; sum += i; &#125; // SyntaxError: i += 1;&#125; 常量ES6引入了const用于定义常量，常量无法修改 123const PI = 3.14;PI = 3; // 某些浏览器不报错，但是无效果！PI; // 3.14 同时对多个变量赋值ES6引入可以同时对多个变量赋值的机制，对多个变量赋值的时候，这些变量要用方括号[]引起来： 1var [x, y, z] = ['hello', 'JavaScript', 'ES6']; 解构赋值还可以忽略某些元素： 12let [, , z] = ['hello', 'JavaScript', 'ES6']; // 忽略前两个元素，只对z赋值第三个元素z; // 'ES6' 如果需要从一个对象中取出若干属性，也可以使用解构赋值，便于快速获取对象的指定属性，在对对象进行解构赋值的时候，用大括号{}把变量扩起来： 123456789var person = &#123; name: '小明', age: 20, gender: 'male', passport: 'G-12345678', school: 'No.4 middle school'&#125;;var &#123;name, age, passport&#125; = person;// name, age, passport分别被赋值为对应属性: 如果对应的属性不存在将会被定义为undefined，如果你要将某个变量拿出来赋给其他值，可以用冒号: 1234567891011121314var person = &#123; name: '小明', age: 20, gender: 'male', passport: 'G-12345678', school: 'No.4 middle school'&#125;;// 把passport属性赋值给变量id:let &#123;name, passport:id&#125; = person;name; // '小明'id; // 'G-12345678'// 注意: passport不是变量，而是为了让变量id获得passport属性:passport; // Uncaught ReferenceError: passport is not defined 解构赋值还可以使用默认值，这样就避免出现undefined的情况： 1234567891011var person = &#123; name: '小明', age: 20, gender: 'male', passport: 'G-12345678'&#125;;// 如果person对象没有single属性，默认赋值为true:var &#123;name, single=true&#125; = person;name; // '小明'single; // true 解构赋值在用于已经定义好的变量的时候，不能直接以{}开头，因为js会认为以{开头的内容是块元素，=不能对块元素赋值，解决办法是用小括号()括起来： 1234567// 声明变量:var x, y;// 解构赋值:&#123;x, y&#125; = &#123; name: '小明', x: 100, y: 200&#125;;// 语法错误: Uncaught SyntaxError: Unexpected token =(&#123;x, y&#125; = &#123; name: '小明', x: 100, y: 200&#125;); //解决办法就是用小括号括起来 方法在一个对象中绑定一个函数，称为这个对象的方法 12345678var xiaoming = &#123; name: '小明', birth: 1990, age: function () &#123; var y = new Date().getFullYear(); return y - this.birth; &#125;&#125;; 这个age()就是一个方法，this就是类定义的this 只有object.funciton()这样的调用形式才能触发this 对于没有定义的this，在strict模式下指向undefined，在非strict模式下指向window applyapply用于显示地指定this，第一个参数就是需要绑定的this变量，第二个参数是Array ，调用形式是function.apply(this, Array) 12345678910111213function getAge() &#123; var y = new Date().getFullYear(); return y - this.birth;&#125;var xiaoming = &#123; name: '小明', birth: 1990, age: getAge&#125;;xiaoming.age(); // 25getAge.apply(xiaoming, []); // 25, this指向xiaoming, 参数为空 另一个与apply()类似的方法是call()，唯一区别是： apply()把参数打包成Array再传入； call()把参数按顺序传入。 比如调用Math.max(3, 5, 4)，分别用apply()和call()实现如下： 12Math.max.apply(null, [3, 5, 4]); // 5Math.max.call(null, 3, 5, 4); // 5 方法阅读: 141906 在一个对象中绑定函数，称为这个对象的方法。 在JavaScript中，对象的定义是这样的： 1234var xiaoming = &#123; name: &apos;小明&apos;, birth: 1990&#125;; 但是，如果我们给xiaoming绑定一个函数，就可以做更多的事情。比如，写个age()方法，返回xiaoming的年龄： 1234567891011var xiaoming = &#123; name: &apos;小明&apos;, birth: 1990, age: function () &#123; var y = new Date().getFullYear(); return y - this.birth; &#125;&#125;;xiaoming.age; // function xiaoming.age()xiaoming.age(); // 今年调用是25,明年调用就变成26了 绑定到对象上的函数称为方法，和普通函数也没啥区别，但是它在内部使用了一个this关键字，这个东东是什么？ 在一个方法内部，this是一个特殊变量，它始终指向当前对象，也就是xiaoming这个变量。所以，this.birth可以拿到xiaoming的birth属性。 让我们拆开写： 12345678910111213function getAge() &#123; var y = new Date().getFullYear(); return y - this.birth;&#125;var xiaoming = &#123; name: &apos;小明&apos;, birth: 1990, age: getAge&#125;;xiaoming.age(); // 25, 正常结果getAge(); // NaN 单独调用函数getAge()怎么返回了NaN？请注意，我们已经进入到了JavaScript的一个大坑里。 JavaScript的函数内部如果调用了this，那么这个this到底指向谁？ 答案是，视情况而定！ 如果以对象的方法形式调用，比如xiaoming.age()，该函数的this指向被调用的对象，也就是xiaoming，这是符合我们预期的。 如果单独调用函数，比如getAge()，此时，该函数的this指向全局对象，也就是window。 坑爹啊！ 更坑爹的是，如果这么写： 12var fn = xiaoming.age; // 先拿到xiaoming的age函数fn(); // NaN 也是不行的！要保证this指向正确，必须用obj.xxx()的形式调用！ 由于这是一个巨大的设计错误，要想纠正可没那么简单。ECMA决定，在strict模式下让函数的this指向undefined，因此，在strict模式下，你会得到一个错误： 12345678910111213&apos;use strict&apos;;var xiaoming = &#123; name: &apos;小明&apos;, birth: 1990, age: function () &#123; var y = new Date().getFullYear(); return y - this.birth; &#125;&#125;;var fn = xiaoming.age;fn(); // Uncaught TypeError: Cannot read property &apos;birth&apos; of undefined 这个决定只是让错误及时暴露出来，并没有解决this应该指向的正确位置。 有些时候，喜欢重构的你把方法重构了一下： 123456789101112131415&apos;use strict&apos;;var xiaoming = &#123; name: &apos;小明&apos;, birth: 1990, age: function () &#123; function getAgeFromBirth() &#123; var y = new Date().getFullYear(); return y - this.birth; &#125; return getAgeFromBirth(); &#125;&#125;;xiaoming.age(); // Uncaught TypeError: Cannot read property &apos;birth&apos; of undefined 结果又报错了！原因是this指针只在age方法的函数内指向xiaoming，在函数内部定义的函数，this又指向undefined了！（在非strict模式下，它重新指向全局对象window！） 修复的办法也不是没有，我们用一个that变量首先捕获this： 12345678910111213141516&apos;use strict&apos;;var xiaoming = &#123; name: &apos;小明&apos;, birth: 1990, age: function () &#123; var that = this; // 在方法内部一开始就捕获this function getAgeFromBirth() &#123; var y = new Date().getFullYear(); return y - that.birth; // 用that而不是this &#125; return getAgeFromBirth(); &#125;&#125;;xiaoming.age(); // 25 用var that = this;，你就可以放心地在方法内部定义其他函数，而不是把所有语句都堆到一个方法中。 apply虽然在一个独立的函数调用中，根据是否是strict模式，this指向undefined或window，不过，我们还是可以控制this的指向的！ 要指定函数的this指向哪个对象，可以用函数本身的apply方法，它接收两个参数，第一个参数就是需要绑定的this变量，第二个参数是Array，表示函数本身的参数。 用apply修复getAge()调用： 12345678910111213function getAge() &#123; var y = new Date().getFullYear(); return y - this.birth;&#125;var xiaoming = &#123; name: &apos;小明&apos;, birth: 1990, age: getAge&#125;;xiaoming.age(); // 25getAge.apply(xiaoming, []); // 25, this指向xiaoming, 参数为空 另一个与apply()类似的方法是call()，唯一区别是： apply()把参数打包成Array再传入； call()把参数按顺序传入。 比如调用Math.max(3, 5, 4)，分别用apply()和call()实现如下： 12Math.max.apply(null, [3, 5, 4]); // 5Math.max.call(null, 3, 5, 4); // 5 对普通函数调用，我们通常把this绑定为null。 装饰器利用apply()，我们还可以动态改变函数的行为。 JavaScript的所有对象都是动态的，即使内置的函数，我们也可以重新指向新的函数。 现在假定我们想统计一下代码一共调用了多少次parseInt()，可以把所有的调用都找出来，然后手动加上count += 1，不过这样做太傻了。最佳方案是用我们自己的函数替换掉默认的parseInt()： 123456789101112131415'use strict';var count = 0;var oldParseInt = parseInt; // 保存原函数window.parseInt = function () &#123; count += 1; return oldParseInt.apply(null, arguments); // 调用原函数&#125;;// 测试:parseInt('10');parseInt('20');parseInt('30');console.log('count = ' + count); // 3 高阶函数js的最基础的高阶函数，就是把一个函数作为另一个函数的参数 1234function add(x, y, f) &#123; return f(x) + f(y);&#125;add(-5, 6, Math.abs);//返回abs(5)+abs(6) map/reducejs的map/reduce和python的基本一样，只是调用方法略有区别，是x.map(function) 123var arr = [1, 2, 3, 4, 5, 6, 7, 8, 9];var results = arr.map(pow); // [1, 4, 9, 16, 25, 36, 49, 64, 81]console.log(results); 1234var arr = [1, 3, 5, 7, 9];arr.reduce(function (x, y) &#123; return x + y;&#125;); // 25 filter用于把array的某些元素过滤掉 12345var arr = [1, 2, 4, 5, 6, 9, 10, 15];var r = arr.filter(function (x) &#123; return x % 2 !== 0;&#125;);r; // [1, 5, 9, 15] sortsort方法用于排序 12345678// 看上去正常的结果:['Google', 'Apple', 'Microsoft'].sort(); // ['Apple', 'Google', 'Microsoft'];// apple排在了最后:根据ASCII码，小写字母a在大写字母之后['Google', 'apple', 'Microsoft'].sort(); // ['Google', 'Microsoft", 'apple']// 无法理解的结果: array的sort方法默认把所有元素转换换为string再排序[10, 20, 1, 2].sort(); // [1, 10, 2, 20] 因为sort的这种默认的排序往往不能达到要求，因此需要自己定义sort当中的条件函数 12345678910var arr = [10, 20, 1, 2];arr.sort(function (x, y) &#123; if (x &lt; y) &#123; return 1; &#125; if (x &gt; y) &#123; return -1; &#125; return 0;&#125;); // [20, 10, 2, 1] 返回1的时候表示要换位置，返回-1表示不换位置 闭包闭包就是在一个函数内部再定义一个函数，执行函数的时候返回的不是值，而是函数 1234567891011121314151617//普通的求和函数function sum(arr) &#123; return arr.reduce(function (x, y) &#123; return x + y; &#125;);&#125;sum([1, 2, 3, 4, 5]); // 15//闭包function lazy_sum(arr) &#123; var sum = function () &#123; return arr.reduce(function (x, y) &#123; return x + y; &#125;); &#125; return sum;&#125; 匿名函数创建一个函数并立即执行的方法称为匿名函数 1(function (x) &#123; return x * x &#125;) (3);//由于js语法限制，要用小括号括起来 箭头函数ES6新增的一种函数 1x =&gt; x * x; 上面的箭头函数相当于： 123function (x) &#123; return x * x;&#125; 参数不止一个的时候要用括号括起来： 123456789101112// 两个参数:(x, y) =&gt; x * x + y * y// 无参数:() =&gt; 3.14// 可变参数:(x, y, ...rest) =&gt; &#123; var i, sum = x + y; for (i=0; i&lt;rest.length; i++) &#123; sum += rest[i]; &#125; return sum;&#125; 如果要返回一个对象，就要注意，如果是单表达式，这么写的话会报错： 1234// SyntaxError:x =&gt; &#123; foo: x &#125;//因为和函数体的&#123; ... &#125;有语法冲突，所以要改为：x =&gt; (&#123; foo: x &#125;) 生成器生成器和python当中的类似，用yield返回，用next访问 标准对象js中所有都是对象，用typeof来查看对象类型 123456789typeof 123; // 'number'typeof NaN; // 'number'typeof 'str'; // 'string'typeof true; // 'boolean'typeof undefined; // 'undefined'typeof Math.abs; // 'function'typeof null; // 'object'typeof []; // 'object'typeof &#123;&#125;; // 'object' 包装对象js提供包装对象，包装对象的关系就像java当中的int和Intenger的关系，Intenger这种包装对象要用new来创建，js当中的number、boolean和string都有包装对象 ，就是首字母大写，虽然包装对象看上去和原来的值一模一样，显示出来也是一模一样，但他们的类型已经变为object了！所以，包装对象和原始值用===比较会返回false： 123456var n = new Number(123); // 123,生成了新的包装类型var b = new Boolean(true); // true,生成了新的包装类型var s = new String('str'); // 'str',生成了新的包装类型typeof new Number(123); // 'object'new Number(123) === 123; // false 如果在使用Number、Boolean和String时，没有写new ，那么这三个函数就是类型转换函数 注意： 不要使用new Number()、new Boolean()、new String()创建包装对象； 用parseInt()或parseFloat()来转换任意类型到number； 用String()来转换任意类型到string，或者直接调用某个对象的toString()方法； 通常不必把任意类型转换为boolean再判断，因为可以直接写if (myVar) {...}； typeof操作符可以判断出number、boolean、string、function和undefined； 判断Array要使用Array.isArray(arr)； 判断null请使用myVar === null； 判断某个全局变量是否存在用typeof window.myVar === &#39;undefined&#39;； 函数内部判断某个变量是否存在用typeof myVar === &#39;undefined&#39;。 Datejs中Date对象用于获取日期和时间： 1234567891011var now = new Date();now; // Wed Jun 24 2015 19:49:22 GMT+0800 (CST)now.getFullYear(); // 2015, 年份now.getMonth(); // 5, 月份，注意月份范围是0~11，5表示六月now.getDate(); // 24, 表示24号now.getDay(); // 3, 表示星期三now.getHours(); // 19, 24小时制now.getMinutes(); // 49, 分钟now.getSeconds(); // 22, 秒now.getMilliseconds(); // 875, 毫秒数now.getTime(); // 1435146562875, 以number形式表示的时间戳 如果要创建一个指定日期和时间的Date对象，可以用： 12var d = new Date(2015, 5, 19, 20, 15, 30, 123);d; // Fri Jun 19 2015 20:15:30 GMT+0800 (CST) JavaScript的月份范围用整数表示是0~11，0表示一月，1表示二月……，所以要表示6月，我们传入的是5！ 第二种创建一个指定日期和时间的方法是解析一个符合ISO 8601格式的字符串： 12var d = Date.parse('2015-06-24T19:49:22.875+08:00');d; // 1435146562875 但它返回的不是Date对象，而是一个时间戳。不过有时间戳就可以很容易地把它转换为一个Date： 123var d = new Date(1435146562875);d; // Wed Jun 24 2015 19:49:22 GMT+0800 (CST)d.getMonth(); // 5 时区浏览器可以把时间戳正确转换为本地时间 时间戳是个什么东西？时间戳是一个自增的整数，它表示从1970年1月1日零时整的GMT时区开始的那一刻，到现在的毫秒数。假设浏览器所在电脑的时间是准确的，那么世界上无论哪个时区的电脑，它们此刻产生的时间戳数字都是一样的，所以，时间戳可以精确地表示一个时刻，并且与时区无关。 123var d = new Date(1435146562875);d.toLocaleString(); // '2015/6/24 下午7:49:22'，本地时间（北京时区+8:00），显示的字符串与操作系统设定的格式有关d.toUTCString(); // 'Wed, 24 Jun 2015 11:49:22 GMT'，UTC时间，与本地时间相差8小时 获取时间戳的方法如下： 1new Date().getTime() 正则表达式js当中的正则表达式的写法和python是一样的，创建正则表达式的方法有两种 第一种是直接通过/正则表达式/写出来，第二种方式是通过new RegExp(&#39;正则表达式&#39;)创建一个RegExp对象 re.test(string)方法用于判断正则表达式是否匹配，这个re就是一个正则表达式对象 1234var re = /^\d&#123;3&#125;\-\d&#123;3,8&#125;$/;re.test('010-12345'); // truere.test('010-1234x'); // falsere.test('010 12345'); // false 切分字符串js切分字符串也是用split()实现的，用这则表达式可以通过任意形式切分 123456//通过空格切分'a b c'.split(' '); // ['a', 'b', '', '', 'c']//通过任意个空格切分'a b c'.split(/\s+/); // ['a', 'b', 'c']//通过任意空格和逗号切分'a,b, c d'.split(/[\s\,]+/); // ['a', 'b', 'c', 'd'] 提取子串js用exec提取子串，子串在正则表达式中用括号括起来 exec()方法在匹配成功后，会返回一个Array，第一个元素是正则表达式匹配到的整个字符串，后面的字符串表示匹配成功的子串。 123var re = /^(\d&#123;3&#125;)-(\d&#123;3,8&#125;)$/;re.exec('010-12345'); // ['010-12345', '010', '12345']re.exec('010 12345'); // null 同样?可以使得正则表达式进行非贪婪匹配 全局搜索js的正则表达式有几个特殊的标志，最常用的是g，表示全局匹配 123var r1 = /test/g;// 等价于:var r2 = new RegExp('test', 'g'); 全局匹配可以多次执行exec()方法来搜索一个匹配的字符串。当我们指定g标志后，每次运行exec()，正则表达式本身会更新lastIndex属性，表示上次匹配到的最后索引： 123456789var s = 'JavaScript, VBScript, JScript and ECMAScript';var re=/[a-zA-Z]+Script/g;// 使用全局匹配:re.exec(s); // ['JavaScript']re.lastIndex; // 10re.exec(s); // ['VBScript']re.lastIndex; // 20 JSONJSON是JavaScript Object Notation的缩写，是一种数据存储格式 在JSON中，一共就这么几种数据类型： number：和JavaScript的number完全一致； boolean：就是JavaScript的true或false； string：就是JavaScript的string； null：就是JavaScript的null； array：就是JavaScript的Array表示方式——[]； object：就是JavaScript的{ ... }表示方式。 为了统一解析，JSON的字符串规定必须用双引号&quot;&quot;，Object的键也必须用双引号&quot;&quot;。 可以用JSON.stringify(object, attribute, format)将对象变为json输出，第一个参数是对象名，第二个参数是属性名或者是转换函数，第三个参数用于控制格式（一般是有多少个空格） 12345678910var xiaoming = &#123; name: '小明', age: 14, gender: true, height: 1.65, grade: null, 'middle-school': '\"W3C\" Middle School', skills: ['JavaScript', 'Java', 'Python', 'Lisp']&#125;;JSON.stringify(xiaoming, ['name', 'skills'], ' '); 结果： 123456789&#123; "name": "小明", "skills": [ "JavaScript", "Java", "Python", "Lisp" ]&#125; 如果第二个参数是转化函数 12345678function convert(key, value) &#123; if (typeof value === 'string') &#123; return value.toUpperCase(); &#125; return value;&#125;JSON.stringify(xiaoming, convert, ' '); 上面的代码把所有属性值都变成大写： 1234567891011121314&#123; "name": "小明", "age": 14, "gender": true, "height": 1.65, "grade": null, "middle-school": "\"W3C\" MIDDLE SCHOOL", "skills": [ "JAVASCRIPT", "JAVA", "PYTHON", "LISP" ]&#125; 反序列化如果你拿到一个JSON字符串，可以用JSON.parse()将其转换为js对象 1234JSON.parse('[1,2,3,true]'); // [1, 2, 3, true]JSON.parse('&#123;"name":"小明","age":14&#125;'); // Object &#123;name: '小明', age: 14&#125;JSON.parse('true'); // trueJSON.parse('123.45'); // 123.45 parse还可以加上一个处理函数 1234567var obj = JSON.parse('&#123;"name":"小明","age":14&#125;', function (key, value) &#123; if (key === 'name') &#123; return value + '同学'; &#125; return value;&#125;);console.log(JSON.stringify(obj)); // &#123;name: '小明同学', age: 14&#125; JS面向对象JS没有class的概念，如果要进行继承要用Object.create()方法，实质就是将一个类的prototype指向另一个类 12345678910111213var Student = &#123; name: 'Robot', height: 1.2, run: function () &#123; console.log(this.name + ' is running...'); &#125;&#125;;var xiaoming = &#123; name: '小明'&#125;;xiaoming.__proto__ = Student; 在编写JavaScript代码时，不要直接用obj.__proto__去改变一个对象的原型。Object.create()方法可以传入一个原型对象，并创建一个基于该原型的新对象 12345678910111213141516171819// 原型对象:var Student = &#123; name: 'Robot', height: 1.2, run: function () &#123; console.log(this.name + ' is running...'); &#125;&#125;;function createStudent(name) &#123; // 基于Student原型创建一个新对象: var s = Object.create(Student); // 初始化新对象: s.name = name; return s;&#125;var xiaoming = createStudent('小明');xiaoming.run(); // 小明 is running... 构造函数new一个对象，就是构造函数，如果不写new，那么就是一个普通函数，返回的是undefined 123456789function Student(name) &#123; this.name = name; this.hello = function () &#123; alert('Hello, ' + this.name + '!'); &#125;&#125;var xiaoming = new Student('小明');xiaoming.name; // '小明'xiaoming.hello(); // Hello, 小明! 新创建的xiaoming的原型链是： 1xiaoming ----&gt; Student.prototype ----&gt; Object.prototype ----&gt; null 原型继承class继承原型继承章节比较难，之后会回过来看 ES6引入了class关键字，可以直接包含构造函数和定义在原型上的其他函数 123456789class Student &#123; constructor(name) &#123; this.name = name; &#125; hello() &#123; alert('Hello, ' + this.name + '!'); &#125;&#125; 有了class之后，直接用extends就可以继承，调用父类方法直接用super 12345678910class PrimaryStudent extends Student &#123; constructor(name, grade) &#123; super(name); // 记得用super调用父类的构造方法! this.grade = grade; &#125; myGrade() &#123; alert('I am at grade ' + this.grade); &#125;&#125; 浏览器js可以获取浏览器对象并对其操作，window不光是全局作用域，还表示浏览器窗口，window对象有innerWidth和innerHeight属性 ，可以获取浏览器窗口的内部宽度和高度。内部宽高是指除去菜单栏、工具栏、边框等占位元素后，用于显示网页的净宽高。 1console.log('window inner size: ' + window.innerWidth + ' x ' + window.innerHeight); navigator通常包含的是浏览器信息，常用的属性包括： navigator.appName：浏览器名称； navigator.appVersion：浏览器版本； navigator.language：浏览器设置的语言； navigator.platform：操作系统类型； navigator.userAgent：浏览器设定的User-Agent字符串。 操作DOMHTML文件被浏览器解析为一棵DOM（Document Object Model）树，要改变HTML的结构，就要用js来操作DOM 对DOM的操作主要有以下几种： 更新：更新该DOM节点的内容，相当于更新了该DOM节点表示的HTML的内容； 遍历：遍历该DOM节点下的子节点，以便进行进一步操作； 添加：在该DOM节点下新增一个子节点，相当于动态增加了一个HTML节点； 删除：将该节点从HTML中删除，相当于删掉了该DOM节点的内容以及它包含的所有子节点。 拿到DOM节点和之前用selenium写爬虫的方法基本是一致的，方法主要有document.getElementById()和document.getElementsByTagName()，以及CSS选择器document.getElementsByClassName() 123456789101112131415// 返回ID为'test'的节点：var test = document.getElementById('test');// 先定位ID为'test-table'的节点，再返回其内部所有tr节点：var trs = document.getElementById('test-table').getElementsByTagName('tr');// 先定位ID为'test-div'的节点，再返回其内部所有class包含red的节点：var reds = document.getElementById('test-div').getElementsByClassName('red');// 获取节点test下的所有直属子节点:var cs = test.children;// 获取节点test下第一个、最后一个子节点：var first = test.firstElementChild;var last = test.lastElementChild; 还有一种是跟scrapy写爬虫的时候的query选择器差不多的语法 12345// 通过querySelector获取ID为q1的节点：var q1 = document.querySelector('#q1');// 通过querySelectorAll获取q1节点内的符合条件的所有节点：var ps = q1.querySelectorAll('div.highlighted &gt; p'); 修改DOM直接修改拿到的节点的innerHTML内容，这要把HTML的内容替换进去： 1234// 获取&lt;p id="p-id"&gt;...&lt;/p&gt;var p = document.getElementById('p-id');// 设置文本为abc:p.innerHTML = 'ABC'; // &lt;p id="p-id"&gt;ABC&lt;/p&gt; 还有一种是替换innerText或者innerContent，这样替换的只是html标签中间的文字内容，不能改变html内容 123456// 获取&lt;p id="p-id"&gt;...&lt;/p&gt;var p = document.getElementById('p-id');// 设置文本:p.innerText = '&lt;script&gt;alert("Hi")&lt;/script&gt;';// HTML被自动编码，无法设置一个&lt;script&gt;节点:// &lt;p id="p-id"&gt;&amp;lt;script&amp;gt;alert("Hi")&amp;lt;/script&amp;gt;&lt;/p&gt; 两者的区别在于读取属性时，innerText不返回隐藏元素的文本，而textContent返回所有文本 还可以通过js修改css样式，直接对对象的Object.style.xxx进行修改 12345// 获取&lt;p id="p-id"&gt;...&lt;/p&gt;var p = document.getElementById('p-id');// 设置CSS:p.style.color = '#ff0000';p.style.fontSize = '20px'; 所有修改的css样式名称用驼峰命名法 插入DOM如果一个标签原本是空的，你直接修改它的innerHTML就相当于插入了一个DOM 如果不是空的，就需要用appendChild方法，将一个子节点加到父节点的最后一个节点 1234567&lt;!-- HTML结构 --&gt;&lt;p id="js"&gt;JavaScript&lt;/p&gt;&lt;div id="list"&gt; &lt;p id="java"&gt;Java&lt;/p&gt; &lt;p id="python"&gt;Python&lt;/p&gt; &lt;p id="scheme"&gt;Scheme&lt;/p&gt;&lt;/div&gt; 把&lt;p id=&quot;js&quot;&gt;JavaScript&lt;/p&gt;添加到&lt;div id=&quot;list&quot;&gt;的最后一项： 1234var js = document.getElementById('js'), list = document.getElementById('list');list.appendChild(js); 现在，HTML结构变成了这样： 1234567&lt;!-- HTML结构 --&gt;&lt;div id="list"&gt; &lt;p id="java"&gt;Java&lt;/p&gt; &lt;p id="python"&gt;Python&lt;/p&gt; &lt;p id="scheme"&gt;Scheme&lt;/p&gt; &lt;p id="js"&gt;JavaScript&lt;/p&gt;&lt;/div&gt; 因为我们插入的js是从html中获取的，因此相当于把上面的节点append到了下面 当然你也可以通过document.createElement(&#39;tag&#39;)来建立某个标签，然后再appendChild 123456var list = document.getElementById('list'), haskell = document.createElement('p');haskell.id = 'haskell';haskell.innerText = 'Haskell';list.appendChild(haskell); 如果要插入到指定位置，那么就用insertBefore函数，用法是父节点.insertBefore(新节点，参考节点)，这样就把新节点插到了参考节点之前 1234567var list = document.getElementById('list'), ref = document.getElementById('python'), haskell = document.createElement('p');haskell.id = 'haskell';haskell.innerText = 'Haskell';list.insertBefore(haskell, ref); 删除DOM删除一个节点只需要得到父节点和本身，然后用父节点.removechild(本身)移除掉特定的节点 1234567// 拿到待删除节点:var self = document.getElementById('to-be-removed');// 拿到父节点:var parent = self.parentElement;// 删除:var removed = parent.removeChild(self);removed === self; // true js操作表单js操作表单和操作DOM类似，因为表单本身也是DOM HTML表单的输入控件主要有以下几种： 文本框，对应的&lt;input type=&quot;text&quot;&gt;，用于输入文本； 密码框，对应的&lt;input type=&quot;password&quot;&gt;，用于输入口令； 单选框，对应的&lt;input type=&quot;radio&quot;&gt;，用于选择一项； 复选框，对应的&lt;input type=&quot;checkbox&quot;&gt;，用于选择多项； 下拉框，对应的&lt;select&gt;，用于选择一项； 隐藏文本，对应的&lt;input type=&quot;hidden&quot;&gt;，用户不可见，但表单提交时会把隐藏文本发送到服务器。 先获取一个表单，然后直接对value赋值，就可以改变value的值 123// &lt;input type="text" id="email"&gt;var input = document.getElementById('email');input.value; // '用户输入的值' 这种方式可以应用于text、password、hidden以及select。但是，对于单选框和复选框，应该用checked判断是否被勾上，也可以对他们设置值将其勾上： 123456789// &lt;label&gt;&lt;input type="radio" name="weekday" id="monday" value="1"&gt; Monday&lt;/label&gt;// &lt;label&gt;&lt;input type="radio" name="weekday" id="tuesday" value="2"&gt; Tuesday&lt;/label&gt;var mon = document.getElementById('monday');var tue = document.getElementById('tuesday');mon.value; // '1'tue.value; // '2'mon.checked; // true或者falsetue.checked; // true或者falsemon.checked = true; //勾上mon这个选项 HTML5控件HTML5比标准的HTML多了几种控件，常用的有date、datetime、datetime-local、color等，它们都使用&lt;input&gt;标签 123&lt;input type="date" value="2015-07-01"&gt;&lt;input type="datetime-local" value="2015-07-01T02:03:04"&gt;&lt;input type="color" value="#ff0000"&gt; 提交表单js有两种方式提交表单，在提交的时候可以对form当中的值进行修改或者是判断是否符合规则 第一种是通过&lt;form&gt;元素的submit()方法进行提交 1234567891011121314&lt;!-- HTML --&gt;&lt;form id="test-form"&gt; &lt;input type="text" name="test"&gt; &lt;button type="button" onclick="doSubmitForm()"&gt;Submit&lt;/button&gt;&lt;/form&gt;&lt;script&gt;function doSubmitForm() &#123; var form = document.getElementById('test-form'); // 可以在此修改form的input... // 提交form: form.submit();&#125;&lt;/script&gt; 这种方式的缺点是扰乱了浏览器对form的正常提交。浏览器默认点击&lt;button type=&quot;submit&quot;&gt;时提交表单，或者用户在最后一个输入框按回车键。因此，第二种方式是响应&lt;form&gt;本身的onsubmit事件，在提交form时作修改： 1234567891011121314&lt;!-- HTML --&gt;&lt;form id="test-form" onsubmit="return checkForm()"&gt; &lt;input type="text" name="test"&gt; &lt;button type="submit"&gt;Submit&lt;/button&gt;&lt;/form&gt;&lt;script&gt;function checkForm() &#123; var form = document.getElementById('test-form'); // 可以在此修改form的input... // 继续下一步: return true;&#125;&lt;/script&gt; 最后一定要return true，这样浏览器才会提交表单，如果return false浏览器就不会提交表单 在检查和修改&lt;input&gt;时，要充分利用&lt;input type=&quot;hidden&quot;&gt;来传递数据。 例如，很多登录表单希望用户输入用户名和口令，但是，安全考虑，提交表单时不传输明文口令，而是口令的MD5。普通JavaScript开发人员会直接修改&lt;input&gt;： 12345678910111213141516&lt;!-- HTML --&gt;&lt;form id="login-form" method="post" onsubmit="return checkForm()"&gt; &lt;input type="text" id="username" name="username"&gt; &lt;input type="password" id="password" name="password"&gt; &lt;button type="submit"&gt;Submit&lt;/button&gt;&lt;/form&gt;&lt;script&gt;function checkForm() &#123; var pwd = document.getElementById('password'); // 把用户输入的明文变为MD5: pwd.value = toMD5(pwd.value); // 继续下一步: return true;&#125;&lt;/script&gt; 这个做法看上去没啥问题，但用户输入了口令提交时，口令框的显示会突然从几个*变成32个*（因为MD5有32个字符）。 要想不改变用户的输入，可以利用&lt;input type=&quot;hidden&quot;&gt;实现： 123456789101112131415161718&lt;!-- HTML --&gt;&lt;form id="login-form" method="post" onsubmit="return checkForm()"&gt; &lt;input type="text" id="username" name="username"&gt; &lt;input type="password" id="input-password"&gt; &lt;input type="hidden" id="md5-password" name="password"&gt; &lt;button type="submit"&gt;Submit&lt;/button&gt;&lt;/form&gt;&lt;script&gt;function checkForm() &#123; var input_pwd = document.getElementById('input-password'); var md5_pwd = document.getElementById('md5-password'); // 把用户输入的明文变为MD5: md5_pwd.value = toMD5(input_pwd.value); // 继续下一步: return true;&#125;&lt;/script&gt; 注意到id为md5-password的&lt;input&gt;标记了name=&quot;password&quot;，而用户输入的id为input-password的&lt;input&gt;没有name属性。没有name属性的&lt;input&gt;的数据不会被提交。 上传文件HTML当中上传文件，用到的唯一控件就是&lt;inpt type=&quot;file&quot;&gt; 注意：当一个表单包含&lt;input type=&quot;file&quot;&gt;时，表单的enctype必须指定为multipart/form-data，method必须指定为post，浏览器才能正确编码并以multipart/form-data格式发送表单的数据。 一般来说上传文件由后台处理，js可以在提交时对文件名称进行检查，以防止上传无效格式的文件 123456var f = document.getElementById('test-file-upload');var filename = f.value; // 'C:\fakepath\test.png'if (!filename || !( filename.endsWith('.jpg') || filename.endsWith('.png') || filename.endsWith('.gif'))) &#123; alert('Can only upload image file.'); return false;&#125; File APIHTML5新增的File API允许js读取文件内容，提供了File和FileReader两个主要对象，可以获取文件信息并读取文件 下面这段代码是预览图片并显示相关信息的代码 123456789101112131415161718192021222324252627282930313233var fileInput = document.getElementById('test-image-file'), info = document.getElementById('test-file-info'), preview = document.getElementById('test-image-preview');// 监听change事件:fileInput.addEventListener('change', function () &#123; // 清除背景图片: preview.style.backgroundImage = ''; // 检查文件是否选择: if (!fileInput.value) &#123; info.innerHTML = '没有选择文件'; return; &#125; // 获取File引用: var file = fileInput.files[0]; // 获取File信息: info.innerHTML = '文件: ' + file.name + '&lt;br&gt;' + '大小: ' + file.size + '&lt;br&gt;' + '修改: ' + file.lastModifiedDate; if (file.type !== 'image/jpeg' &amp;&amp; file.type !== 'image/png' &amp;&amp; file.type !== 'image/gif') &#123; alert('不是有效的图片文件!'); return; &#125; // 读取文件: var reader = new FileReader(); reader.onload = function(e) &#123; var data = e.target.result; // 'data:image/jpeg;base64,/9j/4AAQSk...(base64编码)...' preview.style.backgroundImage = 'url(' + data + ')'; &#125;; // 以DataURL的形式读取文件: reader.readAsDataURL(file);&#125;); 这一部分的回调函数也不是太懂，之后会再回来看看 AJAXAJAX（Asynchronous JavaScript and XML ）就是异步加载的JavaScript，一般提交一个Form，点击submit之后浏览器就会刷新页面，告诉你成功还是失败，web就是这样，一次HTTP请求对应一个页面 如果你想要用户留在当前页面，同时发出HTTP请求，就必须要用js发送请求，接收到数据后再用js更新页面。这样页面没有刷新，但是数据不断地更新。 AJAX请求是异步执行的，也就是说，要通过回调函数获得响应。 在现代浏览器上写AJAX主要依靠XMLHttpRequest对象： 1234567891011121314151617181920212223242526272829303132function success(text) &#123; var textarea = document.getElementById('test-response-text'); textarea.value = text;&#125;function fail(code) &#123; var textarea = document.getElementById('test-response-text'); textarea.value = 'Error code: ' + code;&#125;var request = new XMLHttpRequest(); // 新建XMLHttpRequest对象request.onreadystatechange = function () &#123; // 状态发生变化时，函数被回调 if (request.readyState === 4) &#123; // 成功完成 // 判断响应结果: if (request.status === 200) &#123; // 成功，通过responseText拿到响应的文本: return success(request.responseText); &#125; else &#123; // 失败，根据响应码判断失败原因: return fail(request.status); &#125; &#125; else &#123; // HTTP请求还在继续... &#125;&#125;// 发送请求:request.open('GET', '/api/categories');request.send();alert('请求已发送，请等待响应...'); 当创建了XMLHttpRequest对象后，要先设置onreadystatechange的回调函数。在回调函数中，通常我们只需通过readyState === 4判断请求是否完成，如果已完成，再根据status === 200判断是否是一个成功的响应。 请求第三方网站数据CORSCORS全称Cross-Origin Resource Sharing，是HTML5规范定义的如何跨域访问资源。 只要浏览器的相应的Access-Control-Allow-Origin包含本域，则此次跨域请求成功 PromisePromise是一种ajax异步加载，比较难，之后再看 Canvascanvas可以用来画图 1&lt;canvas id="test-canvas" width="300" height="200"&gt;&lt;/canvas&gt; getContext(&#39;2d&#39;)方法让我们拿到一个CanvasRenderingContext2D对象，所有的绘图操作都需要通过这个对象完成。 1var ctx = canvas.getContext('2d'); 左上角为原点，其余为x，y轴开始画图 1234567891011121314151617var canvas = document.getElementById('test-shape-canvas'), ctx = canvas.getContext('2d');ctx.clearRect(0, 0, 200, 200); // 擦除(0,0)位置大小为200x200的矩形，擦除的意思是把该区域变为透明ctx.fillStyle = '#dddddd'; // 设置颜色ctx.fillRect(10, 10, 130, 130); // 把(10,10)位置大小为130x130的矩形涂色// 利用Path绘制复杂路径:var path=new Path2D();path.arc(75, 75, 50, 0, Math.PI*2, true);path.moveTo(110,75);path.arc(75, 75, 35, 0, Math.PI, false);path.moveTo(65, 65);path.arc(60, 65, 5, 0, Math.PI*2, true);path.moveTo(95, 65);path.arc(90, 65, 5, 0, Math.PI*2, true);ctx.strokeStyle = '#0000ff';ctx.stroke(path); jQueryJavaScript 简介 JavaScript 是互联网上最流行的脚本语言，这门语言可用于 HTML 和 web，更可广泛用于服务器、PC、笔记本电脑、平板电脑和智能手机等设备。 每一句后面添加“；” 放在html的head之间： ①&lt;script type=&quot;text/javascript&quot;&gt; &lt;/script&gt;； ②&lt;script src=&quot;script.js&quot;&gt; &lt;/script&gt; ; 直接写入 HTML 输出流12document.write("&lt;h1&gt;这是一个标题&lt;/h1&gt;");document.write("&lt;p&gt;这是一个段落。&lt;/p&gt;"); 输出多个内容时与python一样用+连接 输出html标签时（例如输出“&lt;br/&gt;”)，需要用引号扩上并用&lt;&gt;包围 对事件的反应1&lt;button type="button" onclick="alert('欢迎!')"&gt;点我!&lt;/button&gt; 改变 HTML 内容12x=document.getElementById("demo") //查找元素x.innerHTML="Hello JavaScript"; //改变内容 您会经常看到 document.getElementById(“some id“)。这个方法是 HTML DOM 中定义的。 DOM (Document Object Model)（文档对象模型）是用于访问 HTML 元素的正式 W3C 标准。 定义变量定义变量使用关键词var，语法如下： var 变量名 变量名可以任意取名，但要遵循命名规则: ​ 1.变量必须使用字母、下划线(_)或者美元符($)开始。 ​ 2.然后可以使用任意多个英文字母、数字、下划线(_)或者美元符($)组成。 ​ 3.不能使用JavaScript关键词与JavaScript保留字。 注意：Javascript里面区分大小写，变量mychar和myChar是不同的变量 条件判断语句语法： 1234if(条件)&#123; 条件成立时执行的代码 &#125;else&#123; 条件不成立时执行的代码 &#125; JavaScript定义函数关键字function，用法如下： 123function 函数名()&#123; 函数代码；&#125; 点击按钮出提示的例子： 123456789101112131415161718&lt;!DOCTYPE HTML&gt;&lt;html&gt;&lt;head&gt;&lt;meta http-equiv="Content-Type" content="text/html; charset=utf-8" /&gt;&lt;title&gt;函数调用&lt;/title&gt; &lt;script type="text/javascript"&gt; function contxt() //定义函数 &#123; alert("哈哈，调用函数了!"); &#125; &lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;form&gt; &lt;input type="button" value="点击我" onclick="contxt()"/&gt; &lt;/form&gt;&lt;/body&gt;&lt;/html&gt; alert 警告框alert是在屏幕上弹出一个警示框，点击确认之后消失，其使用方法如下： 12345678910111213141516&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;Document&lt;/title&gt; &lt;script type="text/javascript"&gt; function alert_test() &#123; var mychar = "一个警告"; alert(mychar); &#125; &lt;/script&gt;&gt;&lt;/head&gt;&lt;body&gt;&lt;input type="button" name="button" onclick="rec()" value="点击我弹出对话框"&gt;&lt;/body&gt;&lt;/html&gt; confirm 选择框confirm是在屏幕上弹出一个选择框，点击确认返回true，否则返回false 1234567891011121314151617181920212223&lt;!DOCTYPE HTML&gt;&lt;html&gt;&lt;head&gt;&lt;meta http-equiv="Content-Type" content="text/html; charset=utf-8" /&gt;&lt;title&gt;confirm&lt;/title&gt; &lt;script type="text/javascript"&gt; function rec()&#123; var mymessage= confirm("你是女士吗") ; if(mymessage==true) &#123; document.write("你是女士!"); &#125; else &#123; document.write("你是男士!"); &#125; &#125; &lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;input name="button" type="button" onClick="rec()" value="点击我，弹出确认对话框" /&gt;&lt;/body&gt;&lt;/html&gt; prompt提示框“”是弹出一个提示框，同时你可以在这个提示框中输入值并返回 1234567891011121314151617181920212223242526272829303132&lt;!DOCTYPE HTML&gt;&lt;html&gt;&lt;head&gt;&lt;meta http-equiv="Content-Type" content="text/html; charset=utf-8" /&gt;&lt;title&gt;prompt&lt;/title&gt; &lt;script type="text/javascript"&gt; function rec()&#123; var score; //score变量，用来存储用户输入的成绩值。 score = prompt("请输入你的成绩"); if(score&gt;=90) &#123; document.write("你很棒!"); &#125; else if(score&gt;=75) &#123; document.write("不错吆!"); &#125; else if(score&gt;=60) &#123; document.write("要加油!"); &#125; else &#123; document.write("要努力了!"); &#125; &#125; &lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;input name="button" type="button" onClick="rec()" value="点击我，对成绩做评价!" /&gt;&lt;/body&gt;&lt;/html&gt; 打开新窗口open() 方法可以查找一个已经存在或者新建的浏览器窗口。语法如下： 1window.open([URL], [窗口名称], [参数字符串]) 123456789窗口名称：可选参数，被打开窗口的名称。 1.该名称由字母、数字和下划线字符组成。 2.&quot;_top&quot;、&quot;_blank&quot;、&quot;_self&quot;具有特殊意义的名称。 _blank：在新窗口显示目标网页 _self：在当前窗口显示目标网页 _top：框架网页中在上部窗口中显示目标网页 3.相同 name 的窗口只能创建一个，要想创建多个窗口则 name 不能相同。 4.name 不能包含有空格。参数字符串：可选参数，设置窗口参数，各参数用逗号隔开。 关闭窗口window.close关闭窗口 DOMdom意思是document object model，文档对象模型，是把html代码分割成3类节点：文本节点，属性节点，元素节点的树形结构 通过id寻找元素document.getElementByid(&#39;id&#39;) innerHTML改变html元素内容用于改变html代码中的内容，通过docment.getElementById找到元素并赋值给object，然后用object.innerHTML = &quot;new content&quot;进行赋值 改变html样式用object.style.property =&quot;xxx&quot;来改变html中元素的样式，object是通过document.getElementById()取得的元素对象 显示或隐藏通过object.style.display = value，value的值为none或者是block 更改类名通过object.className=“xxx”改变一个元素的类名 移除style设置object.removeAttribute(&quot;style&quot;) 用于移除对元素style的设置]]></content>
      <categories>
        <category>编程学习</category>
      </categories>
      <tags>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTML教程.md]]></title>
    <url>%2F2017%2F06%2F29%2FHTML%E6%95%99%E7%A8%8B-md%2F</url>
    <content type="text"><![CDATA[HTML常用标签和属性参考 HTML定义超文本标记语言（英语：HyperText Markup Language，简称：HTML）是一种用于创建网页的标准标记语言。 HTML简介HTML实例网页中需要展示出来的内容都在&lt;body&gt;标签中，整体结构如下： 12345678910&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset='utf-8'&gt; &lt;/head&gt; &lt;body&gt; &lt;p&gt;.....&lt;/p&gt; &lt;a href='www.baidu.com'&gt;........&lt;/a&gt; &lt;/body&gt;&lt;/html&gt; 实例如下： 1234567891011121314&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset="utf-8"&gt;&lt;title&gt;菜鸟教程(runoob.com)&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;我的第一个标题&lt;/h1&gt; &lt;p&gt;我的第一个段落。&lt;/p&gt; &lt;/body&gt;&lt;/html&gt; &lt;!DOCTYPE html&gt;：表示为HTML5文档，这个声明不区分大小写 &lt;html&gt;：是HTML页面的根元素 &lt;head&gt;元素包含了文档的元&lt;meta&gt;数据 &lt;title&gt;元素表示文档的标题 &lt;body&gt;元素包含了可见的页面内容 &lt;h1&gt;元素定义了一个大标题 &lt;p&gt;元素定义了一个段落 &lt;meta charset=&quot;utf-8&quot;&gt;：可以使得输出中文时正常显示 &lt;q&gt;：表示引用 &lt;br/&gt;：换行符，回车在html文件中是无效的 &amp;nbsp;：空格符号 &lt;hr/&gt;：横线 &lt;code&gt;：代码，&lt;pre&gt;:多行代码 ​ HTML 元素语法 HTML 元素以开始标签起始 HTML 元素以结束标签终止 HTML 属性 HTML 元素可以设置属性 属性可以在元素中添加附加信息 属性一般描述于开始标签 属性总是以名称/值对的形式出现，比如：name=”value”。 HTML 链接 由 标签定义。链接的地址在 href 属性中指定： 1&lt;a href="http://www.runoob.com"&gt;这是一个链接&lt;/a&gt; HTML常用标签和属性参考 标签 描述 &lt;html&gt; 定义 HTML 文档 &lt;body&gt; 定义文档的主体 &lt;h1&gt;-&lt;h6&gt; 定义 HTML 标题 &lt;hr&gt; 定义水平线 &lt;!--...--&gt; 定义注释 HTML 文本格式化标签 标签 描述 &lt;b&gt; 定义粗体文本 &lt;em&gt; 定义着重文字 &lt;i&gt; 定义斜体字 &lt;small&gt; 定义小号字 &lt;strong&gt; 定义加重语气 &lt;sub&gt; 定义下标字 &lt;sup&gt; 定义上标字 &lt;ins&gt; 定义插入字 &lt;del&gt; 定义删除字 HTML 链接语法标签&lt;a&gt;加上属性href 1&lt;a href="www.baidu.com"&gt;百度&lt;/a&gt; 如果需要在新标签中打开网页，需要加上：target=&quot;_blank&quot; 1&lt;a href="www.baidu.com" target="_blank"&gt;百度&lt;/a&gt; 邮件语法在连接中使用mailto，第一个符号使用？分隔，后面用&amp;分隔 1&lt;a href = "mailto:xxxx@qq.com? &amp; cc=xxx@qq.com &amp; bcc=xxx@qq.com &amp; subject="主题" &amp; body="内容"&gt;发送按钮&lt;/a&gt; 表格实例由table标签开始，然后用tbody使表可以加载多少显示多少，th：table head表示表头，tr表示table row表行，td表示table data单元格 加入边框的方式有2种；第一种是直接加入border 属性，第二种是在&lt;head&gt;标签中加入style标签，具体如下： 123&lt;style type="text/css"&gt;table tr td,th&#123;border:1px solid #000;&#125;&lt;/style&gt; 表格标题caption 表格摘要用属性表示，&lt;table summary=“xxxxx” 12345678910&lt;table border="1"&gt; &lt;tr&gt; &lt;td&gt;row 1, cell 1&lt;/td&gt; &lt;td&gt;row 1, cell 2&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;row 2, cell 1&lt;/td&gt; &lt;td&gt;row 2, cell 2&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt; 表格标签是&lt;tr&gt;，每一个单元格的标签是&lt;td&gt;，边框的属性是border HTML无序列表无序列表是一个项目的列表，此列项目使用粗体圆点（典型的小黑圆圈）进行标记。 无序列表使用 标签，每个列表项始于 标签。 1234&lt;ul&gt;&lt;li&gt;Coffee&lt;/li&gt;&lt;li&gt;Milk&lt;/li&gt;&lt;/ul&gt; 有序列表始于 标签。每个列表项始于 标签。 1234&lt;ol&gt;&lt;li&gt;Coffee&lt;/li&gt;&lt;li&gt;Milk&lt;/li&gt;&lt;/ol&gt; 图片图片使用&lt;img sec=&quot;sss.jpg&quot;&gt;来表示，如果要改变鼠标滑过时的文字，加入title属性 1&lt;img src="aa.jpg" title="xxxx"&gt; HTML 表单表单用于把用户输入的数据传送到服务端 表单语法语法： 1&lt;form method="传送方式" action="服务器文件"&gt; 1.&lt;form&gt; ：&lt;form&gt;标签是成对出现的，以&lt;form&gt;开始，以&lt;/form&gt;结束。2.action ：浏览者输入的数据被传送到的地方,比如一个PHP页面(save.php) 3.method ： 数据传送的方式（get/post）。 123456&lt;form method="post" action="save.php"&gt; &lt;label for="username"&gt;用户名:&lt;/label&gt; &lt;input type="text" name="username" /&gt; &lt;label for="pass"&gt;密码:&lt;/label&gt; &lt;input type="password" name="pass" /&gt;&lt;/form&gt; 输入大段多行文字用到texarea 1&lt;textarea rows="行数" cols="列数"&gt;文本&lt;/textarea&gt; 复选框ratio：圆框 checkbox：方框 如果要做到单选效果，就需要名字相同 语法： 1&lt;input type="radio/checkbox" value="值" name="名称" checked="checked"/&gt; 下拉框select标签，每个选项使用&lt;option&gt;标签 value为向系统提交的值，后面的文字为显示的内容 123456789&lt;form action="save.php" method="post" &gt; &lt;label&gt;爱好:&lt;/label&gt; &lt;select&gt; &lt;option value="看书"&gt;看书&lt;/option&gt; &lt;option value="旅游"&gt;旅游&lt;/option&gt; &lt;option value="运动"&gt;运动&lt;/option&gt; &lt;option value="购物"&gt;购物&lt;/option&gt; &lt;/select&gt;&lt;/form&gt; 提交按钮：&lt;input type=&quot;submit&quot; value=&quot;提交&quot;/&gt; 重置按钮：&lt;input type=&quot;reset&quot; value=&quot;重置&quot;&gt; label&lt;label&gt;：作用是点击文字时也可以选定复选框，不需要移动到框那里]]></content>
      <categories>
        <category>编程学习</category>
      </categories>
      <tags>
        <tag>网页</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[XML教程.md]]></title>
    <url>%2F2017%2F06%2F10%2FXML%E6%95%99%E7%A8%8B-md%2F</url>
    <content type="text"><![CDATA[XML 指可扩展标记语言（eXtensible Markup Language），被设计用来传输和存储数据。 XML结构 XML整体采用“树形结构”，从根开始，扩展到叶子节点。 1234567&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;note&gt;&lt;to&gt;Tove&lt;/to&gt;&lt;from&gt;Jani&lt;/from&gt;&lt;heading&gt;Reminder&lt;/heading&gt;&lt;body&gt;Don't forget me this weekend!&lt;/body&gt;&lt;/note&gt; 第一行&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;表示的是xml使用的版本和编码方式 第二行是&lt;note&gt;根元素 接下来的四行描述了4个子元素：to，from，heading，body 1234&lt;to&gt;Tove&lt;/to&gt;&lt;from&gt;Jani&lt;/from&gt;&lt;heading&gt;Reminder&lt;/heading&gt;&lt;body&gt;Don't forget me this weekend!&lt;/body&gt; 最后一行定义根元素结果&lt;/note&gt; 上述的结构可以看做Jani给Tove的一封便签 XML由根元素开始，向下扩展子元素，其关系为父子，同级之间的元素关系为同胞 XML语法 文档必须有根元素 XML 声明文件的可选部分，如果存在需要放在文档的第一行，如下所示：&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt; 所有XML都必须有开始和结束标签&lt;p&gt;xxxxxx&lt;/p&gt; XML标签对大小写敏感 XML的元素可以有属性值（名称/值的对），属性值必须加引号 1234&lt;note date="12/11/2007"&gt;&lt;to&gt;Tove&lt;/to&gt;&lt;from&gt;Jani&lt;/from&gt;&lt;/note&gt; &lt;在xml文件中表示一个元素的开始，因此如果想使用小于符号时，应该利用实体引用来代替“&lt;”字符 1&lt;message&gt;if salary &amp;lt; 1000 then&lt;/message&gt; &amp;lt &lt; less than &amp;gt &gt; grater than &amp;amp &amp; ampersand &amp;apos ‘ apostrophe &amp;quot “ quotation mark 在 XML 中编写注释的语法与 HTML 的语法很相似。&lt;!-- This is a comment --&gt; HTML 会把多个连续的空格字符裁减（合并）为一个，但是XML中空格不会减少 在 Windows 应用程序中，换行通常以一对字符来存储：回车符（CR）和换行符（LF）。XML 以 LF 存储换行。 XML 元素XML 命名规则XML 元素必须遵循以下命名规则： 名称可以包含字母、数字以及其他的字符 名称不能以数字或者标点符号开始 名称不能以字母 xml（或者 XML、Xml 等等）开始 名称不能包含空格 XML 属性&lt;file type=&quot;gif&quot;&gt;computer.gif&lt;/file&gt;其中的type=&quot;gif&quot;就是xml中元素的属性，属性必须添加引号]]></content>
      <categories>
        <category>编程学习</category>
      </categories>
      <tags>
        <tag>XML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python爬虫从入门到精通]]></title>
    <url>%2F2017%2F05%2F22%2Fpython%E7%88%AC%E8%99%AB%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A%2F</url>
    <content type="text"><![CDATA[第一讲什么是爬虫 网络蜘蛛（Web spider）也叫网络爬虫（Web crawler），蚂蚁（ant），自动检索工具（automatic indexer），或者（在FOAF软件概念中）网络疾走（WEB scutter），是一种“自动化浏览网络”的程序，或者说是一种网络机器人。它们被广泛用于互联网搜索引擎或其他类似网站，以获取或更新这些网站的内容和检索方式。它们可以自动采集所有其能够访问到的页面内容，以供搜索引擎做进一步处理（分检整理下载的页面），而使得用户能更快的检索到他们需要的信息。 总结：自动抓取数据 爬虫能做什么 搜索引擎 抢票 下载资料（图片等） 爬虫的本质是什么模仿浏览器打开网页 第二讲:HTTP协议什么是HTTP协议 超文本传输协议（英文：HyperText Transfer Protocol，缩写：HTTP）是互联网上应用最为广泛的一种网络协议。设计HTTP最初的目的是为了提供一种发布和接收HTML页面的方法。通过HTTP或者HTTPS协议请求的资源由统一资源标识符（Uniform Resource Identifiers，URI）来标识。 HTTP的发展是由蒂姆·伯纳斯-李于1989年在欧洲核子研究组织（CERN）所发起。由万维网协会（World Wide Web Consortium，W3C）和互联网工程任务组（Internet Engineering Task Force，IETF）制定标准，最终发布了一系列的RFC，其中最著名的是1999年6月公布的 RFC 2616，定义了HTTP协议中现今广泛使用的一个版本——HTTP 1.1。 2014年12月，互联网工程任务组（IETF）的Hypertext Transfer Protocol Bis（httpbis）工作小组将HTTP/2标准提议递交至IESG进行讨论[1]，于2015年2月17日被批准。[2] HTTP/2标准于2015年5月以RFC 7540正式发表，替换HTTP 1.1成为HTTP的实现标准。[3] HTTP是一个客户端终端（用户）和服务器端（网站）请求和应答的标准（TCP）。通过使用网页浏览器、网络爬虫或者其它的工具，客户端发起一个HTTP请求到服务器上指定端口（默认端口为80）。我们称这个客户端为用户代理程序（user agent）。应答的服务器上存储着一些资源，比如HTML文件和图像。我们称这个应答服务器为源服务器（origin server）。在用户代理和源服务器中间可能存在多个“中间层”，比如代理服务器、网关或者隧道（tunnel）。 尽管TCP/IP协议是互联网上最流行的应用，HTTP协议中，并没有规定必须使用它或它支持的层。事实上，HTTP可以在任何互联网协议上，或其他网络上实现。HTTP假定其下层协议提供可靠的传输。因此，任何能够提供这种保证的协议都可以被其使用。因此也就是其在TCP/IP协议族使用TCP作为其传输层。 通常，由HTTP客户端发起一个请求，创建一个到服务器指定端口（默认是80端口）的TCP连接。HTTP服务器则在那个端口监听客户端的请求。一旦收到请求，服务器会向客户端返回一个状态，比如”HTTP/1.1 200 OK”，以及返回的内容，如请求的文件、错误消息、或者其它信息。 具体例子打开知乎页面，按浏览器的F12键，点击network，点击doc，然后刷新页面，再点击headers，可以看到如下界面： 其中： HTTP协议中的统一资源定位符也就是我们打开的网址 1Request URL:https://zhuanlan.zhihu.com/p/25296437 （爬虫会用到） HTTP协议中的请求方法,我们这次用的是GET 1Request Method:GET #（爬虫会用到） 请求方法有以下这些，常用的是GET,POST GET：向指定的资源发出“显示”请求。使用GET方法应该只用在读取数据，而不应当被用于产生“副作用”的操作中，例如在Web Application中。其中一个原因是GET可能会被网络蜘蛛等随意访问。参见安全方法 POST：向指定资源提交数据，请求服务器进行处理（例如提交表单或者上传文件）。数据被包含在请求本文中。这个请求可能会创建新的资源或修改现有资源，或二者皆有。 OPTIONS：这个方法可使服务器传回该资源所支持的所有HTTP请求方法。用’*’来代替资源名称，向Web服务器发送OPTIONS请求，可以测试服务器功能是否正常运作。 HEAD：与GET方法一样，都是向服务器发出指定资源的请求。只不过服务器将不传回资源的本文部分。它的好处在于，使用这个方法可以在不必传输全部内容的情况下，就可以获取其中“关于该资源的信息”（元信息或称元数据）。 PUT：向指定资源位置上传其最新内容。 DELETE：请求服务器删除Request-URI所标识的资源。 TRACE：回显服务器收到的请求，主要用于测试或诊断。 CONNECT：HTTP/1.1协议中预留给能够将连接改为管道方式的代理服务器。通常用于SSL加密服务器的链接（经由非加密的HTTP代理服务器）。 对应HTTP协议中的状态码,我们这次返回的是200 OK、 1Status Code:200 OK（爬虫会用到） 状态码的含义： 1xx消息——请求已被服务器接收，继续处理 2xx成功——请求已成功被服务器接收、理解、并接受 3xx重定向——需要后续操作才能完成这一请求 4xx请求错误——请求含有词法错误或者无法被执行 5xx服务器错误——服务器在处理某个正确请求时发生错误 常见状态代码、状态描述、说明： 200 OK //请求成功 400 Bad Request //客户端请求有语法错误，不能被服务器所理解 401 Unauthorized //请求未经授权，这个状态代码必须和WWW-Authenticate报头域一起使用 403 Forbidden //服务器收到请求，但是拒绝提供服务 404 Not Found //请求资源不存在，eg：输入了错误的URL 500 Internal Server Error //服务器发生不可预期的错误 503 Server Unavailable //服务器当前不能处理客户端的请求，一段时间后可能恢复正常 请求头 1Accept:text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8（爬虫会用到） 其中 Accept代表客户端请求接受的信息类型，这里请求的是text/html类型 Accept-Encoding：gzip, deflate, sdch, br：请求报头域类似于Accept，但是它是用于指定可接受的内容编码。eg：Accept-Encoding:gzip.deflate.如果请求消息中没有设置这个域服务器假定客户端对各种内容编码都可以接受。 Accept-Language:zh-CN,zh;q=0.8：指定语言类型，如果没有报头域，那么各种语言都可以接受 Cache-Control:no-cache：用于控制网页缓存 Connection:keep-alive：HTTP持久连接，使用同一个TCP来发送和接收多个HTTP请求/应答 Cookie:d_c0=&quot;AACAWNtZswqPTnJ8dFXqaygiq82ekPD5_-xxxx：cookie，小型文本文件，某些网站为了辨别用户身份而存储在本地终端上的数据 Host:zhuanlan.zhihu.com：当前请求网页的请求域 Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 用户是通过什么工具来请求的，（因为我用的Google浏览器，所以显示的是Chrome） Referer:https://www.zhihu.com/people/pa-chong-21/activities 是通过哪个页面到当前页面的 1234If-Modified-Since:Wed, 15 Feb 2017 09:14:13 GMTIf-None-Match:W/&quot;58a41be5-190aa&quot;Last-Modified:Wed, 15 Feb 2017 09:14:13 GMTETag:&quot;58a41be5-190aa&quot; 这4个一般静态页面会用到 If-Modified-Since,If-None-Match这两个是请求头，ETag,Last-Modified是返回头（服务器返回的） 如果If-Modified-Since的值和Last-Modified相等 则表明当前请求的内容没有变动，服务器返回Status Code:304 Not Modified ​]]></content>
      <categories>
        <category>编程学习</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库基础教程]]></title>
    <url>%2F2017%2F05%2F11%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[SQL简介 SQL是什么 SQL，指结构化查询语言，全称是 Structured Query Language。 SQL能做什么 SQL 面向数据库执行查询 SQL 可从数据库取回数据 SQL 可在数据库中插入新的记录 SQL 可更新数据库中的数据 SQL 可从数据库删除记录 SQL 可创建新数据库 SQL 可在数据库中创建新表 SQL 可在数据库中创建存储过程 SQL 可在数据库中创建视图 SQL 可以设置表、存储过程和视图的权限 RDBMSRDBMS 指关系型数据库管理系统，全称 Relational Database Management System。 RDBMS 中的数据存储在被称为表的数据库对象中。 表是相关的数据项的集合，它由列和行组成。 连接数据库的方法mysql -u root -p：在cmd中输入之后键入密码，则命令行处于mysql&gt;状态 SHOW DATABASES;：显示DATABASE CREATE DATABASE database_name;：创建新的database use database_name;：改变database的名字 source C:\xxxx.sql;：使用.sql文件 注意每一句mysql命令后面一定要加上“ ; ” SQL语法数据库表一个数据库通常包含一个或多个表。每个表由一个名字标识，表包含带有数据的记录（行）。 SQL不区分大小写 常用的SQL命令 SELECT - 从数据库中提取数据 UPDATE - 更新数据库中的数据 DELETE - 从数据库中删除数据 INSERT INTO - 向数据库中插入新数据 CREATE DATABASE - 创建新数据库 ALTER DATABASE - 修改数据库 CREATE TABLE - 创建新表 ALTER TABLE - 变更（改变）数据库表： DROP TABLE - 删除表 CREATE INDEX - 创建索引（搜索键） DROP INDEX - 删除索引 select 列名称 from 表名称 [查询条件];：从表里面选出所需要的列 SELECT DISTINCT column_name from table_name：从表中选出所有可能值（不重复） select 列名称 from 表名称 where 条件;：从表中选出符合条件的项目 SELECT column_name form table_name where A and B 或者SELECT column_name form table_name where A and B：条件表达式的and和or SELECT column_name FROM table_name ORDER BY column_name ASC|DESC：升序或者降序排列 INSERT INTO table_name VALUES (value1,value2,...)：无需指定要插入数据的列名 insert [into] 表名 [(列名1, 列名2, 列名3, ...)] values (值1, 值2, 值3, ...);：插入值 update 表名称 set 列名称=新值 where 更新条件;：更新表 DELETE FROM table_name WHERE some_column = some_value;用于删除表中的行 alter table 表名 add 列名 列数据类型 [after 插入位置];：添加列 alter table 表名 change 列名称 列新名称 新数据类型;：修改列 alter table 表名 drop 列名称;：删除列 alter table 表名 rename 新表名;：重命名列 drop table 表名;：删除表 drop database 数据库名;：删除数据库 修改密码: mysqladmin -u root -p password 新密码：修改sql密码]]></content>
      <categories>
        <category>编程学习</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python练习册 from github]]></title>
    <url>%2F2017%2F05%2F09%2Fpython%E7%BB%83%E4%B9%A0%E5%86%8C-from-github%2F</url>
    <content type="text"><![CDATA[第 0001 题： 做为 Apple Store App 独立开发者，你要搞限时促销，为你的应用生成激活码（或者优惠券），使用 Python 如何生成 200 个激活码（或者优惠券）？ 解决思路 首先，我们想到要编写一个200大小的循环，放置一个new_active的激活码生成函数 new_active函数：既然要随机，那么我们就要有random模块，import random模块进来，主要使用的是random.choice 函数，从大写字母，小写字母以及数字当中选择 大写字母:string.upper，小写字母：string.lower，数字range(0,10)，但是前两个是string类型的list，range是int类型，在后面&quot;&quot;.join(list)的时候就无法拼接，所以我们用了[str(i) for i in range(0,10) ]，这样就保证了在最后可以把生成的字符串拼接起来 123456789101112131415161718import randomimport stringimport pprint# from random import *def new_activation(n): choice_list = list(string.lowercase) + list(string.uppercase) + [str(i) for i in range(0,10)] string_temp = [] for i in xrange(n): temp_string = random.choice(choice_list) string_temp.append(temp_string) string_temp = "".join(string_temp) return string_tempactiva_list = []for i in range(2): activa_list.append(new_activation(110))pprint.pprint(activa_list) 第 0002 题：将 0001 题生成的 200 个激活码（或者优惠券）保存到 MySQL 关系型数据库中。 解决思路 MySql教程详见mysql教程 安装数据库，仅需要安装SQL sever即可 使用SQlite3包，连接只需要conn = sqlite3.connect(&#39;xx.db&#39;)，然后建立cursor，cursor = conn.cursor,之后就可以建立数据表，然后存储数据了 建表的sql命令， 123sql = '''CREATE TABLE `activate`(\ `ID` integer PRIMARY KEY NOT NULL,\ # integer表示自增 `ACTIVATE_CODE` char(20) NOT NULL )''' 存储的命令 1sql1 = "INSERT INTO ACTIVATE (ACTIVATE_CODE) VALUES ('%s')"%activate_list[i] 其中activate_list[i]表示每次需要存储的激活码的值 详细代码 12345678910111213141516171819202122232425262728293031323334#!/usr/bin/env python# -*- coding: utf-8 -*-# @Time : 2017/5/11 18:27from activate import new_activationimport osimport sqlite3activate_list = []for i in range(100): activate_list.append(new_activation(20))if os.path.exists('./active.db'): os.remove('./active.db')conn = sqlite3.connect('./active.db')cursor = conn.cursor()sql = '''CREATE TABLE `activate`(\ `ID` integer PRIMARY KEY NOT NULL,\ `ACTIVATE_CODE` char(20) NOT NULL )'''cursor.execute(sql)conn.commit()try: for i in range(100): sql1 = "INSERT INTO ACTIVATE (ACTIVATE_CODE) VALUES ('%s')"%activate_list[i] print sql1 cursor.execute(sql1)except Exception as e: raise efinally: sql2 = 'select * from activate' cursor.execute(sql2) print cursor.fetchall() conn.commit() cursor.close() conn.close() 第 0003 题：第 0003 题：将 0001 题生成的 200 个激活码（或者优惠券）保存到 Redis 非关系型数据库中。 解决思路 ridis非关系型数据库就是一个简化的关系型数据库，没有建表这些复杂的操作 连接数据库的函数 1r = redis.Redis(host='localhost',port=6379,db=0) 利用r.set(&#39;列名&#39;,数据值)存储数据，用r.get(&#39;列名&#39;)获取数据值 完整代码 1234567891011#!/usr/bin/env python# -*- coding: utf-8 -*-# @Time : 2017/5/11 18:27from activate import new_activationimport redisactivate_list = []for i in range(100): activate_list.append(new_activation(20))r = redis.Redis(host='localhost',port=6379,db=0)r.set('activate',activate_list)print r.get('activate') 第0004题任一个英文的纯文本文件，统计其中的单词出现的个数。 解题思路 首先要分离出每一个单词，主要用到re模块和string.punctuation，这样就可以从文本中用punctuation分离开来 其次要统计单词个数，就要去重，最简单的去重方式就是利用set 具体代码 123456789101112#!/usr/bin/env python# -*- coding: utf-8 -*-# @Time : 2017/5/11 22:21import refrom string import punctuationwith open(raw_input('filename:')) as f: text = f.read() punctuation = punctuation+' ' pat = '[%s]+' % punctuation word = re.split(pat,text) print word print len(set(word)) 第0005题你有一个目录，装了很多照片，把它们的尺寸变成都不大于 iPhone5 分辨率的大小。 解题思路 引用PIL(python image library)的Image包，其中的resize方法，可以调整图片大小 os.walk方法返回一个元组迭代器，然后用for root, dirs, files in list_dir:可以得到根目录，目录名和文件名 123456789101112131415import osfrom PIL import Imagedef resize(filename,new_name): pic = Image.open(filename) out = pic.resize((100,200),Image.ANTIALIAS) out.save(new_name,quality=100)list_dir = os.walk(r'C:\Users\jeffrey\Desktop\python exercise\python练习册\5\pic')for root, dirs, files in list_dir: for f in files: a = os.path.join(root, f) print a new_name = os.path.join(root,'new_1'+f) print new_name resize(a,new_name) 第 0006 题：你有一个目录，放了你一个月的日记，都是 txt，为了避免分词的问题，假设内容都是英文，请统计出你认为每篇日记最重要的词。 解题思路 引用第0004题的方法，可以分离单词，然后遍历单词，就可以得到每个单词的出现次数 123456789101112131415161718192021222324#!/usr/bin/env python# -*- coding: utf-8 -*-# @Time : 2017/5/12 20:24import refrom string import punctuationwith open('a.txt') as f: text = f.read() punctuation = punctuation+' ' pat = '[%s]+' % punctuation word = re.split(pat,text) w = &#123;&#125; for w1 in word: count = 0 for w2 in word: if w1 == w2: count += 1 w[w1]=count print w cou = 0 for key,value in w.iteritems(): if value &gt; cou: cou = value key_temp = keyprint key_temp 第 0007 题：有个目录，里面是你自己写过的程序，统计一下你写过多少行代码。包括空行和注释，但是要分别列出来。 解题思路1.有目录的问题，一定会用到os.walk函数,使用方法如下 1234list_dir = os.walk(raw_input("dictionary name:"))for root, dirs, files in list_dir: for f in files: with open(os.path.join(root,f)) 注意，这里只需要join(root，f)就可以得到所有文件的地址 具体代码 1234567891011121314151617181920212223#!/usr/bin/env python# -*- coding: gbk -*-# @Time : 2017/5/14 18:31import osif __name__ == '__main__': list_dir = os.walk(raw_input("dictionary name:")) pat = '\n' code_num = 0 annotation_num = 0 for root, dirs, files in list_dir: for f in files: file_name = os.path.join(root,f) with open(file_name) as ff: text = ff.read() sentence = text.split(pat) for line in sentence: if line.strip().startswith('#') or line.strip() == '': annotation_num = annotation_num + 1 else: code_num += 1 print annotation_num print code_num 第0008题：一个HTML文件，找出里面的正文。 解题思路 先要获取网页内容，urlib2.open(&#39;www.baidu.com&#39;).read() 要想解析网页，想到网页解析器，在网上查到可以利用readability模块的Document ，找出正文的话就用get_content函数就可以了 源码：123456import urllib2from readability import Documenthtml = urllib2.urlopen('https://github.com/drawwon/show-me-the-code')#(raw_input('please input the file name:'))text = html.read()doc = Document(text)print doc.content() 第0009题：一个HTML文件，找出里面的链接。 解题思路 获取网页内容，urlib2.open(&#39;www.baidu.com&#39;).read() 找出连接，只要用re模块匹配(http://.+)，re.findall(pat,text)就找到了 源码：12345678import reimport urllib2from readability import Documenthtml = urllib2.urlopen('https://github.com/drawwon/show-me-the-code')#(raw_input('please input the file name:'))text = html.read()pat = re.compile('"(http.+?)"')links = re.findall(pat, text)print links 第0010题使用 Python 生成类似于下图中的字母验证码图片 解题思路 要处理图片，肯定用到PIL(Python Image Library) 首先用pil.Image.new(&#39;RGB&#39;,(width,height),0xffff)新建一张空白图片 从字母(string.letters)和数字&#39;&#39;.join([str(i) for i in range(10)])里面随机选值，用到random.choice 要画图就要用到ImageDraw.Draw(pic) 然后从三个随机的颜色中选一个来填满图片，draw.point(xy,fill=random.choice(color1)) 然后字母随机取颜色并画上，draw.text(xy,text,fill,font=font))，其中字体是ImageFont.truetype(&quot;arial.ttf&quot;,80) 要得到模糊图片，用PIL当中的filter函数进行高斯滤波，参数为ImageFilter.BLUR ​ 效果 源码1234567891011121314151617181920212223242526from __future__ import divisionimport stringimport randomfrom PIL import ImageDrawfrom PIL import Image,ImageFont,ImageFilterl = []num = 4for j in range(num): l.append(random.choice(string.letters+''.join([str(i) for i in range(10)])))pic = Image.new('RGB',(500,200),0xffff)draw = ImageDraw.Draw(pic)color2 = ['purple','green','brown']color1 = ['BurlyWood','DarkGray','DarkOliveGreen']width, height = pic.sizefor i in range(width+1): for j in range(height+1): draw.point(xy=(i,j),fill=random.choice(color1))font = ImageFont.truetype("arial.ttf", 100)for i in range(len(l)): x = i*width/num+5 c = random.choice(color2) draw.text(xy=(x,50),text=l[i],fill=c,font=font)pic = pic.filter(ImageFilter.BLUR)pic.show()pic.save('a.jpg') 第 0011 题敏感词文本文件 filtered_words.txt，里面的内容为以下内容，当用户输入敏感词语时，则打印出 Freedom，否则打印出 Human Rights。北京 程序员 公务员 领导 牛比 牛逼 你娘 你妈 love sex jiangge 解题思路 while 1的循环，如果在列表里打印freedom，否则打印Human rights 源代码1234567b_list = ['北京','程序员','公务员','领导','牛比','牛逼','你娘','你妈','love','sex','jiangge']while 1: a = raw_input('请输入词汇:') if a in b_list: print 'freedom' else: print 'human 中国' 第 0012 题敏感词文本文件 filtered_words.txt，里面的内容 和 0011题一样，当用户输入敏感词语，则用 星号 替换，例如当用户输入「北京是个好城市」，则变成「*是个好城市」。 解题思路 一个txt文件读入之后是ascii的编码，是不能用于正则表达式的，从其他编码到unicode需要decode，而从unicode到utf-8之类的编码需要encode，因为系统认为unicode是通用编码，其他编码都是通过通用编码再编码得到的 打开文件的时候，可以用codecs.open指定编码格式 12 with codecs.open(filename,'r','utf-8') as f: text = f.read 正则表达式匹配的时候，最好都变成unicode编码来匹配 要匹配多个关键词的时候，可以用for 一个一个的匹配 源代码1234567891011121314151617181920212223242526#!/usr/bin/env python# -*- coding: utf-8 -*-# @Time : 2017/5/19 18:59import codecsimport reimport chardetb_list = ['北京','程序员','公务员','领导','牛比','牛逼','你娘','你妈','love','sex','jiangge']# with codecs.open('a.txt','r','utf-8') as f:# text = f.read()# print texttext = open('a.txt').read().decode('utf-8')pat_f = ''for i in b_list: pat_f = pat_f + '[' + i + ']' + '+'# pat_f = pat_f.encode('utf-8', 'unicode')# b = re.findall(u'(北京)+', text)pat_f = pat_f.decode('utf-8')print type(pat_f)print type(text)for i in b_list: pat = str('('+ i +')' + '+').decode('utf-8') text = re.sub(u'%s'%pat, u'*'*(len(pat)-3), unicode(text))# a = re.sub(pat_f, '*', text)# print aprint text# print ''.join(b).encode('utf-8','gbk') 第0013题用 Python 写一个爬图片的程序，爬 这个链接里的日本妹子图片 :-) 解题思路 用urllib2.urlopen(&#39;***.com&#39;).read()打开网页获得网页内容 (r&#39;src=&quot;(http[s]?://.+?\.jp[e]?g)&quot;&#39;) 正则表达式，提取图片 用urllib.urlretrieve下载图片文件，其中的链接需要去重复，用set就可以去重了 源代码1234567891011121314151617181920212223242526#!/usr/bin/env python# -*- coding: utf-8 -*-# @Time : 2017/5/20 14:11import re,osimport urllib2,urllib,socketfrom PIL import Imagetext = urllib2.urlopen('https://www.zhihu.com/question/23535321').read()pat = re.compile(r'src="(http[s]?://.+?\.(jp[e]?g|png))"')# pat2 = re.compile(r'src="(.+?\.png)"')links = re.findall(pat, text)socket.setdefaulttimeout(10)print linkslinks = set(links)# links2 = re.findall(pat2, text)# print len(links2)if not os.path.exists(r'.\pic'): os.makedirs(r'.\pic')for i,p in enumerate(links): try: # print p[0] urllib.urlretrieve(p[0],r'.\pic\%s.jpg'%i) print '%s.jpg is downloading'%i except: print '%s.jpg download fail' % i pass 第0014题纯文本文件 student.txt为学生信息, 里面的内容（包括花括号）如下所示： 123456&gt; &#123;&gt; &quot;1&quot;:[&quot;张三&quot;,150,120,100],&gt; &quot;2&quot;:[&quot;李四&quot;,90,99,95],&gt; &quot;3&quot;:[&quot;王五&quot;,60,66,68]&gt; &#125;&gt; 请将上述内容写到 student.xls 文件中，如下图所示： 解题思路 txt文件是json格式，那我们那就引入json包，用json.loads()函数将txt转换为一个列表 要把列表写到excel中，要用到xlwt包，先用excel = wlwt.workbook()新建一个工作簿，然后用sheet = excel.add_sheet()加入一个sheet，然后用sheet.write(row,col, text)写入内容，最后excel.save(filename)保存xls 要遍历一个字典的key和value，用到for k,v in dict.items() 字典排序sorted(dict.items, key = lambda: x:x[0])，其中x是指前面要排序内容中的每一个元素 源代码1234567891011121314151617181920212223242526#!/usr/bin/env python# -*- coding: utf-8 -*-# @Time : 2017/5/25 15:42import csv,json,xlwtdef read_json(filename): return json.loads(open(filename).read().encode('gbk'))def write_to_csv(data,filename): dw = xlwt.Workbook() ws = dw.add_sheet("student",cell_overwrite_ok=True) row = 0 col = 0 print(data.items()) for k,v in sorted(data.items(), key=lambda d:d[0]): ws.write(row, col, k) for i in v: col = col+1 ws.write(row,col,i) row+=1 col=0 dw.save(filename)write_to_csv(read_json('a.txt'),'student.csv') 第0015题纯文本文件 city.txt为城市信息, 里面的内容（包括花括号）如下所示： { “1” : “上海”, “2” : “北京”, “3” : “成都” } 请将上述内容写到 city.xls 文件中，如下图所示： 解题思路主要方法同上题相似： 使用json包的json.loads()读入数据 使用xlwt，打开workbook，通过xlwt.add_sheet()添加新的子表格，通过for k,v in sorted(data,key= lambda d:d[0])得到经过排序后的key和value值，并通过xlrd的write方法写入表格ps.如果想输出在字典或者是list当中的中文，可以使用json.dumps(list, ensure_ascii=False)进行输出 源代码123456789101112131415161718192021222324#!/usr/bin/env python# -*- coding: utf-8 -*-# @Time : 2017/5/25 20:42import xlwt,jsondef excel_write(txtfile, csvfile): with open(txtfile) as f: data = json.loads(f.read().encode('gbk')) cs = xlwt.Workbook() shet = cs.add_sheet('student') row = 0 col = 0 for i,j in data.items(): shet.write(row,col,i) shet.write(row,col+1,j) row += 1 col = 0 cs.save(csvfile)if __name__ == '__main__': excel_write('a.txt','student.xls') 第0016题 纯文本文件 numbers.txt, 里面的内容（包括方括号）如下所示： 12345[ [1, 82, 65535], [20, 90, 13], [26, 809, 1024]] 请将上述内容写到 numbers.xls 文件中，如下图所示： 解题思路 与上题类似，先使用json包的load方法导入数据 使用xlwt包对数据写入xls文件中，在建立表格的时候，需要设置表格覆盖：wb.add_sheet(&#39;num&#39;,cell_overwrite_ok=True) 源代码1234567891011121314151617181920212223#!/usr/bin/env python# -*- coding: utf-8 -*-# @Time : 2017/5/25 21:28import xlwt,jsondef read_txt_to_xlsfile(txtfile,xlsfile): with open(txtfile) as f: data = json.loads(f.read().encode('utf-8')) wb = xlwt.Workbook() sheet = wb.add_sheet('num',cell_overwrite_ok=True) row = col = 0 print(data) for i in data: for j in i: sheet.write(row,col,j) col = col+1 row = row+1 col = 0 wb.save(xlsfile)if __name__ == '__main__': read_txt_to_xlsfile('number.txt','number.xls') 第0017题将 第 0014 题中的 student.xls 文件中的内容写到 student.xml 文件中，如下所示： 123456789101112131415&gt; &lt;?xml version="1.0" encoding="UTF-8"?&gt;&gt; &lt;root&gt;&gt; &lt;students&gt;&gt; &lt;!-- &gt; 学生信息表&gt; "id" : [名字, 数学, 语文, 英文]&gt; --&gt;&gt; &#123;&gt; "1" : ["张三", 150, 120, 100],&gt; "2" : ["李四", 90, 99, 95],&gt; "3" : ["王五", 60, 66, 68]&gt; &#125;&gt; &lt;/students&gt;&gt; &lt;/root&gt;&gt; 解题思路 要将xls文件写入到xml文件中，首先要将数据读取出来，使用xlrd模块的xlrd.open_workbook方法打开xls文件，然后ws = wb.sheet_by_index[0]找到工作表，然后通过有序字典存储学生信息 12345table = OrderDict()for i in range(ws.nrows) : key = ws.row_values(i)[0] value = ws.row_values(i)[1:] table[key] = value 打开xml文件，用with open(&#39;students.xml&#39;,&#39;w&#39;) as f：打开 要写xml文件要用到etree模块， 首先建立根节点root=etree.Element(&quot;root&quot;)， 然后以root为根节点建立树e_root = ElementTree(root)，建立子节点studentse_students = etree.subElement(root,&#39;students&#39;)， 写students子节点的内容e_students.text = &#39;\n&#39;+json.dumps(table, indent=4 , ensure_ascii=False)， 然后添加注释commente_students.append(etree.Comment(&#39;\n 学生信息表\n &quot;id&quot; : [名字，数学，语文，英语]\n&#39;))， 最后写入etree的unicode元素，f.write((&#39;&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#39;+etree.tounicode(e_root.getroot()))) 源代码12345678910111213141516171819202122232425#!/usr/bin/env python# -*- coding: utf-8 -*-# @Time : 2017/6/27 14:59import xlrd,jsonfrom lxml import etreefrom collections import OrderedDictdef xls2xml(xls_filename): with xlrd.open_workbook(xls_filename) as wb: ws = wb.sheet_by_index(0) table = OrderedDict() for i in range(ws.nrows): key = int(ws.row_values(i)[0]) value = str(ws.row_values(i)[1:]) table[key] = value with open("student.xml",'w') as f: root = etree.Element("root") e_root = etree.ElementTree(root) e_students = etree.SubElement(root,'students') e_students.text = '\n'+json.dumps(table,indent=4,ensure_ascii=False)+'\n' e_students.append(etree.Comment('\n 学生信息表\n "id" : [名字，数学，语文，英语]\n')) f.write(('&lt;?xml version="1.0" encoding="UTF-8"?&gt;'+etree.tounicode(e_root.getroot())))if __name__ == '__main__': xls2xml('student.xls') print 'done' 第0018题将 第 0015 题中的 city.xls 文件中的内容写到 city.xml 文件中，如下所示： 1234567891011121314&gt; &lt;?xmlversion="1.0" encoding="UTF-8"?&gt;&gt; &lt;root&gt;&gt; &lt;citys&gt;&gt; &lt;!-- &gt; 城市信息&gt; --&gt;&gt; &#123;&gt; "1" : "上海",&gt; "2" : "北京",&gt; "3" : "成都"&gt; &#125;&gt; &lt;/citys&gt;&gt; &lt;/root&gt;&gt; 解题思路 方法类似于0017题，首先将xls文件通过xlrd读出来，放在有序字典中 然后通过xml.dom.minidom模块建立Document，然后创建元素rootroot = xml.createElement(&#39;root&#39;)，然后建立子节点，最后写入xml文件中 源代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859#!/usr/bin/env python# -*- coding: utf-8 -*-# @Time : 2017/6/10 17:09import xlrd,jsonfrom xml.dom import minidom# def list2dict(list_name):# dic = &#123;&#125;# for list_element in list_name:# dic[list_element[0]] = list_element[1:]# return dicdef creat_and_write_xml(filename,row_data): xml = minidom.Document() root = xml.createElement('root') xml.appendChild(root) city = xml.createElement('city') root.appendChild(city) city.appendChild(xml.createComment("城市信息")) row_data = json.dumps(row_data,ensure_ascii=False,indent=1) text = xml.createTextNode(row_data.encode('utf-8')) city.appendChild(text) f = open(filename,'wb') f.write(xml.toprettyxml()) f.close()if __name__ == '__main__': data = xlrd.open_workbook('city.xls') table = data.sheet_by_index(0) row_data = &#123;&#125; # res=[] # for i in range(table.nrows): # for j in range(table.ncols): # if isinstance(table.cell(i,j).value,unicode): # a = table.cell(i,j).value.encode('gb2312') # # print table.cell(i,j).value # elif isinstance(table.cell(i,j).value,float) or isinstance(table.cell(i,j).value, int): # a = unicode(table.cell(i,j).value).decode('utf-8').encode('gb2312') # # print table.cell(i, j).value # # # table.cell(i, j).value = str(table.cell(i, j).value).decode('utf-8').encode('gb2312') # res.append(a) # res.append("|") # # print res # res_string = ' '.join(res).split("|") # res_string.pop(-1) # print res_string,'11111111112' # for i in range(len(res_string)): # row_data[i+1] = res_string[i][1:] # print row_data for i in range(table.nrows): print ''.join(table.row_values(i)[1:]) row_data[i+1] = ''.join(table.row_values(i)[1:]) filename = 'city.xml' creat_and_write_xml(filename, row_data) 第0019题将 第 0016 题中的 numbers.xls 文件中的内容写到 numbers.xml 文件中，如下所示： 12345678910111213141516&gt; &lt;?xml version="1.0" encoding="UTF-8"?&gt;&gt; &lt;root&gt;&gt; &lt;numbers&gt;&gt; &lt;!-- &gt; 数字信息&gt; --&gt;&gt;&gt; [&gt; [1, 82, 65535],&gt; [20, 90, 13],&gt; [26, 809, 1024]&gt; ]&gt;&gt; &lt;/numbers&gt;&gt; &lt;/root&gt;&gt; 解题思路 整体思路与0018题类似，用xlrd文件读取xls文件内容 用xml.dom.minidom创建Document对象，然后通过创建名为root的elementxml.createElement(&#39;root&#39;)，然后通过xml.appendChild(root)把root添加为xml文件的根节点，创建并添加number节点，添加comment注释节点并添加为子节点，添加文本节点并添加为子节点，最终用topreetyxml写入xml 源代码1234567891011121314151617181920212223242526272829303132#!/usr/bin/env python# -*- coding: utf-8 -*-# @Time : 2017/6/10 17:09import xlrd,jsonfrom xml.dom import minidomdef creat_and_write_xml(filename,row_data): xml = minidom.Document() root = xml.createElement('root') xml.appendChild(root) number = xml.createElement('number') root.appendChild(number) number.appendChild(xml.createComment("城市信息")) row_data = json.dumps(row_data,ensure_ascii=False) text = xml.createTextNode(row_data.encode('utf-8')) number.appendChild(text) f = open(filename,'wb') f.write(xml.toprettyxml()) f.close()if __name__ == '__main__': data = xlrd.open_workbook('number.xls') table = data.sheet_by_index(0) row_data = &#123;&#125; for i in range(table.nrows): row_data[i+1] = table.row_values(i)[1:] filename = 'number.xml' creat_and_write_xml(filename, row_data) 第0020题 登陆中国联通网上营业厅 后选择「自助服务」 —&gt; 「详单查询」，然后选择你要查询的时间段，点击「查询」按钮，查询结果页面的最下方，点击「导出」，就会生成类似于 2014年10月01日～2014年10月31日通话详单.xls 文件。写代码，对每月通话时间做个统计。 解题思路 导出的文件是一个xls文件，我们使用xlrd模块读入内容 统计数据并通过plt.bar画直方图，第一个参数为横坐标，第二个参数为纵坐标，要想plt显示中文标注，需要： 12plt.rcParams['font.sans-serif']=['SimHei'] #用来正常显示中文标签plt.rcParams['axes.unicode_minus']=False #用来正常显示负号 源代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273#!/usr/bin/env python# -*- coding: utf-8 -*-# @Time : 2017/6/27 16:50import xlrd,re,pprintfrom collections import OrderedDictimport matplotlib.pyplot as pltimport numpy as npimport seabornplt.rcParams['font.sans-serif']=['SimHei'] #用来正常显示中文标签plt.rcParams['axes.unicode_minus']=False #用来正常显示负号wb = xlrd.open_workbook('2017-6.xls')ws = wb.sheet_by_index(0)def time2second(time): second_pattern = u'([0-9]+)秒' minute_pattern = u'([0-9]+)分' minute = re.findall(minute_pattern, time) second = re.findall(second_pattern, time) # print minute,second if minute: return int(minute[0]) * 60 + int(second[0]) else: if second: return int(second[0]) else: return 0data=[]for i in range(ws.nrows): data.append(ws.row_values(i))data.pop(0)call_num = OrderedDict()call_time = OrderedDict()month = '2017-06-'day_range = range(1,31)for i,item in enumerate(day_range): if item &lt; 10: day_range[i] = '0'+str(item) else: day_range[i] = str(i)date_range = [ month + day + " " for day in day_range]for date in date_range: call_num[date] = 0 call_time[date] = 0for row in range(len(data)): row_value = data[row] time = time2second(row_value[3]) for element in row_value: for date in date_range: if re.match(date,element): # print element call_num[date] = call_num[date] + 1 call_time[date] = call_time[date] + time# print call_num# print call_timenum = []time = []for i in call_num.iteritems(): num.append(i[1]) time.append(i[0])print numprint np.arange(len(num))plt.bar(np.arange(len(num)),num)plt.xticks(range(len(num)))plt.xlabel(u'6月通话时间')for i, v in enumerate(num): plt.text(i-0.35,v+0.2, str(v), color='blue', fontweight='bold')plt.show() 第0021题通常，登陆某个网站或者 APP，需要使用用户名和密码。密码是如何加密后存储起来的呢？请使用 Python 对密码加密。 解题思路 要想加密，可以使用hashlib.sha256库，使用os.random(8)生成一个长度为8位的salt，让密码与salt一起进行哈希，进行哈希的函数是hmac.HMAC 判定输入的密码是不是正确，只需要将新接受到的密码与原先的salt一起进行一次hash看是否等于之前的hash结果 源代码12345678910111213141516171819202122232425#!/usr/bin/env python# -*- coding: utf-8 -*-# @Time : 2017/6/28 11:00from hashlib import sha256from hmac import HMACimport osdef hash_password(password, salt = None): if isinstance(password, unicode): password = password.encode('UTF-8') if salt is None: salt = os.urandom(8) result = HMAC(password, salt, sha256).digest() return result,saltdef authen_password(result, new_password, salt): return hash_password(new_password,salt)[0] == resultif __name__ == '__main__': password = raw_input('please input the password: ') result,salt = hash_password(password) print result new_password = raw_input('please input the password again: ') print authen_password(result,password,salt) 第0022题 iPhone 6、iPhone 6 Plus 早已上市开卖。请查看你写得 第 0005 题的代码是否可以复用。 解题思路 整体思路与0005题类似，利用PIL.Image.resize函数对图片进行重塑大小 源代码12345678910111213141516171819#!/usr/bin/env python# -*- coding: gbk -*-# @Time : 2017/6/28 13:53import osfrom PIL import Imagedef resize(filename,new_name): pic = Image.open(filename) out = pic.resize((1000,800),Image.ANTIALIAS) out.save(new_name,quality=100)list_dir = os.walk(r'C:\Users\jeffrey\Desktop\python exercise\python练习册\22\pic')for root, dirs, files in list_dir: for f in files: a = os.path.join(root, f) print a new_name = os.path.join(root,'new_1'+f) print new_name resize(a,new_name) 第0023题使用 Python 的 Web 框架，做一个 Web 版本 留言簿 应用。 阅读资料：Python 有哪些 Web 框架 解题思路 使用的是flask框架，参照网上的示例，先在app文件夹下建立__init__.py，在文件中写入如下内容： 12345678from flask import FLASKfrom flask_mongoengine import MongoEngineapp = FLASK(__name__)app.config.from_object("config")db = MongoEngine(app)import views,models 其中的models.py定义了Todo类，包含内容，时间，和状态三个属性，如下所示: 123from . import dbimport datetimefrom flask_mongoengine.wtf import model_form class Todo(db.Document): content = db.StringField(required=True, max_length=20) time = db.DateTimeField(default=datetime.datetime.now()) status = db.IntField(default=0) TodoForm = model_form(Todo) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455其中`views.py`定义了每个页面的函数，如下：```pythonfrom . import appfrom flask import render_template, requestfrom models import Todo, TodoForm@app.route(&apos;/&apos;)def index(): form = TodoForm() todos = Todo.objects.order_by(&apos;-time&apos;) return render_template(&quot;index.html&quot;, todos=todos, form=form)@app.route(&apos;/add&apos;, methods=[&apos;POST&apos;, ])def add(): form = TodoForm(request.form) if form.validate(): content = form.content.data todo = Todo(content=content) todo.save() todos = Todo.objects.order_by(&apos;-time&apos;) return render_template(&quot;index.html&quot;, todos=todos, form=form)@app.route(&apos;/done/&lt;string:todo_id&gt;&apos;)def done(todo_id): form = TodoForm() todo = Todo.objects.get_or_404(id=todo_id) todo.status = 1 todo.save() todos = Todo.objects.all() return render_template(&apos;index.html&apos;, todos=todos, form=form)@app.route(&apos;/undone/&lt;string:todo_id&gt;&apos;)def undone(todo_id): form = TodoForm() todo = Todo.objects.get_or_404(id=todo_id) todo.status = 0 todo.save() todos = Todo.objects.all() return render_template(&quot;index.html&quot;, todos=todos,form=form)@app.route(&apos;/delete/&lt;string:todo_id&gt;&apos;)def delete(todo_id): form = TodoForm() todo = Todo.objects.get_or_404(id=todo_id) todo.delete() todos = Todo.objects.all() return render_template(&apos;index.html&apos;, todos=todos,form=form)@app.errorhandler(404)def not_found(e): return render_template(&apos;404.html&apos;),404 ​ 其中index.html文件是放在app/templates文件夹下的网页模板文件 所有关于index.html文件的静态文件（如js和css文件）均放在app/statics下面 在index.html文件中写入网页模板如下：如果要用到循环：大括号加百分号的形式，{ % for error in form.error.content % }要用到某个变量：双大括号，{ { } } t.content }} 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152&#123; % extends "base.html" % &#125; &#123; % block content % &#125; &lt;!--继承base.html--&gt;&lt;head&gt; &lt;style type="text/css"&gt; td&#123;text-align: center&#125; .content_td&#123;width: 100px&#125; .time_td&#123;width: 300px&#125; .done_td&#123;width: 100px&#125; &lt;/style&gt;&lt;/head&gt;&lt;form class="input-form" action="/add" method="post"&gt; &lt;!--输入框，记录输入的内容--&gt; &#123; &#123; &#125; &#125; form.hidden_tag() &#125;&#125; &#123; &#123; &#125; &#125; form.content(class="form-control") &#125;&#125; &lt;span class="input-btn"&gt; &lt;button class="btn-primary" type="submit"&gt;Add&lt;/button&gt; &lt;!--提交按钮--&gt; &lt;/span&gt;&lt;/form&gt;&#123; % for error in form.errors.content % &#125;&lt;div class="flash alert"&gt;&lt;span&gt;&#123; &#123; &#125; &#125; error &#125;&#125;&lt;/span&gt;&lt;/div&gt;&#123; % endfor % &#125;&lt;div&gt; &lt;h2&gt;Todo List&lt;/h2&gt; &#123; % if todos % &#125; &lt;table class="table" style="margin: 0 auto"&gt; &lt;thead&gt; &lt;tr&gt; &lt;td class="content_td"&gt;Content&lt;/td&gt; &lt;td class="time_td"&gt;Time&lt;/td&gt; &lt;td class="done_td"&gt;Operation&lt;/td&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &#123; % for t in todos % &#125; &lt;tr&gt; &lt;td class="content_td"&gt;&#123; &#123; &#125; &#125; t.content &#125;&#125;&lt;/td&gt; &lt;td class="time_td"&gt;&#123; &#123; &#125; &#125; t.time.strftime(' %m-%d %H:%M') &#125;&#125;&lt;/td&gt; &lt;td class="done_td"&gt; &#123; % if t.status == 0 % &#125; &lt;a href="/done/&#123; &#123; &#125; &#125; t.id &#125;&#125;" class="btn btn-primary" style="color: blue"&gt;Done&lt;/a&gt; &#123; % else % &#125; &lt;a href="/undone/&#123; &#123; &#125; &#125; t.id &#125;&#125;" class="btn btn-primary" style="color: red"&gt;Undone&lt;/a&gt; &#123; % endif % &#125; &lt;a href="/delete/&#123; &#123; &#125; &#125; t.id &#125;&#125;" class="delete btn"&gt;Delete&lt;/a&gt; &lt;/td&gt; &lt;/tr&gt; &#123; % endfor % &#125; &lt;/tbody&gt; &lt;/table&gt; &#123; % else % &#125; &lt;h3 style="color: red"&gt;NO Todos, please add things&lt;/h3&gt; &#123; % endif % &#125;&lt;/div&gt;&#123; % endblock % &#125; 而index.html文件继承于base.html文件如下： 123456789101112131415161718192021222324252627282930313233&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head lang="en"&gt; &lt;meta charset="UTF-8"&gt; &lt;style type="text/css"&gt; *&#123;text-align: center&#125; td&#123;line-height: 30px&#125; &lt;/style&gt; &lt;title&gt;to_do&lt;/title&gt; &lt;link href="&#123; &#123; &#125; &#125; url_for('static',filename='bootstrap.css') &#125;&#125;" rel="stylesheet" type="text/css"/&gt; &lt;link href="&#123; &#123; &#125; &#125; url_for('static',filename='index.css') &#125;&#125;" rel="stylesheet" type="text/css"/&gt;&lt;/head&gt;&lt;body&gt;&lt;div class="container"&gt; &lt;div class="page-header"&gt; &lt;h1&gt;my-flask-todo&lt;/h1&gt; &lt;/div&gt; &lt;div class="row"&gt; &lt;div class="col-lg-10"&gt; &#123; % block content % &#125; &#123; % endblock % &#125; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt;&lt;footer class="footer"&gt; &lt;div class="container"&gt; &lt;p class="text-muted"&gt;Copyright © drawon 2015&lt;/p&gt; &lt;/div&gt;&lt;/footer&gt;&lt;/body&gt;&lt;/html&gt; 在my_to_do/app的my_to_do文件夹下，写配置文件config.py 123SECRET_KEY = "never tell you"MONGODB_SETTINGS = &#123;'DB': 'todo_db'&#125;WTF_CSRF_ENABLED = False 在my_to_do/app的my_to_do文件夹下，写管理文件manage.py，通过这个py文件启动flask： 12345678910111213141516171819# -*- coding: utf-8 -*-from flask.ext.script import Manager, Serverfrom app import appfrom app.models import Todomanager = Manager(app) #定义Manager对象manager.add_command("runserver", Server(host='0.0.0.0', port=5000, use_debugger=True)) #通过add_command命令添加网页启动命令 runserver @manager.command # 添加新的命令save_tododef save_todo():todo = Todo(content="my first todo")todo.save()if name == 'main': manager.run() 在命令行运行 python manage.py runserver即可开启网页 源代码具体请查看github]]></content>
      <categories>
        <category>编程练习</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python基础教程（十五）：Python和Web]]></title>
    <url>%2F2017%2F04%2F20%2Fpython%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B%EF%BC%88%E5%8D%81%E4%BA%94%EF%BC%89%EF%BC%9Apython%E5%92%8Cweb%2F</url>
    <content type="text"><![CDATA[屏幕抓取想要抓取网页信息，可以用urllib和正则表达式做到：1234567from urllib import urlopenimport rep = re.compile('&lt;h3&gt;&lt;a .*?&gt;&lt;a .*? href="(.*?)"&gt;(.*?)&lt;/a&gt;')text = urlopen('http://python.org/community/jobs').read()for url, name in p.findall(text): print '%s (%s)'%(name, url) 正则表达式的模式相对固定，下面我们介绍Tidy和XHTML解析 Tidy和XHTML解析XHTML是HTML最新的方言，是XML的一种形式。 tidy 是什么tidy是用来修复不规范且有些随意的HTML文档的工具。 XHTML和HTML区别xhtml对显示关闭更加严格]]></content>
      <categories>
        <category>编程学习</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[markdown基础语法]]></title>
    <url>%2F2017%2F04%2F18%2Fmarkdown%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[表示标题级别]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git教程]]></title>
    <url>%2F2017%2F04%2F18%2Fgit%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[命令总结 本地git命令感觉git常用的几个：add\commit\checkout\merge\reset\push\pull，其他的都没怎么用 git add filename git commit -m “message” github命令$ ssh-keygen -t rsa -C &quot;youremail@example.com&quot; git 是什么Git是目前世界上最先进的分布式版本控制系统，简而言之，可以用作回滚文件版本，把你在过程中的任何版本都保留下来。 分布式和集中式的区别集中式：干活之前先从中央服务器获得文件的最新版本，干完活再推送给中央服务器，必须要联网（网速限制了其使用的效果） 分布式：每个人电脑上有一个完整的版本库，中央服务器只是用来交换大家的修改 安装gitLinux上安装git：123$ git The program 'git' is currently not installed. You can install it by typing:sudo apt-get install git Mac OS X上面安装gitXcode里面自带了git，因此你只需要从App Store安装Xcode即可 WINDOWS 安装gitWindows下要使用很多Linux/Unix的工具时，需要Cygwin这样的模拟环境，Git也一样。Cygwin的安装和配置都比较复杂，就不建议你折腾了。不过，有高人已经把模拟环境和Git都打包好了，名叫msysgit，只需要下载一个单独的exe安装程序，其他什么也不用装，绝对好用。 msysgit是Windows版的Git，从https://git-for-windows.github.io下载（网速慢的同学请移步国内镜像），然后按默认选项安装即可。安装完成后，在开始菜单里找到“Git”-&gt;“Git Bash”，蹦出一个类似命令行窗口的东西，就说明Git安装成功！ 安装完成之后，设置git的名字和email地址，用于在网络上区分用户 12$ git config --global user.name "Your Name"$ git config --global user.email "email@example.com" 创建版本库版本库又称为仓库，英文名为：repository，可以理解成一个目录，这个目录下任何文件的更改删除都能被git跟踪，任何时候都可以将其还原 创建一个版本库选择一个合适的地方创建一个空目录： 1234$ mkdir learngit$ cd learngit$ pwd/Users/michael/learngit pwd：用于显示当前所在目录的命令 使用windows系统是，请确保文件路径中没有中文 初始化git​1$ git init 此时你的文件夹中应该出现一个.git隐藏文件，如果要显示该隐藏文件，输入如下命令： ​1$ ls -a 其中ls的意思是list，列出 把文件添加到版本库首先这里再明确一下，所有的版本控制系统，其实只能跟踪文本文件的改动，比如TXT文件，网页，所有的程序代码等等，Git也不例外。版本控制系统可以告诉你每次的改动，比如在第5行加了一个单词“Linux”，在第8行删了一个单词“Windows”。而图片、视频这些二进制文件，虽然也能由版本控制系统管理，但没法跟踪文件的变化，只能把二进制文件每次改动串起来，也就是只知道图片从100KB改成了120KB，但到底改了啥，版本控制系统不知道，也没法知道。同样，word的改动也不能被跟踪。 注意：不能用windows自带的记事本来编写文件，因为其UTF-8的标准有问题（在文本最前面加了一段十六进制字符） 现在我们先建立一个readme.txt 文件，内容如下 12Git is a version control system.Git is free software. 把一个文件放到git只需要两部 用git add指令把文件添加到仓库1$ git add readme.txt 没有任何显示表示提交成功 用git commit指令告诉git，把文件提交到仓库 1234$ git commit -m "wrote a redme file"[master (root-commit) cb926e7] wrote a readme file 1 file changed, 2 insertions(+) create mode 100644 readme.txt 简单解释一下git commit命令，-m后面输入的是本次提交的说明，可以输入任意内容，当然最好是有意义的，这样你就能从历史记录里方便地找到改动记录 查看文件的各个版本我们现在修改readme.txt为如下内容: 12Git is a distributed version control system.Git is free software. 现在运行git status可以看到文件已经modified，但是还没有添加： 123456789$ git status# On branch master# Changes not staged for commit:# (use &quot;git add &lt;file&gt;...&quot; to update what will be committed)# (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory)## modified: readme.txt#no changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;) 接下来，我们使用git diff查看文件的具体变化： 123456789$ git diff readme.txt diff --git a/readme.txt b/readme.txtindex 46d49bf..9247db6 100644--- a/readme.txt+++ b/readme.txt@@ -1,2 +1,2 @@-Git is a version control system.+Git is a distributed version control system. Git is free software. git diff 顾名思义就是 difference 接下来，我们将提交文件，git add 1$ git add readme.txt 在执行git commit之前，我们先运行git status看看当前仓库状态 1234567$ git status# On branch master# Changes to be committed:# (use "git reset HEAD &lt;file&gt;..." to unstage)## modified: readme.txt# git status告诉我们，readme.txt文件将要被提交，接下来，我们是用git commit提交文件 123$ git commit -m "add distributed"[master ea34578] add distributed 1 file changed, 1 insertion(+), 1 deletion(-) 接下来，我们再用git status查看当前仓库的状态 123$ git status# On branch masternothing to commit (working directory clean) 版本回退现在已经学会了如何修改文件，那么我们再试着做一次，修改readme.txt文件内容如下： 12Git is a distributed version control system.Git is free software distributed under the GPL. 然后用git status查看git状态，然后用git diff查看修改的内容，最终用git add和git commit提交修改 1234$ git add readme.txt$ git commit -m "append GPL"[master 3628164] append GPL 1 file changed, 1 insertion(+), 1 deletion(-) 一旦出现错误，这样，我们就可以从最近的一个commit开始恢复 现在，我们回顾一下readme.txt文件一共有几个版本被提交到Git仓库里了： 版本1：wrote a readme file 12Git is a version control system.Git is free software. 版本2：add distributed 12Git is a distributed version control system.Git is free software. 版本3：append GPL 12Git is a distributed version control system.Git is free software distributed under the GPL. 用git log命令，我们可以查看从最近到最远的提交日志，我们可以看到3次提交，最近的一次是append GPL，上一次是add distributed，最早的一次是wrote a readme file。如果嫌输出信息太多，看得眼花缭乱的，可以试试加上--pretty=oneline参数： 首先，Git必须知道当前版本是哪个版本，在Git中，用HEAD表示当前版本，也就是最新的提交3628164...882e1e0（注意我的提交ID和你的肯定不一样），上一个版本就是HEAD^，上上一个版本就是HEAD^^，当然往上100个版本写100个^比较容易数不过来，所以写成HEAD~100。 运行： 12$ git reset --hard HEAD^HEAD is now at ea34578 add distributed hard指令的具体含义我们会在后面说明 此时看到，已经回到了上一个版本，但是我们会发现，最新的那个版本不见了。 为了找到最新的版本，我们应该向上找到那个版本号c82373d096fbc635b12d4cd，然后 12$ git reset --hard c82373HEAD is now at c82373 add distributed 版本号不用全部填写，只要写一部分就可以了 但是，如果我们已经关闭了串口怎么办，这个时候，我们就需要git reflog，找到之前的命令 12345$ git reflogea34578 HEAD@&#123;0&#125;: reset: moving to HEAD^3628164 HEAD@&#123;1&#125;: commit: append GPLea34578 HEAD@&#123;2&#125;: commit: add distributedcb926e7 HEAD@&#123;3&#125;: commit (initial): wrote a readme file 这样，我们看到第二行的id，我们就可以回滚了 小结： HEAD用来指定会退的版本，git reset --hard commit_id用来回退 可以用git log 查看历史版本 用git relog 查看历史命令，以回退历史版本 工作区和暂存区工作区工作区就是我们之前创建的git文件夹 版本库工作区当中有一个隐藏的.git文件，称为版本库，git版本库中保存了stage暂存区，和git自动创建的第一个分支master，以及指向master的一个指针叫head git add命令实际上就是把要提交的所有修改放到暂存区（Stage），然后，执行git commit就可以一次性把暂存区的所有修改提交到分支。 Git管理的是修改，比如你的文件修改后-&gt;add-&gt;第二次修改-&gt;commit，那么此时系统中保留的是你第一次修改的内容，可以用git diff HEAD -- readme.txt命令查看当前Git中的文件和最新的文件的区别 撤销修改用命令git reset HEAD file可以把暂存区的修改撤销掉（unstage），重新放回工作区： 场景1：当你改乱了工作区某个文件的内容，想直接丢弃工作区的修改时，用命令git checkout -- file。 场景2：当你不但改乱了工作区某个文件的内容，还添加到了暂存区时，想丢弃修改，分两步，第一步用命令git reset HEAD file，就回到了场景1，第二步按场景1操作。 删除文件一般情况下，你通常直接在文件管理器中把没用的文件删了，或者用rm命令删了： 1$ rm test.txt 现在，你可以用git rm test.txt来删除git中的文件，要么你可以用git checkout -- test.txt来恢复文件 使用github第1步：创建SSH Key。在用户主目录下，看看有没有.ssh目录，如果有，再看看这个目录下有没有id_rsa和id_rsa.pub这两个文件，如果已经有了，可直接跳到下一步。如果没有，打开Shell（Windows下打开Git Bash），创建SSH Key： 1$ ssh-keygen -t rsa -C &quot;youremail@example.com&quot; 如果一切顺利的话，可以在用户主目录里找到.ssh目录，里面有id_rsa和id_rsa.pub两个文件，这两个就是SSH Key的秘钥对，id_rsa是私钥，不能泄露出去，id_rsa.pub是公钥，可以放心地告诉任何人。 第2步：登陆GitHub，打开“Account settings”，“SSH Keys”页面：然后， 点“Add SSH Key”，填上任意Title，在Key文本框里粘贴id_rsa.pub文件的内容： 添加远程库首先，登陆GitHub，然后，在右上角找到“Create a new repo”按钮，创建一个新的仓库： 在本地的git仓库下运行命令： 1$ git remote add origin git@github.com:drawwon/learngit.git 请千万注意，把上面的drawwon替换成你自己的GitHub账户名，否则，你在本地关联的就是我的远程库，关联没有问题，但是你以后推送是推不上去的，因为你的SSH Key公钥不在我的账户列表中。 注意：此时如果失败，可能是因为你创建库的时候添加了readme文件，那么本地文件就少一个readme.md，因此我们要先从远程pull下来才行， 1git pull origin master --allow-unrelated-histories 最后的--allow-unrelated-histories：是因为github不允许两个没有建立连接的库进行通信 再次push 1$ git push -u origin master -u：与远程库的master分支连接起来，在以后推送时简化命令 从现在开始，只需要在本地使用如下命令，即可push到github 1$ git push origin master 命令小结要关联一个远程库，使用命令git remote add origin git@github.com:drawwon/repo-name.git； 关联后，使用命令git push -u origin master第一次推送master分支的所有内容； 此后，每次本地提交后，只要有必要，就可以使用命令git push origin master推送最新修改； 从远程库克隆要使用github开发最好的方式就是先在远程创建一个repository，勾选添加readme文件，然后git clone远程库 1$ git clone git@github.com:drawwon/learngit.git 或者 1$ git clone https://github.com/drawwon/leargit.git 但是通过原生git的方式最快 分支管理创建分支首先，我们传建一个dev分支，并切换到dev分支： 12$ git checkout -b devSwitched to a new branch &apos;dev&apos; git checkout命令加上-b参数表示创建并切换，相当于以下两条命令： 123$ git branch dev$ git checkout devSwitched to branch &apos;dev&apos; 我们修改readme.txt并提交： 1234$ git add readme.txt $ git commit -m &quot;branch test&quot;[dev fec145a] branch test 1 file changed, 1 insertion(+) 先在切换回master分支： 1git checkout master 可以看到我们之前增加的内容不见了 现在，我们把dev分支的成果合并到master上面： 1git merge &lt;name&gt; #合并分支到当前分支上面 如果需要有历史版本的merge，那么请使用—no-ff 1git merge --no-ff -m &quot;merge with no-ff&quot; dev]]></content>
      <categories>
        <category>编程学习</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
</search>
